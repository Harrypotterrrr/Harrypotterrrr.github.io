window.TEXT_SEARCH_DATA={'experience':[{'title':"The Experimental High School Attached To Beijing Normal University",'url':"/experience/high_school"},{'title':"Tongji University",'url':"/experience/tongji"},{'title':"University of California, Merced",'url':"/experience/ucm"},{'title':"New York University",'url':"/experience/nyu"}],'posts':[{'title':"Post with Header Image",'url':"/2018/06/01/header-image.html"},{'title':"Welcome",'url':"/2018/07/01/welcome.html"},{'title':"Linux cookbook",'url':"/2019/02/06/Linux-cookbook.html"},{'title':"Git cookbook",'url':"/2019/02/10/Git-cookbook.html"},{'title':"Generative Adversarial Text to Image Synthesis",'url':"/2019/05/11/Text_to_image-1.html"},{'title':"Learning where and what to draw",'url':"/2019/05/18/Text_to_image-2.html"},{'title':"Text2Scene: Generating Compositional Scenes from Textual Descriptions",'url':"/2019/05/22/Text_to_scene.html"},{'title':"Semi-parametric Image Synthesis",'url':"/2019/05/28/Semi-param_img_syn.html"},{'title':"Tmux tutorial",'url':"/2019/06/20/Tmux-cookbook.html"},{'title':"Image generation from scene graphs",'url':"/2019/07/13/Sg2im.html"},{'title':"StoryGAN: A Sequential Conditional GAN for Story Visualization",'url':"/2019/07/14/storyGAN.html"},{'title':"Object-driven Text-to-Image Synthesis via Adversarial Training",'url':"/2019/07/16/ObjGAN.html"},{'title':"Vim cookbook",'url':"/2019/08/03/Vim-cookbook.html"},{'title':"Port forward",'url':"/2020/04/01/Port-forward.html"}]};
