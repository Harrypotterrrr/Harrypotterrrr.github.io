<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://harrypotterrrr.github.io//feed.xml" rel="self" type="application/atom+xml" /><link href="https://harrypotterrrr.github.io//" rel="alternate" type="text/html" /><updated>2021-05-31T10:04:22+08:00</updated><id>https://harrypotterrrr.github.io//feed.xml</id><title type="html">Haolin Jia’s Homepage</title><subtitle>Keep working hard!
</subtitle><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><entry><title type="html">The Notes of Computer Graphics Ⅹ</title><link href="https://harrypotterrrr.github.io//2020/12/20/cg-10.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅹ" /><published>2020-12-20T00:00:00+08:00</published><updated>2020-12-20T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/12/20/cg-10</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/12/20/cg-10.html">&lt;p&gt;Material, Microfacet Theory, Isotropic Material, Anisotropic Material&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;material&quot;&gt;Material&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Recall that BRDF is used to calculate how much of the light ray will be reflected in a particular outgoing direction by the surface, which specify reflection ability and properties of the surface
    &lt;ul&gt;
      &lt;li&gt;Material == BRDF&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/11/y0TtQP.jpg&quot; alt=&quot;cg-10-1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;diffuse--lambertian-material&quot;&gt;Diffuse / Lambertian Material&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Assume a senario with a reflected point
    &lt;ul&gt;
      &lt;li&gt;Light coming in distributed uniformly in the hemisphere&lt;/li&gt;
      &lt;li&gt;The point absorbs nothing energy and reflects all the energy out&lt;/li&gt;
      &lt;li&gt;Light is equally reflected in each output direction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned} 
L_{o}\left(\omega_{o}\right) &amp;amp;=\int_{H^{2}} f_{r} L_{i}\left(\omega_{i}\right) \cos \theta_{i} d \omega_{i} \\ 
&amp;amp;=f_{r} L_{i} \int_{H^{2}} \cos \theta_{i} d \omega_{i} \\ 
&amp;amp;=f_{r} L_{i} \int_{H^{2}} \cos \theta \sin \theta d \theta d \varphi \\ 
&amp;amp;=f_{r} L_{i} \int_{0}^{\frac{\pi}{2}} \cos \theta \sin \theta d \theta \int_{0}^{2 \pi} d \theta \\ 
&amp;amp;=f_{r} L_{i} \cdot \frac{1}{4} \cos 2 \theta \bigg|_{\frac{\pi}{2}} ^{0} \cdot \varphi \bigg|_{0} ^{2 \pi} \\ 
&amp;amp;=\pi f_{r} L_{i} 
\end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/11/y0T8JA.jpg&quot; alt=&quot;cg-10-2&quot; style=&quot;width:40%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;On account of energy conservation, the energy absorbed and the enrgy emitted from the point is the same
    &lt;ul&gt;
      &lt;li&gt;incident radiance equals to exitant radiance&lt;/li&gt;
    &lt;/ul&gt;

\[\left\{\begin{array}{l} L_o = L_i \\ L_{o}\left(\omega_{o}\right) = \pi f_{r} L_{i}\end{array}\right.\]

\[f_r = \frac{1}{\pi}\]
  &lt;/li&gt;
  &lt;li&gt;Denote reflection ratio $\rho$ (&lt;strong&gt;albedo&lt;/strong&gt;) $0 \lt \rho \lt 1$
    &lt;ul&gt;
      &lt;li&gt;Three dimensional vector to specify different ability of reflection regrading three colors&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[f_r = \frac{\rho}{\pi} \in (0, \frac{1}{\pi})\]

&lt;h3 id=&quot;material-category&quot;&gt;Material Category&lt;/h3&gt;

&lt;h4 id=&quot;diffuse-material&quot;&gt;Diffuse Material&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/11/y0T3id.jpg&quot; alt=&quot;cg-10-3&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;glossy-material&quot;&gt;Glossy Material&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/11/y0TJzt.jpg&quot; alt=&quot;cg-10-4&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;ideal-reflective--refractive-material&quot;&gt;Ideal Reflective / Refractive Material&lt;/h4&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/11/y0TGRI.jpg&quot; alt=&quot;cg-10-5&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;specular-reflection&quot;&gt;Specular Reflection&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Calculate &lt;a href=&quot;/2020/12/03/cg-9#Angles-and-Solid-Angles&quot;&gt;zenith angle and azimuth angle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/11/y0TNsf.jpg&quot; alt=&quot;cg-10-6&quot; style=&quot;width:70%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

\[\omega_{o}+\omega_{i}=2 \cos \theta \overrightarrow{\mathrm{n}}=2\left(\omega_{i} \cdot \overrightarrow{\mathrm{n}}\right) \overrightarrow{\mathrm{n}}\]

\[\omega_{o}=-\omega_{i}+2\left(\omega_{i} \cdot \overrightarrow{\mathrm{n}}\right) \overrightarrow{\mathrm{n}}\]

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: The difference between Blinn-Phong model and Phong model is the half vector, which is computed by adding incident vector and the vector of viewing direction. With dot product, Computing reflected is less efficient than half vector.&lt;/p&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: BRDF distributes as &lt;a href=&quot;https://en.wikipedia.org/wiki/Dirac_delta_function&quot;&gt;Dirac δ function(distribution)&lt;/a&gt;. The total area under BRDF curve is the &lt;strong&gt;albedo&lt;/strong&gt; specifying what fraction of incident light is reflected in total, which is as opposed to being abosorbed or transmitted. For the perfect reflector, the area under the curbe sums to 1, because it reflects all of the incident light but in one direction. In this case, the δ function, with the area of 1, is an infinite thin and infinite tall spike at $x = 0$, which is ideal reflective material.&lt;/p&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Obviously, a real material can not be perfect specular reflector. First, the area under the curve is less than 1 due to some of the light absorbed. More importantly, the reflection peak can not be infinite thin so that the reflection will be blurred ever so slightly. This implicates that the peak will not be infinitely high. The wider the peak, the less hight it has to be to maintain the area of 1.&lt;/p&gt;

&lt;h3 id=&quot;specular-refraction&quot;&gt;Specular Refraction&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;In addition to reflecting off surface, light may be transmitted through surface.&lt;/li&gt;
  &lt;li&gt;Light refracts when it enters a new medium.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/11/y0TUL8.jpg&quot; alt=&quot;cg-10-7&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Though the scattering of the light is due to the discrepancy of the wave length of light, we still consider it in geometric way as different refractive index in CG.&lt;/li&gt;
  &lt;li&gt;The phenomenon of &lt;a href=&quot;https://en.wikipedia.org/wiki/Caustic_(optics)&quot;&gt;caustics&lt;/a&gt; as the right image shows is caused by light rays refracting off the uneven and curved surface of the sea and converging on the seafloor. It is tricky to deal with such thing in practical CG implementation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;snells-law&quot;&gt;Snell’s Law&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Snell’s Law&lt;/strong&gt;: Transmitted angle depends on
    &lt;ul&gt;
      &lt;li&gt;index of refraction (IOR) for incident ray&lt;/li&gt;
      &lt;li&gt;index of refraction (IOR) for exiting ray&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;calculate azimuth angle in the same as reflection&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/yrab7T.jpg&quot; alt=&quot;cg-10-8&quot; style=&quot;width:60%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Medium&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;$\eta ^*$&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Vaccum&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Air (sea level)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.00029&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Water(20°C)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.333&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Glass&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1.5-1.6&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Diamond&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2.42&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;index of refraction is wavelength dependent&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Total internal reflection&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned} \eta_{i} \sin \theta_{i} &amp;amp;=\eta_{t} \sin \theta_{t} \\ \cos \theta_{t} &amp;amp;=\sqrt{1-\sin ^{2} \theta_{t}} \\ &amp;amp;=\sqrt{1-\left(\frac{\eta_{i}}{\eta_{t}}\right)^{2} \sin ^{2} \theta_{i}} \\ &amp;amp;=\sqrt{1-\left(\frac{\eta_{i}}{\eta_{t}}\right)^{2}\left(1-\cos ^{2} \theta_{i}\right)}\end{aligned}\]

\[1-\left(\frac{\eta_{i}}{\eta_{t}}\right)^{2}\left(1-\cos ^{2} \theta_{i}\right)&amp;lt;0\]

&lt;ul&gt;
  &lt;li&gt;When light is moving from a more optically dense medium (e.g. water) to a less optically dense medium (e.g. air), which means $\eta_i / \eta_t \gt 1$&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Light incident on boundary from large enough angle &lt;strong&gt;may&lt;/strong&gt; not exit medium&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Snell’s Window / Circle&lt;/strong&gt;: underwater viewer sees everthing above the surface through a cone of light.
    &lt;ul&gt;
      &lt;li&gt;The area outside Snell’s window will be dark or show a reflection of underwater objects by total internal reflection&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/yraONF.jpg&quot; alt=&quot;cg-10-9&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: The sphere is symmetric object, which means that the light ray refracted into the sphere will &lt;strong&gt;always&lt;/strong&gt; be refracted out.&lt;/p&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;info&lt;/strong&gt;: &lt;strong&gt;BTDF&lt;/strong&gt; (bidirectional transmittance distribution function) is similar to &lt;strong&gt;BRDF&lt;/strong&gt; (bidirectional reflectance distribution function) but for the opposite side of the surface, especially used to evaluate how outgoing refractive light distributes at incident point. Further, &lt;strong&gt;BSDF&lt;/strong&gt; (bidirectional scattering distribution function) is the generalization of &lt;strong&gt;BRDF&lt;/strong&gt; and &lt;strong&gt;BTDF&lt;/strong&gt;. Moreover, &lt;strong&gt;BSSRDF&lt;/strong&gt; (bidirectional scattering-surface reflectance distribution function) describes the relationship between outgoing radiance and the incident flux, including the phenonmona like &lt;a href=&quot;https://en.wikipedia.org/wiki/Subsurface_scattering&quot;&gt;subsurface scattering&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&quot;fresnel-reflection-term&quot;&gt;Fresnel Reflection Term&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Fresnel Reflection&lt;/strong&gt;: predict the reflectance of smooth surfaces, and depends solely on the refractive index and the angle of incidence.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The inverted reflection in water gradually evanish with the increasing incident angle between the normal of horizontal plane and incident light.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/yraXh4.jpg&quot; alt=&quot;cg-10-10&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fresnel Term of Dielectric material ($\eta = 1.5$, &lt;strong&gt;i.e.&lt;/strong&gt; most glasses and plastics)
    &lt;ul&gt;
      &lt;li&gt;Reflectance increases greatly as the grazing angle increases&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/yraHBV.jpg&quot; alt=&quot;cg-10-12&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fresnel Term of Conductor (&lt;strong&gt;i.e.&lt;/strong&gt; metals)
    &lt;ul&gt;
      &lt;li&gt;The effect of Fresnel reflectance is subtle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/yraLAU.jpg&quot; alt=&quot;cg-10-11&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Index of refraction of the conductor is actually the complex number, which contains two number $n,\ k$.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;This is the reason why people use polished metal (mercury) as mirror instead of polished glass.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: Polarization is defined relative to the plane of incidence, i.e. the plane that contains the incoming and reflected rays as well as the normal to the sample surface. Perpendicular (&lt;strong&gt;s-&lt;/strong&gt;)polarization is the polarization where the electric field is perpendicular to the plane of incidence. Parallel (&lt;strong&gt;p-&lt;/strong&gt;)polarization is the polarization where the electric field is parallel to the plane of incidence.&lt;/p&gt;

&lt;h4 id=&quot;fresnel-equation&quot;&gt;Fresnel Equation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Consider the light as a wave&lt;/li&gt;
  &lt;li&gt;Accurate and need to consider polarization&lt;/li&gt;
&lt;/ul&gt;

\[R_{\mathrm{s}}=\left|\frac{n_{1} \cos \theta_{\mathrm{i}}-n_{2} \cos \theta_{\mathrm{t}}}{n_{1} \cos \theta_{\mathrm{i}}+n_{2} \cos \theta_{\mathrm{t}}}\right|^{2}=\left|\frac{n_{1} \cos \theta_{\mathrm{i}}-n_{2} \sqrt{1-\left(\frac{n_{1}}{n_{2}} \sin \theta_{\mathrm{i}}\right)^{2}}}{n_{1} \cos \theta_{\mathrm{i}}+n_{2} \sqrt{1-\left(\frac{n_{1}}{n_{2}} \sin \theta_{\mathrm{i}}\right)^{2}}}\right|^{2}\]

\[R_{\mathrm{p}}=\left|\frac{n_{1} \cos \theta_{\mathrm{t}}-n_{2} \cos \theta_{\mathrm{i}}}{n_{1} \cos \theta_{\mathrm{t}}+n_{2} \cos \theta_{\mathrm{i}}}\right|^{2}=\left|\frac{n_{1} \sqrt{1-\left(\frac{n_{1}}{n_{2}} \sin \theta_{\mathrm{i}}\right)^{2}}-n_{2} \cos \theta_{\mathrm{i}}}{n_{1} \sqrt{1-\left(\frac{n_{1}}{n_{2}} \sin \theta_{\mathrm{i}}\right)^{2}}+n_{2} \cos \theta_{\mathrm{i}}}\right|\]

&lt;ul&gt;
  &lt;li&gt;Effective reflectivity (&lt;strong&gt;unpolarized&lt;/strong&gt;) is just the average of two reflectivities&lt;/li&gt;
&lt;/ul&gt;

\[R_{\mathrm{eff}} =\frac{1}{2}\left(R_{\mathrm{s}}+R_{\mathrm{p}}\right)\]

&lt;h4 id=&quot;schlicks-approximation&quot;&gt;Schlick’s approximation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;$\theta$ : angle between the incident light and the normal&lt;/li&gt;
  &lt;li&gt;$n_1,\ n_2$ : indices of refraction of two media at the intrerface&lt;/li&gt;
  &lt;li&gt;$R_0$ : reflection coefficient for light incoming parallel to the normal (the value of Fresnel term when $\theta = 0$)&lt;/li&gt;
&lt;/ul&gt;

\[R(\theta) =R_{0}+\left(1-R_{0}\right)(1-\cos \theta)^{5}\]

\[R_{0} =\left(\frac{n_{1}-n_{2}}{n_{1}+n_{2}}\right)^{2}\]

&lt;h2 id=&quot;microfacet-material&quot;&gt;Microfacet Material&lt;/h2&gt;

&lt;h3 id=&quot;microfacet-theory&quot;&gt;Microfacet Theory&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Microfacet theory&lt;/strong&gt;: Rough surfaces can be modeled as a collection of small microfacets
    &lt;ul&gt;
      &lt;li&gt;Macroscale: flat &amp;amp; rough material, describe underlying smooth surface&lt;/li&gt;
      &lt;li&gt;Microscale: bumpy &amp;amp; specular property, describe high variation of microfacet surfaces&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Individual elements of surface at like &lt;strong&gt;mirror&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Known as Microfacets&lt;/li&gt;
      &lt;li&gt;Each microfacet has its own normal&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Intuitively, surface is regarded as &lt;strong&gt;material&lt;/strong&gt; see from a distance, &lt;strong&gt;geometry&lt;/strong&gt; see from closeup
    &lt;ul&gt;
      &lt;li&gt;As the camera zooms out away from the surface, geometry will gradually fades into material.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysEcs1.jpg&quot; alt=&quot;cg-10-13&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;microfacet-brdf&quot;&gt;Microfacet BRDF&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Microfacet BRDF: &lt;strong&gt;distribution&lt;/strong&gt; of microfacets’ normals&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Concentrated &amp;lt;==&amp;gt; smooth &amp;lt;==&amp;gt; glossy&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysAq5F.jpg&quot; alt=&quot;cg-10-14&quot; style=&quot;width:80%;&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Spread &amp;lt;==&amp;gt; rough  &amp;lt;==&amp;gt; diffuse&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysAbUU.jpg&quot; alt=&quot;cg-10-15&quot; style=&quot;width:80%;&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[f_{microfacet} (i, o) = \frac{F(i, h)G(i,o,h)D(h)}{4(n,i)(n,o)}\]

&lt;ul&gt;
  &lt;li&gt;$f_{microfacet}$ : microfacet BRDF&lt;/li&gt;
  &lt;li&gt;$F(i, h)$ : Fresnel reflectance term, the amount of energy reflected in terms of incident angle&lt;/li&gt;
  &lt;li&gt;$G(i,o,h)$ : geometry term of shadowing masking between microfacet&lt;/li&gt;
  &lt;li&gt;$D(h)$ : normal distribution term describing how microfacet normals is distributed around the given direction $h$&lt;/li&gt;
  &lt;li&gt;$i$ : incident light direction&lt;/li&gt;
  &lt;li&gt;$o$ : view direction&lt;/li&gt;
  &lt;li&gt;$n$ : surface normal&lt;/li&gt;
  &lt;li&gt;$h$ : half vector between $i$ and $o$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysAoD0.jpg&quot; alt=&quot;cg-10-16&quot; style=&quot;width:80%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;More details discussed in paper &lt;a href=&quot;https://www.cs.cornell.edu/~srm/publications/EGSR07-btdf.html&quot;&gt;Microfacet Models for Refraction through Rough Surfaces&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: Three Important Geometric Effects to Consider with Microfacet Reflection Models. &lt;strong&gt;(a)&lt;/strong&gt; Masking: the microfacet of interest isn’t visible to the viewer due to occlusion by another microfacet. &lt;strong&gt;(b)&lt;/strong&gt; Shadowing: analogously, light doesn’t reach the microfacet. &lt;strong&gt;(c)&lt;/strong&gt; Interreflection: light bounces among the microfacets before reaching the viewer. Shadow-masking effect is obvious when the angle between incident light or viewing direction and normal is aounrd 90°, which we called &lt;strong&gt;grazing angle&lt;/strong&gt; (掠射角).&lt;br /&gt;
&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysEPUO.jpg&quot; alt=&quot;cg-10-17&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Microfacet model is widely used in &lt;strong&gt;PBR&lt;/strong&gt; (Physically Based Rendering)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysAHET.jpg&quot; alt=&quot;cg-10-18&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;isotropic--anisotropic-material&quot;&gt;Isotropic / Anisotropic Material&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;One way to classifying material: directionality of underlying surface&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysATbV.jpg&quot; alt=&quot;cg-10-19&quot; style=&quot;width:70%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Isotropic Material&lt;/strong&gt;: have identical properties in all direction.
    &lt;ul&gt;
      &lt;li&gt;Rotate around normal without changing reflections.&lt;/li&gt;
      &lt;li&gt;BRDF only depends on &lt;strong&gt;relative&lt;/strong&gt; location (azimuth angle) of the incident and exitent light ray&lt;/li&gt;
      &lt;li&gt;e.g. Most materials&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[f_{r}\left(\theta_{i}, \phi_{i} ; \theta_{r}, \phi_{r}\right) = f_{r}\left(\theta_{i}, \phi_{i} - \phi ; \theta_{r}, \phi_{r} - \phi \right) = f_{r}\left(\theta_{i}, \theta_{r}, \phi_{r} - \phi_{i} \right)\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysAOC4.jpg&quot; alt=&quot;cg-10-20&quot; style=&quot;width:60%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Anisotropic Material&lt;/strong&gt;: change properties with direction.
    &lt;ul&gt;
      &lt;li&gt;Rotate on zaimuth angle $\Phi$ and change BRDF&lt;/li&gt;
      &lt;li&gt;e.g. Brushed metal&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysAX8J.jpg&quot; alt=&quot;cg-10-21&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Some other anisotropic material
    &lt;ul&gt;
      &lt;li&gt;Nylon: istropic along colum and row but not in the diagonal direction&lt;/li&gt;
      &lt;li&gt;Velvet: self-defined microfacet material&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysENq0.gif&quot; alt=&quot;cg-10-22&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;properties-of-brdf&quot;&gt;Properties of BRDF&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Non-negativity: BRDF represents the distribution of energy&lt;/li&gt;
&lt;/ul&gt;

\[f_{r}\left(\omega_{i} \rightarrow \omega_{r}\right) \geq 0\]

&lt;ul&gt;
  &lt;li&gt;Linearity: In Blinn-Phong model, shading is the sum of ambient, diffuse, specular terms, while BRDF takes three parts as a whole.
    &lt;ul&gt;
      &lt;li&gt;More generally, in many cases, material often require multiple ray tracing with different BRDF to achieve reflective properties.&lt;/li&gt;
      &lt;li&gt;The total radiance of a point on a surface can be simply expressed as the sum of the radiance of multiple BRDFS.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[L_{r}\left(\mathrm{p}, \omega_{r}\right)= \sum_{BRDF} \int_{H^{2}} f_{r}\left(\mathrm{p}, \omega_{i} \rightarrow \omega_{r}\right) L_{i}\left(\mathrm{p}, \omega_{i}\right) \cos \theta_{i} \mathrm{~d} \omega_{i}\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysAj29.jpg&quot; alt=&quot;cg-10-23&quot; style=&quot;width:70%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reciprocity principle (可逆性): similar to the reciprocity of light ray&lt;/li&gt;
&lt;/ul&gt;

\[f_{r}\left(\omega_{r} \rightarrow \omega_{i}\right)=f_{r}\left(\omega_{i} \rightarrow \omega_{r}\right)\]

&lt;ul&gt;
  &lt;li&gt;Energy conservation: otherwise, the energy will not converge but explode in path tracing.&lt;/li&gt;
&lt;/ul&gt;

\[\forall \omega_{r} \int_{H^{2}} f_{r}\left(\omega_{i} \rightarrow \omega_{r}\right) \cos \theta_{i} \mathrm{~d} \omega_{i} \leq 1\]

&lt;ul&gt;
  &lt;li&gt;Isotropic or anisotropic
    &lt;ul&gt;
      &lt;li&gt;If isotropic:&lt;/li&gt;
    &lt;/ul&gt;

\[f_{r}\left(\theta_{i}, \phi_{i} ; \theta_{r}, \phi_{r}\right)=f_{r}\left(\theta_{i}, \theta_{r}, \phi_{r}-\phi_{i}\right)\]

    &lt;ul&gt;
      &lt;li&gt;Then, from reciprocity:&lt;/li&gt;
    &lt;/ul&gt;

\[f_{r}\left(\theta_{i}, \theta_{r}, \phi_{r}-\phi_{i}\right)=f_{r}\left(\theta_{r}, \theta_{i}, \phi_{i}-\phi_{r}\right)=f_{r}\left(\theta_{i}, \theta_{r},\left|\phi_{r}-\phi_{i}\right|\right)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;measuring-brdf&quot;&gt;Measuring BRDF&lt;/h2&gt;

&lt;h3 id=&quot;motivation-of-measuring-brdf&quot;&gt;Motivation of Measuring BRDF&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Avoid need to develop / derive models:the error of the theory model is sometimes very large&lt;/li&gt;
  &lt;li&gt;Accurately render with real-world materials: automatically includes all of the scattering effects present and useful for product design, special effects, …&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;general-approach&quot;&gt;General Approach&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Image-based BRDF measurement: goniorreflectometer&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysESDx.jpg&quot; alt=&quot;cg-10-24&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outgoing&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;direction&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;move&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;light&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;illuminate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;surface&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thin&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beam&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_o&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;incoming&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;direction&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;move&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sensor&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;be&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;direction&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w_i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;surface&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;measure&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;incident&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;radiance&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Improving efficiency
    &lt;ul&gt;
      &lt;li&gt;Isotropic surfaces reduce dimensionality from 4D to 3D
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;4D to 3D&lt;/strong&gt;: $f_{r}\left(\theta_{i}, \phi_{i} ; \theta_{r}, \phi_{r}\right) \implies f_{r}\left(\theta_{i}, \theta_{r}, \phi_{r}-\phi_{i}\right)$&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;Curse of dimensionality&lt;/strong&gt;: with an increase dimension, the size of data surges&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Reciprocity reduces number of measurements by half&lt;/li&gt;
      &lt;li&gt;Clever optical systems …&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;challenges-in-measuring-brdf&quot;&gt;Challenges in Measuring BRDF&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Accurate measurements at grazing angles
    &lt;ul&gt;
      &lt;li&gt;Important due to Fresnel effects&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Measuring with dense enough sampling to capture high frequency specularities&lt;/li&gt;
  &lt;li&gt;Retro-reflection&lt;/li&gt;
  &lt;li&gt;Spatially-varying reflectance, …&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;representing-measured-brdf&quot;&gt;Representing Measured BRDF&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Desirable qualities
    &lt;ul&gt;
      &lt;li&gt;Compact representation&lt;/li&gt;
      &lt;li&gt;Accurate representation of measured data&lt;/li&gt;
      &lt;li&gt;Efficient evaluation for arbitrary pairs of diretions&lt;/li&gt;
      &lt;li&gt;Good distributions available for importance sampling&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Tabular Representation
    &lt;ul&gt;
      &lt;li&gt;Store regularly-spaced samples in $ ( \theta_i, \theta_o, \big| \phi_i - \phi_o \big| ) $
        &lt;ul&gt;
          &lt;li&gt;Better: reparameterize angles to better match specularities&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Generally need to resample measured values to table&lt;/li&gt;
      &lt;li&gt;Very high storage requirements&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/13/ysAzK1.jpg&quot; alt=&quot;cg-10-25&quot; style=&quot;width:60%;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://computergraphics.stackexchange.com/questions/4767&quot;&gt;BRDF of specular reflection is infinite&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Fresnel_equations&quot;&gt;Fresnel equations&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.cornell.edu/~srm/publications/EGSR07-btdf.html&quot;&gt;Microfacet Models for Refraction through Rough Surfaces&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.pbr-book.org/3ed-2018/Reflection_Models/Microfacet_Models.html&quot;&gt;Microfacet Models&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://simonstechblog.blogspot.com/2011/12/microfacet-brdf.html&quot;&gt;Microfacet BRDF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/62904454&quot;&gt;深入BRDF和PBR&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">Material, Microfacet Theory, Isotropic Material, Anisotropic Material</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅸ</title><link href="https://harrypotterrrr.github.io//2020/12/03/cg-9.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅸ" /><published>2020-12-03T00:00:00+08:00</published><updated>2020-12-03T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/12/03/cg-9</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/12/03/cg-9.html">&lt;p&gt;Advanced Ray Tracing, Radiometry, BRDF, Path Tracing&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;radiometry&quot;&gt;Radiometry&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Motivation: Blinn-Phong is experienced model and light intensity corresponding to the amount of shading is not explained well, the output is not realistic but plastic. Whitted-style ray tracing sometimes doesn’t give correct result, especially involving how much light energy is refracted and reflected, and how much the rest is absorbed by the material, etc.
    &lt;ul&gt;
      &lt;li&gt;All the answers can be found in radiometry!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Measurement system and units for illumination&lt;/li&gt;
  &lt;li&gt;Accurately measure the spatial properties of light (not temperal dimension, we still suppose light travel in straight line with out wave property)
    &lt;ul&gt;
      &lt;li&gt;New terms: Radiant flux, intensity, irradiance, radiance (辐射通量, 光强, 照度, 亮度)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Perform lighting calculations in a physically correct manner&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;radiant-energy-and-flux&quot;&gt;Radiant Energy and Flux&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Radiant energy&lt;/strong&gt;: the energy of electromagnetic radiation. It is measured in units of joules, and denoted by the symbol:&lt;/li&gt;
&lt;/ul&gt;

\[Q[J=Joule]\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Radiant flux&lt;/strong&gt; (&lt;strong&gt;radiant power&lt;/strong&gt;, &lt;strong&gt;luminous flux&lt;/strong&gt;): the energy emitted, reflected, transmitted or received, &lt;strong&gt;per unit time&lt;/strong&gt;.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Flux&lt;/strong&gt;: photons flowing through a sensor in unit time&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\Phi \equiv \frac{\mathrm{d} Q}{\mathrm{~d} t}\]

\[[\mathrm{~W}=\mathrm{Watt}][\mathrm{lm}=\operatorname{lumen}]^{\star}\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/sgJQAI.png&quot; alt=&quot;cg-9-1&quot; style=&quot;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;radiant-intensity&quot;&gt;Radiant Intensity&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Radiant Intensity&lt;/strong&gt;: The radiant (luminous) intensity is the power per unit solid angle emitted by a point light source.&lt;/li&gt;
&lt;/ul&gt;

\[I(\omega) \equiv \frac{\mathrm{d} \Phi}{\mathrm{d} \omega}\]

\[\left[\frac{\mathrm{W}}{\mathrm{sr}}\right]\left[\frac{\mathrm{lm}}{\mathrm{sr}}=\mathrm{cd}=\mathrm{candela}\right]\]

&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;candela&lt;/strong&gt; is one of the seven SI base units&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/sg8uxe.jpg&quot; alt=&quot;cg-9-2&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;angles-and-solid-angles&quot;&gt;Angles and Solid Angles&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Angle&lt;/strong&gt;: ratio of subtended arc length on circle to radius
    &lt;ul&gt;
      &lt;li&gt;$\theta = l / r$&lt;/li&gt;
      &lt;li&gt;Circle has $2\pi$ radians&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Solid angle&lt;/strong&gt;: ratio of subtended area on sphere to radius squared
    &lt;ul&gt;
      &lt;li&gt;$\omega = A / r^2$&lt;/li&gt;
      &lt;li&gt;Sphere has $4\pi$ steradians&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/sg8V56.jpg&quot; alt=&quot;cg-9-3&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Differential Solid Angles
    &lt;ul&gt;
      &lt;li&gt;Direction vector $\omega$ to denote direction vector of unit length&lt;/li&gt;
      &lt;li&gt;$\theta$ : elevation, zenith angle (仰角)&lt;/li&gt;
      &lt;li&gt;$\phi$ : azimuth, azimuth angle (方位角)&lt;/li&gt;
    &lt;/ul&gt;

\[\mathrm{d} A =(r \mathrm{~d} \theta)(r \sin \theta \mathrm{d} \phi) =r^{2} \sin \theta \mathrm{d} \theta \mathrm{d} \phi\]

\[\mathrm{d} \omega =\frac{\mathrm{d} A}{r^{2}}=\sin \theta \mathrm{d} \theta \mathrm{d} \phi\]

    &lt;ul&gt;
      &lt;li&gt;Sphere: $S^{2}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\Omega =\int_{S^{2}} \mathrm{~d} \omega = \int_{0}^{\pi} \sin \theta \mathrm{d} \theta \int_{0}^{2 \pi} \mathrm{d} \phi  =4 \pi\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/sg8ePK.jpg&quot; alt=&quot;cg-9-4&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Isotropic Point Source&lt;/li&gt;
&lt;/ul&gt;

\[\Phi = \int_{S^2}Idw = 4\pi I\]

\[I=\frac{\Phi}{4\pi}\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/sgqUs0.jpg&quot; alt=&quot;cg-9-5&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Modern LED Light
    &lt;ul&gt;
      &lt;li&gt;Output: 815 lumens (11W LED replacement paifor 60W incandescent)&lt;/li&gt;
      &lt;li&gt;Radiant intensity (assume isotropic) = 815 lumens / 4π sr = 65 candelas&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;irradiance&quot;&gt;Irradiance&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Irradiance&lt;/strong&gt;: the power per (perpendicular / projected) unit area incident on a surface point.&lt;/li&gt;
&lt;/ul&gt;

\[E(\mathbf{x}) \equiv \frac{\mathrm{d} \Phi(\mathbf{x})}{\mathrm{d} A}\]

\[\left[\frac{\mathrm{W}}{\mathrm{m}^{2}}\right]\left[\frac{\mathrm{lm}}{\mathrm{m}^{2}}=\operatorname{lux}\right]\]

&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;lux&lt;/strong&gt; is SI derived unit of illuminance, measuring luminous flux per unit area.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/sg8uxe.jpg&quot; alt=&quot;cg-9-2&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Irradiance&lt;/strong&gt; at surface is proportional to &lt;strong&gt;cosine&lt;/strong&gt; of angle between light direction and surface normal
    &lt;ul&gt;
      &lt;li&gt;Recall &lt;a href=&quot;/2020/09/02/cg-5#diffuse-reflection&quot;&gt;Lambert’s Cosine Law&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/s2AFXT.jpg&quot; alt=&quot;cg-9-6&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Analogous &lt;strong&gt;Irradiance&lt;/strong&gt; to &lt;strong&gt;Electric field intensity&lt;/strong&gt;, &lt;strong&gt;Radiant flux&lt;/strong&gt; to &lt;strong&gt;Magnetic Flux&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The reason why we feel cold and hot in different seasons
    &lt;ul&gt;
      &lt;li&gt;Earth’s axis of rotation: ~23.5° off axis&lt;/li&gt;
      &lt;li&gt;Give rise to the different Solar elevation angle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/s2AP10.jpg&quot; alt=&quot;cg-9-7&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;/2020/09/02/cg-5#light-falloff&quot;&gt;Correction&lt;/a&gt; of Irradiance Falloff
    &lt;ul&gt;
      &lt;li&gt;Assume light is emitting power $\Phi$ in a uniform angular distribution&lt;/li&gt;
      &lt;li&gt;Compare irradiance at surface of two spheres&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/s2AicV.jpg&quot; alt=&quot;cg-9-8&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;radiance&quot;&gt;Radiance&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Radiance&lt;/strong&gt; (&lt;strong&gt;luminance&lt;/strong&gt;): the power emitted, reflected, transmitted or received by a surface, &lt;strong&gt;per unit solid angle&lt;/strong&gt;, &lt;strong&gt;per projected unit area&lt;/strong&gt;.
    &lt;ul&gt;
      &lt;li&gt;Radiance is the fundamental field quantity that describes the distribution of light in an environment&lt;/li&gt;
      &lt;li&gt;Radiance is the quantity associated with a ray&lt;/li&gt;
      &lt;li&gt;Rendering is all about computing radiance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/s2ACpq.jpg&quot; alt=&quot;cg-9-9&quot; style=&quot;width:70%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

\[L(\mathrm{p}, \omega) \equiv \frac{\mathrm{d}^{2} \Phi(\mathrm{p}, \omega)}{\mathrm{d} \omega \mathrm{d} A \cos \theta}\]

\[\left[\frac{\mathrm{W}}{\mathrm{sr} \mathrm{m}^{2}}\right]\left[\frac{\mathrm{cd}}{\mathrm{m}^{2}}=\frac{\mathrm{lm}}{\mathrm{sr} \mathrm{m}^{2}}=\mathrm{nit}\right]\]

&lt;ul&gt;
  &lt;li&gt;$\cos\theta$ accounts for projected surface area&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;nit&lt;/strong&gt;, the candela per square metre, is the derived SI unit of luminance.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/sg8uxe.jpg&quot; alt=&quot;cg-9-2&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Recall
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Irradiance&lt;/strong&gt;: power per projected unit area&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Intensity&lt;/strong&gt;: power per solid angle&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Radiance&lt;/strong&gt;: power per solid angle, per projected unit area&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Thus
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Radiance&lt;/strong&gt;: Irradiance per solid angle&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Radiance&lt;/strong&gt;: Intensity per projected unit area&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;incident-radiance&quot;&gt;Incident Radiance&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Incident Radiance&lt;/strong&gt;: the irradiance per unit solid angle arriving at the surface
    &lt;ul&gt;
      &lt;li&gt;It is the light arriving at the surface along a given ray (point on surface and incident direction).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/s2Aphn.jpg&quot; alt=&quot;cg-9-10&quot; style=&quot;width:70%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

\[L(\mathrm{p}, \omega)=\frac{\mathrm{d} E(\mathrm{p})}{\mathrm{d} \omega \cos \theta}\]

&lt;h4 id=&quot;exiting-radiance&quot;&gt;Exiting Radiance&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Exiting Radiance&lt;/strong&gt;: the intensity per unit projected area leaving the surface
    &lt;ul&gt;
      &lt;li&gt;For an area light, it is the light emitted along a given ray (point on surface and exit direction).&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/s2ACpq.jpg&quot; alt=&quot;cg-9-9&quot; style=&quot;width:70%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

\[L(\mathrm{p}, \omega)=\frac{\mathrm{d} I(\mathrm{p}, \omega)}{\mathrm{d} A \cos \theta}\]

&lt;h4 id=&quot;irradiance-vs-radiance&quot;&gt;Irradiance vs. Radiance&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Irradiance: total power received by area $dA$&lt;/li&gt;
  &lt;li&gt;Radiance: power received by area $dA$ from direction $d\omega$&lt;/li&gt;
&lt;/ul&gt;

\[d E(\mathrm{p}, \omega) =L_{i}(\mathrm{p}, \omega) \cos \theta \mathrm{d} \omega\]

\[E(\mathrm{p}) =\int_{H^{2}} L_{i}(\mathrm{p}, \omega) \cos \theta \mathrm{d} \omega\]

&lt;ul&gt;
  &lt;li&gt;Unit Hemisphere $H^2$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/19/s2AAnU.jpg&quot; alt=&quot;cg-9-11&quot; style=&quot;width:55%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;bidirectional-reflectance-distribution-function&quot;&gt;Bidirectional Reflectance Distribution Function&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Radiance from direction $\omega_i$ turns into the power $E$ that $dA$ receives&lt;/li&gt;
  &lt;li&gt;The npower $E$ will become the radiance to any other direction $\omega_o$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/29/yihyJx.jpg&quot; alt=&quot;cg-9-12&quot; style=&quot;width:55%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Differential irradiance incoming: $d E\left(\omega_{i}\right)=L\left(\omega_{i}\right) \cos \theta_{i} d \omega_{i}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Differential radiance exiting (due to $dE(\omega_i)$): $dL_r(\omega_r)$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;BRDF can be understanded in the way of energy distribution after the point on the surface absorbs the energy from directions all around and then reflects.&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;For the specular reflection, BRDF specifies the reflected energy is mostly on the reflection direction&lt;/li&gt;
      &lt;li&gt;For the diffuse reflection, BRDF specifies the reflected energy will distributed amoung all directions around.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;brdf&quot;&gt;BRDF&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Bidirectional Reflectance Distribution Function&lt;/strong&gt; (BRDF): represents how much light is reflected into each outgoing direction $\omega_r$ from each incoming direction&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/29/yihsF1.jpg&quot; alt=&quot;cg-9-13&quot; style=&quot;width:65%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

\[f_{r}\left(\omega_{i} \rightarrow \omega_{r}\right)=\frac{\mathrm{d} L_{r}\left(\omega_{r}\right)}{\mathrm{d} E_{i}\left(\omega_{i}\right)}=\frac{\mathrm{d} L_{r}\left(\omega_{r}\right)}{L_{i}\left(\omega_{i}\right) \cos \theta_{i} \mathrm{~d} \omega_{i}}\left[\frac{1}{\mathrm{sr}}\right]\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Conclusion&lt;/strong&gt;: The BRDF, the ratio of exitant radiance to incident irradiance, is to characterize the directional properties of how a surface reflects light, which is independent of the strength of the light.
    &lt;ul&gt;
      &lt;li&gt;In fact, we use &lt;em&gt;cosine irradiance collector&lt;/em&gt; to measure incident irradiance, &lt;em&gt;conical baffler&lt;/em&gt; to measure received radiance, and calculate the BRDF corresponding to the surface/texture by dividing the two. &lt;a href=&quot;https://www.zhihu.com/question/28476602/answer/41003204&quot;&gt;More info&lt;/a&gt;, and &lt;a href=&quot;/2020/12/20/cg-10.html#Measuring-BRDF&quot;&gt;later notes&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;In a word, BRDF describes how the light interacts with the object. Accordingly, BRDF describes the property of the texture.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The quantity is between zero and one for reasons of energy conservation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reflection-equation&quot;&gt;Reflection Equation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Consider BRDF only takes one direction of incident light, thus integral light (energy) from all directions of hemisphere will get the entire light source directing to the reflection point.
    &lt;ul&gt;
      &lt;li&gt;Understand in discrete way: traverse solid angles on the hemisphere, each incident solid angle will make contribution to the radiance of one specified direction. Sum these up will get the entire contribution, that is received energy.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[L_{r}\left(\mathrm{p}, \omega_{r}\right)=\int_{H^{2}} f_{r}\left(\mathrm{p}, \omega_{i} \rightarrow \omega_{r}\right) L_{i}\left(\mathrm{p}, \omega_{i}\right) \cos \theta_{i} \mathrm{~d} \omega_{i}\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/29/yihDoR.jpg&quot; alt=&quot;cg-9-14&quot; style=&quot;width:70%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Challenege&lt;/strong&gt;: recursion
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Reflected radiance&lt;/strong&gt; $L_{r}\left(\mathrm{p}, \omega_{r}\right)$ on the left hand depends on &lt;strong&gt;incoming radiance&lt;/strong&gt; $L_{i}\left(\mathrm{p}, \omega_{i}\right)$ on the right hand.&lt;/li&gt;
      &lt;li&gt;But &lt;strong&gt;incoming radiance&lt;/strong&gt; depends on reflected radiance at another point in the scene.
        &lt;ul&gt;
          &lt;li&gt;Incoming radiance is not limited to the light source, but reflected light etc.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rendering-equation&quot;&gt;Rendering Equation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Rewrite the reflection equation by adding an &lt;strong&gt;Emission term&lt;/strong&gt; $L_{e}\left(p, \omega_{o}\right)$ to make it general:&lt;/li&gt;
&lt;/ul&gt;

\[L_{o}\left(p, \omega_{o}\right)=L_{e}\left(p, \omega_{o}\right)+\int_{\Omega^{+}} L_{i}\left(p, \omega_{i}\right) f_{r}\left(p, \omega_{i}, \omega_{o}\right)\left(n \cdot \omega_{i}\right) \mathrm{d} \omega_{i}\]

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Caveat&lt;/strong&gt;: we assume that all directions are pointing &lt;strong&gt;outwards&lt;/strong&gt;, and field of integration is hemisphere, which is the reason for $\cos\theta$ replacing $max(\cos\theta, 0)$.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Volume rendering equation is a more general form of rendering equation.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The solution of renderings equation will be narrated in the &lt;a href=&quot;#path-tracing&quot;&gt;following part&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Understanding of the rendering equation&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;for the single light source&lt;/li&gt;
    &lt;/ul&gt;

\[\underset{\\ \quad \\ Reflected\ Light \\ (Output\ image)}{L_{r}\left(x, \omega_{r}\right)}= \underset{\\ \quad \\ Emission}{L_{e}\left(x, \omega_{r}\right)} + \underset{\\ \quad \\ Incident \ Light \\ (from\ light \\ source)}{L_{i}\left(x, \omega_{i}\right)} \underset{\\ \quad \\ BRDF}{f\left(x, \omega_{i}, \omega_{r}\right)} \underset{\\ \quad \\ Cosine\ of \\ Incident\ angle}{\left(\omega_{i}, n\right)}\]

    &lt;ul&gt;
      &lt;li&gt;for the multiple light sources&lt;/li&gt;
    &lt;/ul&gt;

\[\underset{\\ \quad \\ Reflected\ Light \\ (Output\ image)}{L_{r}\left(x, \omega_{r}\right)} = \underset{\\ \quad \\ Emission}{L_{e}\left(x, \omega_{r}\right)} + \sum \underset{\\ \quad \\ Incident \ Light \\ (from\ light \\ source)}{L_{i}\left(x, \omega_{i}\right)} \underset{\\ \quad \\ BRDF}{f\left(x, \omega_{i}, \omega_{r}\right)} \underset{\\ \quad \\ Cosine\ of \\ Incident\ angle}{\left(\omega_{i}, n\right)}\]

    &lt;ul&gt;
      &lt;li&gt;for the planar light sources&lt;/li&gt;
    &lt;/ul&gt;

\[\underset{\\ \quad \\ Reflected\ Light \\ (Output\ image)}{L_{r}\left(x, \omega_{r}\right)} = \underset{\\ \quad \\ Emission}{L_{e}\left(x, \omega_{r}\right)} + \int_\omega \underset{\\ \quad \\ Incident \ Light \\ (from\ light \\ source)}{L_{i}\left(x, \omega_{i}\right)} \underset{\\ \quad \\ BRDF}{f\left(x, \omega_{i}, \omega_{r}\right)} \underset{\\ \quad \\ Cosine\ of \\ Incident\ angle}{\cos \theta_i d\omega_i}\]

    &lt;ul&gt;
      &lt;li&gt;for the surfaces with reflected light (interreflection)&lt;/li&gt;
    &lt;/ul&gt;

\[\underset{\\ \quad \\ Reflected\ Light \\ (Output\ image) \\ \quad \color{red}{Unkown}}{L_{r}\left(x, \omega_{r}\right)} = \underset{\\ \quad \\ Emission \\ \color{blue}{Known}}{L_{e}\left(x, \omega_{r}\right)} + \int_\omega \underset{\\ \quad \\ Reflected\ light \\ from\ others \\ \quad \color{red}{Unkown}}{L_{r}\left(x^\prime, -\omega_i\right)} \underset{\\ \quad \\ BRDF \\ \color{blue}{Known}}{f\left(x, \omega_{i}, \omega_{r}\right)} \underset{\\ \quad \\ Cosine\ of \\ Incident\ angle \\ \color{blue}{Known}}{\cos \theta_i d\omega_i}\]

    &lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: $-\omega$ is because the light direction is pointing opposite of the incident direction with regards to $x^\prime$.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;which is the canonical form of &lt;a href=&quot;#fredholm-integral-equation&quot;&gt;Fredholm Integral Equation&lt;/a&gt; of second kind&lt;/li&gt;
    &lt;/ul&gt;

\[\underset{\\ \quad \\ Radiance \\ \color{red}{Unkown}}{\color{red}{I(u)}} = \underset{\\ \quad \\ Emission}{e(u)} + \int \underset{\\ \quad \\ Radiance\\ from\ others \\ \color{red}{Unkown}}{\color{red}{I(v)}} \underset{\\ \quad \\ \quad Kernel\ of\ equation \\ \quad Light\ Transport\ Operator}{\boxed{K(u, v)dv}}\]

    &lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Use substitution rule for integrals from the current object to the object of reflected light source will achieve $d\omega_i$ to $dv$, which will be detailed in &lt;a href=&quot;#solution-of-rendering-equation&quot;&gt;solution part&lt;/a&gt;.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;which can be discretized to a simple matrix equation or system of simultaneous linear equations, where $L,\ E$ are vectors, $K$ is the light transport matrix (&lt;strong&gt;reflection operator&lt;/strong&gt;)&lt;/li&gt;
    &lt;/ul&gt;

\[\color{red}{L} = E + K\color{red}{L}\]

    &lt;ul&gt;
      &lt;li&gt;rearrange terms and use taylor expassion&lt;/li&gt;
    &lt;/ul&gt;

\[\begin{aligned}\color{red}{L}&amp;amp;=E+K\color{red}{L} \\ I\color{red}{L}-K\color{red}{L} &amp;amp;= E \\ (I-K)\color{red}{L} &amp;amp;= E \\ \color{red}{L} &amp;amp;= (I-K)^{-1}E \\ \color{red}{L} &amp;amp;= (I + K + K^2 + K^3 + ...)E \\ \color{red}{L} &amp;amp;= E + KE + K^2E + K^3E + ...\end{aligned}\]

    &lt;ul&gt;
      &lt;li&gt;final form of ray tracing is&lt;/li&gt;
    &lt;/ul&gt;

\[L = \color{orange}{E + KE} + K^2E + K^3E + ...\]

    &lt;ul&gt;
      &lt;li&gt;understanding of the expression
        &lt;ul&gt;
          &lt;li&gt;$K$ : Reflection operator&lt;/li&gt;
          &lt;li&gt;$E$ : Emission directly from light sources&lt;/li&gt;
          &lt;li&gt;$KE$ : Direct illumination on surfaces&lt;/li&gt;
          &lt;li&gt;$K^2E$ : Indirect illumination (One bounce indirect, mirros, refraction)&lt;/li&gt;
          &lt;li&gt;$K^3E$ : Two bounce indirect illumination&lt;/li&gt;
          &lt;li&gt;$\color{orange}{E + KE}$: &lt;strong&gt;Direct illumination&lt;/strong&gt; is all the shading in &lt;em&gt;rasterization&lt;/em&gt; can do&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Global illumination&lt;/strong&gt;: the union of all direct and indirect light&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/06/yJ4T4e.jpg&quot; alt=&quot;cg-9-15&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The more bounce of illumination, the more realistic. When the bounce of illumination goes to infinity, the image finally becomes factual as in the real world.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/08/yUcPRs.gif&quot; alt=&quot;cg-9-16&quot; style=&quot;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;mathematics-foundation&quot;&gt;Mathematics Foundation&lt;/h2&gt;

&lt;h3 id=&quot;fredholm-integral-equation&quot;&gt;Fredholm Integral Equation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Equation of the first kind&lt;/p&gt;

\[g(t)=\int_{a}^{b} K(t, s) f(s) \mathrm{d} s\]

    &lt;ul&gt;
      &lt;li&gt;Given the continuous kernel function $K$ and the function $g$, to find the function $f$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Equation of the second kind&lt;/p&gt;

\[\varphi(t)=f(t)+\lambda \int_{a}^{b} K(t, s) \varphi(s) \mathrm{d} s\]

    &lt;ul&gt;
      &lt;li&gt;Given the kernel $K(t,s)$, and the function $f(t)$, the problem is typically to find the function $\varphi(t)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;linear-operator&quot;&gt;Linear Operator&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Operator&lt;/strong&gt;: generally a mapping or function acting on elements of a space to produce elements of another space.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Linear Operator&lt;/strong&gt; (kernel): $f$ is a linear&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;operator if it has two properties&lt;/p&gt;

\[f(x + y) = f(x) + f(y)\]

\[f(cx) = cf(x)\]
  &lt;/li&gt;
  &lt;li&gt;Thus, $f(ax+by) = af(x)+bf(y)$
    &lt;ul&gt;
      &lt;li&gt;If $M$ is a linear operator, $ab$ is constant, $fg$ is function&lt;/li&gt;
    &lt;/ul&gt;

\[M \bullet (af + bg) = a(M \bullet f) + b(M\bullet g)\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The most common examples of linear operators $K$ of differentiation and integration&lt;/p&gt;

\[(K \bullet f)(u)=\frac{\partial f}{\partial u}(u)\]

\[(K \bullet f)(u)=\int k(u, v) f(v) d v\]
  &lt;/li&gt;
  &lt;li&gt;Proof of Fredholm Integral Equation as linear operator
    &lt;ul&gt;
      &lt;li&gt;Want to show&lt;/li&gt;
    &lt;/ul&gt;

\[(K \bullet f)(u)=\int k(u, v) f(v) d v\]

    &lt;ul&gt;
      &lt;li&gt;Then need to verify the two properties of linear operator&lt;/li&gt;
    &lt;/ul&gt;

\[\begin{aligned} &amp;amp;M\bullet(af) = a(M\bullet f) \\ &amp;amp; M\bullet(f+g) = (M\bullet f) + (M \bullet g) \end{aligned}\]

    &lt;ul&gt;
      &lt;li&gt;Addition&lt;/li&gt;
    &lt;/ul&gt;

\[\begin{aligned} (K \bullet (f+g))(u) &amp;amp;= \int k(i, v)(f+g)(v)dv \\ &amp;amp;= \int k(i, v)(f(v) + g(v))dv \\ &amp;amp;= \int k(i, v)f(v)dv + \int k(i, v)g(v)dv \\ &amp;amp;= (K \bullet f) (u) + (K \bullet g) (v) \end{aligned}\]

    &lt;ul&gt;
      &lt;li&gt;Multiplication&lt;/li&gt;
    &lt;/ul&gt;

\[\begin{aligned} (K \bullet af)(u) &amp;amp;= \int k(i, v)(af)(v)dv \\ &amp;amp;= \int ak(i, v)f(v)dv \\ &amp;amp;= a \int k(i, v)f(v)dv \\ &amp;amp;= a(K \bullet f) (u) \end{aligned}\]
  &lt;/li&gt;
  &lt;li&gt;More info refer to &lt;a href=&quot;https://en.wikipedia.org/wiki/Functional_analysis&quot;&gt;functional analysis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;monte-carlo-intergration&quot;&gt;Monte Carlo Intergration&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;It is too difficult to solve an integral analytically.
    &lt;ul&gt;
      &lt;li&gt;Thus estimate the integral of a function by averaging random samples of the function’s value.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Different with &lt;a href=&quot;https://en.wikipedia.org/wiki/Riemann_integral&quot;&gt;Riemann integral&lt;/a&gt; which solve an integral analytically, &lt;a href=&quot;https://en.wikipedia.org/wiki/Monte_Carlo_integration&quot;&gt;Monte Carlo&lt;/a&gt; estimates the value of integration&lt;/li&gt;
  &lt;li&gt;Define the Monte Carlo estimnator for the definite integral of given function $f(x)$
    &lt;ul&gt;
      &lt;li&gt;Definite integral&lt;/li&gt;
    &lt;/ul&gt;

\[\int_{a}^{b} f(x) d x\]

    &lt;ul&gt;
      &lt;li&gt;Random variable, where $p(x)$ is &lt;em&gt;probability density function&lt;/em&gt; (&lt;em&gt;pdf&lt;/em&gt;)&lt;/li&gt;
    &lt;/ul&gt;

\[X_{i} \sim p(x)\]

    &lt;ul&gt;
      &lt;li&gt;MonteCarlo estimator&lt;/li&gt;
    &lt;/ul&gt;

\[F_{N}=\frac{1}{N} \sum_{i=1}^{N} \frac{f\left(X_{i}\right)}{p\left(X_{i}\right)}\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Monte Carlo Integration&lt;/p&gt;

\[\int f(x) dx = \frac{1}{N} \sum_{i=1}^{N} \frac{f\left(X_{i}\right)}{p\left(X_{i}\right)}\]

    &lt;ul&gt;
      &lt;li&gt;The more samples, the less variance&lt;/li&gt;
      &lt;li&gt;Sample on x, integrate on x&lt;/li&gt;
      &lt;li&gt;Don’t care about the domain of integration, but use numerical method sampling to estimate the value of integration&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;When the random variable distributes between $a$ and $b$ uniformly&lt;/li&gt;
&lt;/ul&gt;

\[X_{i} \sim p(x) = \frac{1}{b-a}\]

&lt;ul&gt;
  &lt;li&gt;Then the Basic Monte Carlo estimator will be&lt;/li&gt;
&lt;/ul&gt;

\[F_{N}=\frac{b-a}{N} \sum_{i=1}^{N} f\left(X_{i}\right)\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/08/yUcSIg.png&quot; alt=&quot;cg-9-17&quot; style=&quot;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;If we want to keep the sampling number but increase the estimation accurarcy, we should sample from a distribution of interest than the uniform distribution, that is &lt;a href=&quot;https://en.wikipedia.org/wiki/Importance_sampling&quot;&gt;Importance Sampling&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;path-tracing&quot;&gt;Path Tracing&lt;/h2&gt;

&lt;h3 id=&quot;whitted-style-problem&quot;&gt;Whitted-style problem&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Whitted-style ray tracing
    &lt;ul&gt;
      &lt;li&gt;Always perform specular reflections or refractions&lt;/li&gt;
      &lt;li&gt;Stop bouncing at diffuse surfaces&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;But these simplifications are not reasonable&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Whitted-style ray tracing can not deal with the glossy materials where the ray reflects not the same as the way on mirror material&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/08/yUcCGj.jpg&quot; alt=&quot;cg-9-18&quot; /&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Whitted-style ray tracing has no reflection between diffuse material&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/08/yUc9iQ.jpg&quot; alt=&quot;cg-9-19&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: In the left image of the above figure, the region that are not reached by direct illumination are shadowed in black, whereas the diffuse ambient actually illuminates the region. In the right image, the left side of rectangular is shaded in red, and right side of cubic is shaded in green, This phenomenon in which objects or surfaces are colored by reflection of colored light from nearby surfaces is called &lt;strong&gt;color bleeding&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;solution-of-rendering-equation&quot;&gt;Solution of rendering equation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The rendering equation to be solved&lt;/li&gt;
&lt;/ul&gt;

\[L_{o}\left(p, \omega_{o}\right)=L_{e}\left(p, \omega_{o}\right)+\int_{\Omega^{+}} L_{i}\left(p, \omega_{i}\right) f_{r}\left(p, \omega_{i}, \omega_{o}\right)\left(n \cdot \omega_{i}\right) \mathrm{d} \omega_{i}\]

&lt;ul&gt;
  &lt;li&gt;It involves two problems
    &lt;ul&gt;
      &lt;li&gt;Solve an integral over the hemisphere&lt;/li&gt;
      &lt;li&gt;Deal with recursion of $L_{i}\left(p, \omega_{i}\right)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;a-sample-monte-carlo-solution&quot;&gt;A Sample Monte Carlo Solution&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Suppose we want to render one pixel (point) in the following scene for &lt;strong&gt;direct illumination&lt;/strong&gt; only
    &lt;ul&gt;
      &lt;li&gt;No indirect reflection light is considered at this time&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[L_{o}\left(p, \omega_{o}\right)=\int_{\Omega^{+}} L_{i}\left(p, \omega_{i}\right) f_{r}\left(p, \omega_{i}, \omega_{o}\right)\left(n \cdot \omega_{i}\right) \mathrm{d} \omega_{i}\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/09/ydKcwT.jpg&quot; alt=&quot;cg-9-20&quot; style=&quot;width:50%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Use Monte Carlo method to solve this integration numerically&lt;/p&gt;

\[\int_{a}^{b} f(x) \mathrm{d} x \approx \frac{1}{N} \sum_{k=1}^{N} \frac{f\left(X_{k}\right)}{p\left(X_{k}\right)} \quad X_{k} \sim p(x)\]

    &lt;ul&gt;
      &lt;li&gt;$f(x)$: $L_{i}\left(p, \omega_{i}\right) f_{r}\left(p, \omega_{i}, \omega_{o}\right)\left(n \cdot \omega_{i}\right)$&lt;/li&gt;
      &lt;li&gt;$pdf$ (assume uniformly sampling the hemisphere): $pdf\left(\omega_{i}\right)=1 / 2 \pi$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Shading algorithm for direct illumination&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned} L_{o}\left(p, \omega_{o}\right) &amp;amp;=\int_{\Omega^{+}} L_{i}\left(p, \omega_{i}\right) f_{r}\left(p, \omega_{i}, \omega_{o}\right)\left(n \cdot \omega_{i}\right) \mathrm{d} \omega_{i} \\ &amp;amp; \approx \frac{1}{N} \sum_{i=1}^{N} \frac{L_{i}\left(p, \omega_{i}\right) f_{r}\left(p, \omega_{i}, \omega_{o}\right)\left(n \cdot \omega_{i}\right)}{pdf\left(\omega_{i}\right)} \end{aligned}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Randomly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;choose&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;directions&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Lo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Trace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;light&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;Lo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Lo&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;introducing-global-illumination&quot;&gt;Introducing Global Illumination&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;One more step forward: what if a ray hits an object
    &lt;ul&gt;
      &lt;li&gt;Point $Q$ also reflects light to $P$, and the amount of radiance is the amount of radiance of direct illumination at point $Q$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/09/ydlMYF.jpg&quot; alt=&quot;cg-9-21&quot; style=&quot;width:80%;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Randomly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;choose&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;directions&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Lo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Trace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;light&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;Lo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Add the following branch
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;an&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;Lo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# minus wi is due to the reversed direction of the light towards object p
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Lo&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;problem-1-number-explosion&quot;&gt;Problem 1: Number Explosion&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Explosion of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_rays&lt;/code&gt; as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_bounce&lt;/code&gt; goes up&lt;/li&gt;
&lt;/ul&gt;

\[num\_ray = N^{num\_bounce}\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/09/ydKDln.jpg&quot; alt=&quot;cg-9-22&quot; style=&quot;width:80%;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_ray&lt;/code&gt; will not explode if an only if $\color{red}{N = 1}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Path Tracing&lt;/strong&gt;: only &lt;strong&gt;1 ray&lt;/strong&gt; is traced at each shading point&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;#  modify N to One
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;Randomly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;choose&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;One&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;directions&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Trace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;light&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;an&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;info&lt;/strong&gt;: &lt;a href=&quot;https://en.wikipedia.org/wiki/Distributed_ray_tracing&quot;&gt;Distributed Ray Tracing&lt;/a&gt;: $ N != 1$&lt;/p&gt;

&lt;h4 id=&quot;ray-generation&quot;&gt;Ray Generation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;If the ray is only sampled once, the shaded point will be noisy!&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;BUT&lt;/strong&gt; it doesn’t matter, because just trace more &lt;strong&gt;paths&lt;/strong&gt; thorugh each pixel and average their radiance.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;The goal&lt;/strong&gt; is to render pixels of the image, instead of each points of objects in the scene.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/09/ydKBSs.jpg&quot; alt=&quot;cg-9-23&quot; style=&quot;width:70%;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;ray_generation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Uniformly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;choose&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;positions&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;within&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pixel&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pixel_radiance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pixel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;shoot&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cam_pos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;camera_to_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scene&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pixel_radiance&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;camera_to_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pixel_radiance&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;problem-2-infinite-recursion&quot;&gt;Problem 2: Infinite Recursion&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Dilemma: the light does not stop bouncing indeed in the real world&lt;/li&gt;
  &lt;li&gt;Further, cut &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;num_bounce&lt;/code&gt; is to cut &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;energy&lt;/code&gt; and reduce authenticity&lt;/li&gt;
  &lt;li&gt;Solution: Russian Roulette (RR)
    &lt;ul&gt;
      &lt;li&gt;With probability $ 0 \lt P \lt 1$, condition 1&lt;/li&gt;
      &lt;li&gt;With probablity $1 - P$, otherwise&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Previously, we always shoot a ray at a shading point and get the shading result $L_o$&lt;/li&gt;
  &lt;li&gt;Suppose we manually set a probability $P$
    &lt;ul&gt;
      &lt;li&gt;With probability $P$, shoot a ray and return the shading result &lt;strong&gt;divided by&lt;/strong&gt; $P$: $L_o / P$&lt;/li&gt;
      &lt;li&gt;With probablity $1-P$, don’t shoot a ray and you’ll get $0$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;In this way, you can still expect to get $L_o$&lt;/li&gt;
&lt;/ul&gt;

\[Expect = P * (L_o / P) + (1-P)* 0 = L_o\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Add the following branch
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;Manually&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;specify&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probability&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_RR&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Randomly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ksi&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distribution&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ksi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_RR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Randomly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;choose&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;One&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;directions&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Trace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;light&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_RR&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;an&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosine&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_RR&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Expected value of bounce number, given probability $p$&lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned}\sum_{n=1}^{+\infty} p^{n} &amp;amp;=\lim _{n \rightarrow+\infty} \frac{p(1-p^{n})}{1-p} \\ &amp;amp;=\frac{p}{1-p}\ (0 \lt p \lt 1) \end{aligned}\]

\[\begin{aligned} E &amp;amp;=\sum_{n=1}^{+\infty} n p(1-p)^{n-1} \\ &amp;amp;=p \sum_{n=1}^{+\infty} n(1-p)^{n-1} \\ &amp;amp;=-p\left(\sum_{n=1}^{+\infty} (1-p)^{n}\right)^{\prime} \\ &amp;amp;=-p\left(\frac{1-p}{p}\right)^{\prime} \\ &amp;amp;=-p \frac{-p-(1-p)}{p^{2}} \\ &amp;amp;=\frac{1}{p} \\ \end{aligned}\]

&lt;h3 id=&quot;sampling-the-light&quot;&gt;Sampling the Light&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Path tracing is correct but not efficient actually&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/09/ydQ0rq.jpg&quot; alt=&quot;cg-9-24&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The reason of being inefficient is the sampled 1 ray &lt;strong&gt;may not&lt;/strong&gt; hit the light, so that a lot of rays are wasted if we uniformly sample the hemisphere at the shading point&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/09/ydK6mV.jpg&quot; alt=&quot;cg-9-25&quot; style=&quot;width:80%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sampling on the shading point will lead to waste of rays which fail to hit the light source
    &lt;ul&gt;
      &lt;li&gt;Monte Carlo methods allows any sampling methods&lt;/li&gt;
      &lt;li&gt;Hence, change the sampling point to the light&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Assume uniformly sampling on the light&lt;/li&gt;
&lt;/ul&gt;

\[\int pdf \color{red}{dA} = 1\]

\[Hence,\ pdf = \frac{1}{A}\]

&lt;ul&gt;
  &lt;li&gt;The rendering equation integrates on &lt;strong&gt;the solid angle&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Recall Monte Carlo Integration: Sample on $x$, and integrate on $x$&lt;/li&gt;
      &lt;li&gt;Integral variable substitution&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[L_o = \int L_r f_BRDF \cos\theta \color{red}{d\omega}\]

&lt;ul&gt;
  &lt;li&gt;Make the rendering equation converting converting from an integral of $d\omega$ to $dA$.&lt;/li&gt;
  &lt;li&gt;The relationship between $d\omega$ and $dA$
    &lt;ul&gt;
      &lt;li&gt;The projected area towards $x^\primex$ at point $x^\prime$ is $d A \cos \theta^{\prime}$&lt;/li&gt;
      &lt;li&gt;Recall that $dS = R^2d\theta$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[d \omega=\frac{d A \cos \theta^{\prime}}{\left\|x^{\prime}-x\right\|^{2}}\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/09/ydKsO0.jpg&quot; alt=&quot;cg-9-26&quot; style=&quot;width:50%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;final-form-of-path-tracing&quot;&gt;Final Form of Path Tracing&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Rewrite the rendering equation as final form with an integral on $dA$&lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned} L_{o}\left(x, \omega_{o}\right) &amp;amp;=\int_{\Omega^{+}} L_{i}\left(x, \omega_{i}\right) f_{r}\left(x, \omega_{i}, \omega_{o}\right) \cos \theta \mathrm{d} \omega_{i} \\ &amp;amp;=\int_{A} L_{i}\left(x, \omega_{i}\right) f_{r}\left(x, \omega_{i}, \omega_{o}\right) \frac{\cos \theta \cos \theta^{\prime}}{\left\|x^{\prime}-x\right\|^{2}} \mathrm{~d} A \end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;Now integration is on the light, so for Monte Carlo integration:
    &lt;ul&gt;
      &lt;li&gt;$f(x)$ : $L_{i}\left(p, \omega_{i}\right) f_{r}\left(p, \omega_{i}, \omega_{o}\right) \frac{\cos \theta \cos \theta^{\prime}}{\left|x^{\prime}-x\right|^{2}}$&lt;/li&gt;
      &lt;li&gt;$pdf$ : $1 / A$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Previously, we assume the light is accidentally shot by uniform hemisphere sampling&lt;/li&gt;
  &lt;li&gt;Now we consider the radiance coming from two parts:
    &lt;ul&gt;
      &lt;li&gt;Light source (direct, no need to have RR), if the ray is &lt;strong&gt;not blocked&lt;/strong&gt; in the middle&lt;/li&gt;
      &lt;li&gt;Other reflectors (indirect, need to have RR)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/09/ydKRkF.jpg&quot; alt=&quot;cg-9-27&quot; style=&quot;width:70%;margin:auto;display:block;&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Contribution from the light source
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;Uniformly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;light&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' (pdf_light = 1 / A)
    L_dir = 0.0
    Shoot a ray from p to x'&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blocked&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;middle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;L_dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Li&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosθ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosθ&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' / |x'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;|^&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pdf_light&lt;/span&gt;

    &lt;span class=&quot;c1&quot;&gt;# Contribution from other reflections
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;## Test RR
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;Manually&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;specify&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;probability&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_RR&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Randomly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;select&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ksi&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;distribution&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ksi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_RR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_dir&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;## Ray Travce
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;L_indir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Uniformly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hemisphere&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;toward&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf_hemi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Trace&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;non&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emitting&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;L_indir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shade&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cosθ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pdf_hemi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p_RR&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_dir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L_indir&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Path tracing is almost 100% correct, a.k.a &lt;strong&gt;Photo-realistic&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/02/09/ydKgTU.jpg&quot; alt=&quot;cg-9-28&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;summary--future-work&quot;&gt;Summary &amp;amp; Future work&lt;/h2&gt;

&lt;h3 id=&quot;summary&quot;&gt;Summary&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Ray tracing: Previous vs. Modern Concepts
    &lt;ul&gt;
      &lt;li&gt;Previous: Ray tracing == Whitted-style ray tracing&lt;/li&gt;
      &lt;li&gt;Modern
        &lt;ul&gt;
          &lt;li&gt;The general solution of light transport, including:&lt;/li&gt;
          &lt;li&gt;(Unidirectional or Bidirectional) Path tracing&lt;/li&gt;
          &lt;li&gt;Photon mapping&lt;/li&gt;
          &lt;li&gt;Metropolis light transport&lt;/li&gt;
          &lt;li&gt;VCM / UPBP …&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;future-work&quot;&gt;Future work&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Uniformly sampling the hemisphere
    &lt;ul&gt;
      &lt;li&gt;How? and in general, how to sample any function? (sampling theory)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Monte Carlo integration allows arbitrary $pdf$
    &lt;ul&gt;
      &lt;li&gt;Instead of uniform sampling, what’s the best choice of sampling with regards to different shapes of function? (importance sampling)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Do random numbers matter?
    &lt;ul&gt;
      &lt;li&gt;Yes! (low discrepancy sequences)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;I can sample the hemisphere and the light
    &lt;ul&gt;
      &lt;li&gt;Can I combine them? Yes! (multiple importance sampling)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The radiance of a pixel is the averange of radiance on all paths passing through it
    &lt;ul&gt;
      &lt;li&gt;Why? If different weighted sampling at the center of pixel or the edge is needed? (pixel reconstruction filter)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Is the radiance of a pixel the color of a pixel?
    &lt;ul&gt;
      &lt;li&gt;No. (gamma correction, curves concerning high dynamic range (HDR) image , color space, photography)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/21376124&quot;&gt;基于物理着色：BRDF&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/leonwei/article/details/44539217&quot;&gt;物理渲染(PBR)-基于物理的光照模型&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/28476602/answer/41003204&quot;&gt;BRDF单位为sr^-1的原因&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://web.cs.wpi.edu/~emmanuel/courses/cs563/write_ups/chuckm/chuckm_BRDFs_overview.html&quot;&gt;Bi-Directional Reflectance Distribution Functions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.qiujiawei.com/monte-carlo/&quot;&gt;蒙特·卡罗积分&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/146144853&quot;&gt;蒙特卡洛积分概述&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.twistedwg.com/2018/05/29/MC-integral.html&quot;&gt;蒙特卡洛（Monte Carlo）法求定积分&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/56443239&quot;&gt;Rendering Equation求解&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">Advanced Ray Tracing, Radiometry, BRDF, Path Tracing</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅷ</title><link href="https://harrypotterrrr.github.io//2020/11/25/cg-8.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅷ" /><published>2020-11-25T00:00:00+08:00</published><updated>2020-11-25T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/11/25/cg-8</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/11/25/cg-8.html">&lt;p&gt;Whitted Style Ray Tracing, Ray-Surface Intersection, Acceleration of Ray Tracing, Ray-Intersection with AABB, KD-Tree, BVH&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;ray-tracing&quot;&gt;Ray Tracing&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Rasterization can not handle &lt;strong&gt;global effect&lt;/strong&gt; well
    &lt;ul&gt;
      &lt;li&gt;Soft shadows&lt;/li&gt;
      &lt;li&gt;Glossy reflection, transparent / subtransparent object&lt;/li&gt;
      &lt;li&gt;Indirect illumination when light bounces more than once&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Ray tracing is accurate, but is very slow
    &lt;ul&gt;
      &lt;li&gt;Rasterization: real time, Ray tracing: offline&lt;/li&gt;
      &lt;li&gt;Time estimation: ~10K CPU core hours to render one frame in video production&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;light-rays&quot;&gt;Light Rays&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Three ideas about light rays:
    &lt;ul&gt;
      &lt;li&gt;Light travels in straight lines, though this is wrong because light is a wave which has volatility.&lt;/li&gt;
      &lt;li&gt;Light rays do not collide with each other if they cross, though this is still not wrong.&lt;/li&gt;
      &lt;li&gt;Light rays travel from the light sources to the eye, and the reciprocity of the light means the physics is invariant under path reversal.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ray-casting&quot;&gt;Ray Casting&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Pinhole Camera Model&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generate an image by casting one ray per pixel&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/17/sr6ECR.jpg&quot; alt=&quot;cg-8-1&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Check for shadows by sending a ray to the light&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/17/sr6FUJ.jpg&quot; alt=&quot;cg-8-2&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Whitted-Style Ray Tracing&lt;/strong&gt;: &lt;strong&gt;Recursive&lt;/strong&gt; Ray Tracing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/17/sr6k59.gif&quot; alt=&quot;cg-8-3&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Key idea&lt;/strong&gt;: ray tracing is to simulate the ray casting&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ray-surface-intersection&quot;&gt;Ray-Surface Intersection&lt;/h3&gt;

&lt;h4 id=&quot;ray-equation&quot;&gt;Ray Equation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Ray is defined by its origin and a direction vector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/17/sr6iE4.jpg&quot; alt=&quot;cg-8-4&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ray equation $\boldsymbol{r}(t) = \boldsymbol{o} + t\boldsymbol{d}$ where, $0 \leq t &amp;lt; \infty$
    &lt;ul&gt;
      &lt;li&gt;$o$: origin point&lt;/li&gt;
      &lt;li&gt;$d$: &lt;strong&gt;normalized&lt;/strong&gt; direction of the ray&lt;/li&gt;
      &lt;li&gt;$r(t)$: point along the ray&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;intersect-with-sphere&quot;&gt;Intersect with Sphere&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Ray: $\boldsymbol{r}(t) = \boldsymbol{o} + t\boldsymbol{d}, 0 \leq t &amp;lt; \infty$&lt;/li&gt;
  &lt;li&gt;Sphere: $ \boldsymbol{p}:\ (\boldsymbol{p}-\boldsymbol{c})^2-R^2 = 0$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/17/sr6CbF.jpg&quot; alt=&quot;cg-8-5&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The intersection $p$ must satisfy both ray equation and sphere equation&lt;/li&gt;
  &lt;li&gt;Intersection: $ (\boldsymbol{o}+ t\boldsymbol{d}-\boldsymbol{c})^2-R^2 = 0$&lt;/li&gt;
&lt;/ul&gt;

\[a t^{2}+b t+c=0,\ where\]

\[\left\{\begin{aligned} a=&amp;amp;\mathrm{d} \cdot \mathrm{d} \\
b=&amp;amp;2(\mathbf{o}-\mathbf{c}) \cdot \mathrm{d} \\
c=&amp;amp;(\mathbf{o}-\mathbf{c}) \cdot(\mathbf{o}-\mathbf{c})-R^{2}\end{aligned}\right.\]

\[t=\frac{-b \pm \sqrt{b^{2}-4 a c}}{2 a}\]

&lt;ul&gt;
  &lt;li&gt;Ray intersects with sphere if only if $\varDelta \ge 0$ &lt;strong&gt;and&lt;/strong&gt; $t \ge 0$, otherwise no intersection.&lt;/li&gt;
  &lt;li&gt;Given the solved $t$, intersection is $\boldsymbol{o} + t\boldsymbol{d}$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;intersect-with-implicit-surface&quot;&gt;Intersect With Implicit Surface&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Ray: $\boldsymbol{r}(t) = \boldsymbol{o} + t\boldsymbol{d}$, where $0 \leq t &amp;lt; \infty$&lt;/li&gt;
  &lt;li&gt;General implicit surface: $\boldsymbol{p}: f(\boldsymbol{p}) = 0$&lt;/li&gt;
  &lt;li&gt;Substitute ray equation: $f(\boldsymbol{o}+t\boldsymbol{d}) = 0$&lt;/li&gt;
  &lt;li&gt;Solve for real, positive roots of $t$&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: we usually don’t care about how to solve the equation, because numerical optimization will always help us to find an approximate solution of the problem corresponding to the given equation of implicit surface.&lt;/p&gt;

&lt;h4 id=&quot;plane-equation&quot;&gt;Plane Equation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Plane is defined by normal vector and a point on plane&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/s6F3Y6.jpg&quot; alt=&quot;cg-8-6&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Plane Equation: $\boldsymbol{p}: (\boldsymbol{p}-\boldsymbol{p^\prime}) \cdot \boldsymbol{N}=0$
    &lt;ul&gt;
      &lt;li&gt;$p$: all points on plane&lt;/li&gt;
      &lt;li&gt;$p^\prime$: one point on plane&lt;/li&gt;
      &lt;li&gt;$N$: normal vector&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Expland the plane equation will get Plane Equation in Cartesian coordinates: $ax + by + cz + d = 0$&lt;/li&gt;
  &lt;li&gt;Solve for intersection
    &lt;ul&gt;
      &lt;li&gt;Set $\boldsymbol{p} = \boldsymbol{r}(t)$ and solve for $t$&lt;/li&gt;
      &lt;li&gt;Check if $0 \leq t&amp;lt;\infty$ intersection inside the plane, otherwise not.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\left(\mathbf{p}-\mathbf{p}^{\prime}\right) \cdot \mathbf{N}=\left(\mathbf{o}+t \mathbf{d}-\mathbf{p}^{\prime}\right) \cdot \mathbf{N}=0\]

\[t=\frac{\left(\mathbf{p}^{\prime}-\mathbf{o}\right) \cdot \mathbf{N}}{\mathbf{d} \cdot \mathbf{N}} \quad\]

&lt;ul&gt;
  &lt;li&gt;After get the $t$ and intersection with the plane, check if the intersection is inside triangle
    &lt;ul&gt;
      &lt;li&gt;Use three &lt;a href=&quot;/2020/08/11/cg-2#cross-product&quot;&gt;cross product&lt;/a&gt; and check if the results are all in the same direction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;intersect-with-triangle-mesh&quot;&gt;Intersect with Triangle Mesh&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Usage: visiblity, shadows, lighting …&lt;/li&gt;
  &lt;li&gt;Geometry: inside / outside test&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Point in Polygon test is: given a point $p$ and a polygon $Q$, draw a line from the query point $p$ to other point far away in the plane, which should be outside $Q$, then count the number of intersection of this ray with $Q$. If odd number of intersections, the point $p$ is inside polygon $Q$, otherwise outside.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/s6F8fK.jpg&quot; alt=&quot;cg-8-7&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Idea: just intersect ray with each triangle&lt;/li&gt;
  &lt;li&gt;Simple, but very slow since for each resolution pixel of the screen will cast a ray and do intersection test with each triangle in mesh&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Only care 0, 1 intersection, ignore multiple edge cases&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Triangle is in a plane
    &lt;ul&gt;
      &lt;li&gt;Ray-plane intersection&lt;/li&gt;
      &lt;li&gt;Test if hit point is inside triangle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Möller Trumbore Algorithm&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Given barycentric coordinate of triangle, a faster and direct approach to calculate intersection&lt;/li&gt;
      &lt;li&gt;Use &lt;a href=&quot;https://en.wikipedia.org/wiki/Cramer's_rule&quot;&gt;Cramer’s rule&lt;/a&gt; to solve for system of linear equations&lt;/li&gt;
      &lt;li&gt;The proof can be found &lt;a href=&quot;https://www.scratchapixel.com/lessons/3d-basic-rendering/ray-tracing-rendering-a-triangle/moller-trumbore-ray-triangle-intersection&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\overrightarrow{\mathbf{o}}+t \overrightarrow{\mathbf{d}}=\left(1-b_{1}-b_{2}\right) \overrightarrow{\mathbf{P}}_{0}+b_{1} \overrightarrow{\mathbf{P}}_{1}+b_{2} \overrightarrow{\mathbf{P}}_{2}\]

\[\left[\begin{array}{l}t \\ b_{1} \\ b_{2}\end{array}\right]=\frac{1}{\overrightarrow{\mathbf{S}}_{1} \cdot \overrightarrow{\mathbf{E}}_{1}}\left[\begin{array}{c}\overrightarrow{\mathbf{S}}_{2} \cdot \overrightarrow{\mathbf{E}}_{2} \\ \overrightarrow{\mathbf{S}}_{1} \cdot \overrightarrow{\mathbf{S}} \\ \overrightarrow{\mathbf{S}}_{2} \cdot \overrightarrow{\mathbf{d}}\end{array}\right]\]

\[where\ \left\{\begin{aligned}
\overrightarrow{\mathbf{E}}_{1}=\overrightarrow{\mathbf{P}}_{1}-\overrightarrow{\mathbf{P}}_{0} \\
\overrightarrow{\mathbf{E}}_{2}=\overrightarrow{\mathbf{P}}_{2}-\overrightarrow{\mathbf{P}}_{0} \\
\overrightarrow{\mathbf{S}}=\overrightarrow{\mathbf{o}}-\overrightarrow{\mathbf{P}}_{0} \\
\overrightarrow{\mathbf{S}}_{1}=\overrightarrow{\mathbf{d}} \times \overrightarrow{\mathbf{E}}_{2} \\
\overrightarrow{\mathbf{S}}_{2}=\overrightarrow{\mathbf{S}} \times \overrightarrow{\mathbf{E}}_{1}
\end{aligned}\right.\]

&lt;ul&gt;
  &lt;li&gt;After get $t$, $b_1$,\ $b_2$
    &lt;ul&gt;
      &lt;li&gt;Check if $t \ge 0$ then the intersection is in the plane, otherwise not&lt;/li&gt;
      &lt;li&gt;Check if $0 \le b_1,\ b_2,\ 1-b_1-b_2 \le 1$ then the intersection is &lt;a href=&quot;/2020/09/07/cg-6#barycentric-coordinate&quot;&gt;inside triangle&lt;/a&gt;, otherwise not&lt;/li&gt;
      &lt;li&gt;If &lt;strong&gt;both&lt;/strong&gt; conditions are satisfied, the ray does intersect with the triangle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;acceleration&quot;&gt;Acceleration&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Simple ray-scene intersection
    &lt;ul&gt;
      &lt;li&gt;Exhaustively test ray-intersection with every triangle&lt;/li&gt;
      &lt;li&gt;Find the closest hit&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Problem
    &lt;ul&gt;
      &lt;li&gt;Naive algorithm = num_pixels x num_triangles x num_bounces&lt;/li&gt;
      &lt;li&gt;Very slow&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;bounding-volumes&quot;&gt;Bounding Volumes&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Quick way to avoid intersections: bound complex object with a simple volume
    &lt;ul&gt;
      &lt;li&gt;Object is fully contained in the volume&lt;/li&gt;
      &lt;li&gt;If it doesn’t hit the volume, it doesn’t hit the object&lt;/li&gt;
      &lt;li&gt;Thus, test bounding volume first, then test object if it hits&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/s6F1Fx.jpg&quot; alt=&quot;cg-8-8&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;ray-intersection-with-box&quot;&gt;Ray-Intersection With Box&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Box is the intersection of 3 pairs of slabs&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Axis-Aligned Bounding Box&lt;/strong&gt; (&lt;strong&gt;AABB&lt;/strong&gt;): the smallest enclosing box with any side along either x, y, z axis.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/s6FQT1.jpg&quot; alt=&quot;cg-8-9&quot; width=&quot;40%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;‘Axis-Aligned’ is to reduce computational time
    &lt;ul&gt;
      &lt;li&gt;For the general plane, 3 subtractions, 6 multiplies, 1 division required&lt;br /&gt;
\(t=\frac{\left(\mathbf{p}^{\prime}-\mathbf{o}\right) \cdot \mathbf{N}}{\mathbf{d} \cdot \mathbf{N}} \quad\)&lt;/li&gt;
      &lt;li&gt;For slabs perpendicular to x-axis, only 1 subtraction, 1 division required&lt;br /&gt;
\(t=\frac{\mathbf{p}^\prime_x - \mathbf{o}_x}{\mathbf{d}_x}\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scEUqe.jpg&quot; alt=&quot;cg-8-12&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;intersect-with-2d-aabb&quot;&gt;Intersect with 2D AABB&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;2D example of computing intersections with slabs and take &lt;strong&gt;intersection&lt;/strong&gt; of $t_{min}/ t_{max}$ intervals&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scEdVH.jpg&quot; alt=&quot;cg-8-10&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;intersect-with-3d-aabb&quot;&gt;Intersect with 3D AABB&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;A box in 3D = three pairs of infinitely large slabs&lt;/li&gt;
  &lt;li&gt;Key ideas
    &lt;ul&gt;
      &lt;li&gt;The ray enters the box &lt;strong&gt;only when&lt;/strong&gt; it enters all pairs of slabs&lt;/li&gt;
      &lt;li&gt;The ray exits the box &lt;strong&gt;as long as&lt;/strong&gt; it exits any pair of slabs&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;For each pair, calculate the $t_{min}$ and $t_{max}$. &lt;strong&gt;Negative&lt;/strong&gt; is fine and will be discussed later&lt;/li&gt;
  &lt;li&gt;For the 3D box, $t_{enter} = max \{ t_{min} \}$, $t_{exit} = min \{ t_{max} \} $&lt;/li&gt;
  &lt;li&gt;If $t_{enter} \lt t_{exit}$, we know the ray stays a while in the box, thus ray must intersect with bounding box. But this is &lt;strong&gt;NOT&lt;/strong&gt; absolutely correct!
    &lt;ul&gt;
      &lt;li&gt;e.g. the following ray won’t intersect with the bounding box&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/s6FJSO.jpg&quot; alt=&quot;cg-8-11&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Problem: what about the $t$ is negative?&lt;/li&gt;
  &lt;li&gt;Ray is not a line, but a ray
    &lt;ul&gt;
      &lt;li&gt;Should check whether $t$ is negative for physical correctness&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What if $t_{exit} \lt 0$
    &lt;ul&gt;
      &lt;li&gt;The box is behind the ray: no intersection&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What if $t_{exit} \ge 0$ and $t_{enter} \lt 0$
    &lt;ul&gt;
      &lt;li&gt;The ray’s origin is inside the box: have intersection&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;In summary, ray and AABB intersect if and only if
    &lt;ul&gt;
      &lt;li&gt;$t_{enter} \lt t_{exit} 0\ \&amp;amp;\&amp;amp;\ t_{exit} \ge 0$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;uniform-spatial-partitions&quot;&gt;Uniform Spatial Partitions&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Preprocess to build acceleration grid
    &lt;ul&gt;
      &lt;li&gt;Find bounding box&lt;/li&gt;
      &lt;li&gt;Create grid&lt;/li&gt;
      &lt;li&gt;Store each object in overlapping cells (test if the object’s surface intersects with cells)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scEtKO.jpg&quot; alt=&quot;cg-8-13&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ray Scene Intersection
    &lt;ul&gt;
      &lt;li&gt;Step through grid in ray traversal order&lt;/li&gt;
      &lt;li&gt;For each grid cell
        &lt;ul&gt;
          &lt;li&gt;Test intersection with all objects stored at that cell&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scENrD.jpg&quot; alt=&quot;cg-8-14&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Grid resolution should not be too small nor too large
    &lt;ul&gt;
      &lt;li&gt;One cell: no speedup&lt;/li&gt;
      &lt;li&gt;Many cells: infficiency due to extraneous grid traversal&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Heuristic experience
    &lt;ul&gt;
      &lt;li&gt;num_cells = Const * num_objs&lt;/li&gt;
      &lt;li&gt;Const ≈ 27 in 3D&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scEJxK.jpg&quot; alt=&quot;cg-8-15&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Uniform Grids’ Problem
    &lt;ul&gt;
      &lt;li&gt;Work well on large collections of objects that are distributed evenly in size and space&lt;/li&gt;
      &lt;li&gt;But fail on the scene where large ratio of space is empty with no objects or the objects are not evenly distributed, i.e. “Teapot in a stadium” problem&lt;/li&gt;
      &lt;li&gt;Spatial Partition to solve this problem!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scE0IA.jpg&quot; alt=&quot;cg-8-16&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;spatial-partitions&quot;&gt;Spatial Partitions&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Partition the 3D space using plane
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Oct-Tree&lt;/strong&gt;: Recursively partition the space into 8 subspace until specified condition, e.g. the new splitted cells are empty with no objects&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;KD-Tree&lt;/strong&gt; (short for k-dimensional tree): Alternatively use xy-plane, yz-plane, xz-plane to divide objects into different space&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;BSP-Tree&lt;/strong&gt; (short for binary space partitioning tree): More general case of KD-Tree. Recursively subdividing a space into two subspace&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scEyxf.jpg&quot; alt=&quot;cg-8-17&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Data Structure for KD-Tree
    &lt;ul&gt;
      &lt;li&gt;Internal Nodes store
        &lt;ul&gt;
          &lt;li&gt;split axis: x-, y-, or z-axis&lt;/li&gt;
          &lt;li&gt;split position: coordinate of split plane along axis&lt;/li&gt;
          &lt;li&gt;children: pointers to child nodes&lt;/li&gt;
          &lt;li&gt;&lt;strong&gt;No objects&lt;/strong&gt; are stored in internal nodes&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Leaf nodes store
        &lt;ul&gt;
          &lt;li&gt;list of objects&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scEwad.gif&quot; alt=&quot;cg-8-18&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Traversing a KD-Tree&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scZipq.gif&quot; alt=&quot;cg-8-19&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Problem existed in KD-Tree method
    &lt;ul&gt;
      &lt;li&gt;Computing the overlap between triangle and AABB to build KD-Tree is difficult, though intersection algorithm exist, detailed &lt;a href=&quot;https://fileadmin.cs.lth.se/cs/Personal/Tomas_Akenine-Moller/code/&quot;&gt;here&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;One objects can be included in multiple cells&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;object-partitions&quot;&gt;Object Partitions&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Bounding Volume Hierarchy&lt;/strong&gt; (BVH): tree structure on a set of geometric objects, which are wrapped in bounding volumes
    &lt;ul&gt;
      &lt;li&gt;Find bounding box&lt;/li&gt;
      &lt;li&gt;Recursively split set of objects in two subsets&lt;/li&gt;
      &lt;li&gt;Recompute the bounding box of the subsets&lt;/li&gt;
      &lt;li&gt;Stop when necessary&lt;/li&gt;
      &lt;li&gt;Store objects in each leaf node&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scEsRP.gif&quot; alt=&quot;cg-8-20&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The problem existed in KD-Tree are solved
    &lt;ul&gt;
      &lt;li&gt;No need to compute the overlap because overlap doesn’t influence, but precompute the bounding box which may overlap one another&lt;/li&gt;
      &lt;li&gt;One object only exist in one node&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;BVH is the preprocess to accelerate unnecessary computation before ray tracing and shading, but for each time the objects move or displace to somewhere else, BVH will be built once again &lt;strong&gt;for each frame&lt;/strong&gt;. Thus, Real-time ray tracing is great difficult.
    &lt;ul&gt;
      &lt;li&gt;Thus it is hard for real-time ray tracing to deal with shape deformation and position transformation, since it is great time-costly to build accelerating structure&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Strategy to subdivide a node to build BVH
    &lt;ul&gt;
      &lt;li&gt;Choose a dimension to split: Always choose the longest axis in node, especially when objects in elongated bounding box&lt;/li&gt;
      &lt;li&gt;Choose split position: Split node at location of &lt;strong&gt;median&lt;/strong&gt; object, which is beneficial to build a more &lt;strong&gt;balanced&lt;/strong&gt; tree with more evenly depth of two side.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Termination criteria: stop when node contains few elements (e.g. heuristically 5)&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Choosing split position of median object can be implement by sorting the barycentric of each triangle and select the median one, which take $O(nlog(n))$ time. While &lt;a href=&quot;https://en.wikipedia.org/wiki/Selection_algorithm&quot;&gt;quick selection algorithm&lt;/a&gt; for finding the kth smallest value can optimize the consuming complexity to $O(n)$.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Data Structure for KD-Tree
    &lt;ul&gt;
      &lt;li&gt;Internal nodes store
        &lt;ul&gt;
          &lt;li&gt;Bounding box&lt;/li&gt;
          &lt;li&gt;Children: pointers to child nodes&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Leaf nodes store
        &lt;ul&gt;
          &lt;li&gt;Bounding box&lt;/li&gt;
          &lt;li&gt;List of objects&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Traversing BVH&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Intersect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BVH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;misses&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bbox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;leaf&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;test&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intersection&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objects&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;closest&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;intersection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hit1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Intersect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hit2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Intersect&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;closer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;of&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// ATTENTION: closer hit point is returned!&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scErGt.jpg&quot; alt=&quot;cg-8-21&quot; width=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;spatial-vs-object-partitions&quot;&gt;Spatial vs Object Partitions&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Spatial partition (e.g. KD-Tree)
    &lt;ul&gt;
      &lt;li&gt;Partition space into non-overlapping regions&lt;/li&gt;
      &lt;li&gt;Object can be contained in multiple regions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Object partition (e.g. BVH)
    &lt;ul&gt;
      &lt;li&gt;Partition set of objects into disjoint subsets&lt;/li&gt;
      &lt;li&gt;Bounding boxes for each set may overlap in space&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/18/scEcM8.jpg&quot; alt=&quot;cg-8-22&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://fileadmin.cs.lth.se/cs/Personal/Tomas_Akenine-Moller/code/&quot;&gt;Triangle-Box Overlap Test, Tomas Akenine-Möller&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Selection_algorithm&quot;&gt;Selection problem&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">Whitted Style Ray Tracing, Ray-Surface Intersection, Acceleration of Ray Tracing, Ray-Intersection with AABB, KD-Tree, BVH</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅶ</title><link href="https://harrypotterrrr.github.io//2020/11/19/cg-7.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅶ" /><published>2020-11-19T00:00:00+08:00</published><updated>2020-11-19T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/11/19/cg-7</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/11/19/cg-7.html">&lt;p&gt;Geometry, Implicit &amp;amp; Explicit Geometry, Curve, Surface, Subdivision, Mesh Simplification&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;geometry&quot;&gt;Geometry&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Implicit Geometry
    &lt;ul&gt;
      &lt;li&gt;algebraic surface&lt;/li&gt;
      &lt;li&gt;level sets&lt;/li&gt;
      &lt;li&gt;distance functions&lt;/li&gt;
      &lt;li&gt;…&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Explicit Geometry
    &lt;ul&gt;
      &lt;li&gt;point cloud&lt;/li&gt;
      &lt;li&gt;polygon mesh&lt;/li&gt;
      &lt;li&gt;subdivision, NURBS&lt;/li&gt;
      &lt;li&gt;…&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Each choice best suited to a different task/type of geometry&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;implicit-representations-of-geometry&quot;&gt;Implicit Representations of Geometry&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Based on classifying points: Points satisfy some specified relationship, without given coordinate
    &lt;ul&gt;
      &lt;li&gt;E.g. sphere: all points in 3D, where $x^2+y^2+z^2=1$&lt;/li&gt;
      &lt;li&gt;More generally, $f(x, y, z) = 0$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Take $f(x, y, z)=\left(2-\sqrt{x^{2}+y^{2}}\right)^{2}+z^{2}-1$ as an example:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Implicit Surface sampling can be hard
    &lt;ul&gt;
      &lt;li&gt;What points lie on $f(x, y, z) = 0$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJNoff.jpg&quot; alt=&quot;cg-7-1&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Take $f(x, y, z)=x^{2}+y^{2}+z^{2}-1$ as an example:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Implicit Surface inside/outside test is easy
    &lt;ul&gt;
      &lt;li&gt;Is $(3/4, 1/2, 1/4)$ inside the sphere?&lt;/li&gt;
      &lt;li&gt;Just plug it in $f(x, y, z) = -1/8 &amp;lt; 0$, so Inside&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;implicit-geometry&quot;&gt;Implicit Geometry&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Implicit Algebraic Surfaces&lt;/li&gt;
  &lt;li&gt;Constructive solid geometry&lt;/li&gt;
  &lt;li&gt;Level set methods&lt;/li&gt;
  &lt;li&gt;Fractals&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;algebraic-surfaces&quot;&gt;Algebraic Surfaces&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Surface is zero set of a polynomial in x, y, z&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJNhTI.jpg&quot; alt=&quot;cg-7-3&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;But how about using polynomial to represent a more complext object as a cow?&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;constructive-solid-geometry&quot;&gt;Constructive Solid Geometry&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Constructive Solid Geometry&lt;/strong&gt; (&lt;strong&gt;CSG&lt;/strong&gt;): Combine implicit geometry via Boolean operations&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJNf0A.jpg&quot; alt=&quot;cg-7-4&quot; width=&quot;700px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use CSG and operation to define complex geometry&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJNWmd.png&quot; alt=&quot;cg-7-5&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;distance-functions&quot;&gt;Distance Functions&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Signed Distance Functions&lt;/strong&gt; (&lt;strong&gt;SDF&lt;/strong&gt;): determines the distance of a given point $x$ from the boundary of $\omega$. The function has positive values at points $x$ outside $\omega$, it decreases in value as $x$ approches the boundary of $\omega$ where the signed distance function is zero.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Instead of Booleans, gradually blend surfaces together using Distance functions:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Give minimum distance (could be signed distance) from anywhere to object&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJNItP.jpg&quot; alt=&quot;cg-7-6&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;An Example: Blending (linear interp.) a moving boundary
    &lt;ul&gt;
      &lt;li&gt;The above row describes the normal blending of A and B region, which results A overlaps B&lt;/li&gt;
      &lt;li&gt;The below row describes the blending using SDF, similar to superposition of the electric field of two same point charges, which results the zero plane right in the middle of A and B&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJNH1S.jpg&quot; alt=&quot;cg-7-7&quot; width=&quot;550px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Blending any two distance functions: every point in the space can be represented as distance function, blending of two objects in the space is to sum up two distance functions. The boundary forms when the distance function is 0&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;More details about &lt;a href=&quot;https://www.youtube.com/watch?v=Cp5WWtMoeKg&quot;&gt;distance function&lt;/a&gt;, &lt;a href=&quot;https://www.iquilezles.org/www/articles/distfunctions/distfunctions.htm&quot;&gt;SDF code about various primitives&lt;/a&gt; and &lt;a href=&quot;https://www.iquilezles.org/www/index.htm&quot;&gt;useful tutorial&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;level-set-methods&quot;&gt;Level Set Methods&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;For Distance Function method, closed-form equations (解析式) are sometimes hard to describe complex shapes.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Level Set Methods&lt;/strong&gt; performs numerical computations involving curves and surfaces on a fixed Cardesian grid without having to &lt;strong&gt;parameterize&lt;/strong&gt; objects.
    &lt;ul&gt;
      &lt;li&gt;Level Set Methods is to store a grid of values approximating function.&lt;/li&gt;
      &lt;li&gt;The central idea is same to SDF: find the boundary where the value is 0.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJN7p8.jpg&quot; alt=&quot;cg-7-8&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Surface is found where interpolated values equal zero&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Provides much more explicit control over shape (like a texture)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Level set encodes distance to air-liquid boundary to simulate physical scene of water dropping, constant tissue density to image medical data like CT, MRI etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;fractal&quot;&gt;Fractal&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Self-similarity, detail at all scales&lt;/li&gt;
  &lt;li&gt;Hard to control shape&lt;/li&gt;
  &lt;li&gt;Sometimes cause the drastic aliasing due to the high frequency of variation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJNb6g.jpg&quot; alt=&quot;cg-7-9&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;pros--cons&quot;&gt;Pros &amp;amp; Cons&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Pros
    &lt;ul&gt;
      &lt;li&gt;compact description (a function), benefit for storing&lt;/li&gt;
      &lt;li&gt;queries easy (inside object, distance to surface)&lt;/li&gt;
      &lt;li&gt;good for ray-to-surface intersection&lt;/li&gt;
      &lt;li&gt;easy to handle changes in topology (e.g. fluid)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Cons
    &lt;ul&gt;
      &lt;li&gt;difficult to model complex shapes&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;explicit-representations-of-geometry&quot;&gt;Explicit Representations of Geometry&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;All points are given directly or via parameter mapping&lt;/li&gt;
&lt;/ul&gt;

\[f: \mathbb{R}^{2} \rightarrow \mathbb{R}^{3} ;(u, v) \mapsto(x, y, z)\]

&lt;ul&gt;
  &lt;li&gt;Given any $(u,v)$ coordinate, $(x, y, z)$ can be mapped&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJN5kt.jpg&quot; alt=&quot;cg-7-2&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Take $f(u, v)=((2+\cos u) \cos v,(2+\cos u) \sin v, \sin u)$ as an example&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Explicit Surface sampling is easy
    &lt;ul&gt;
      &lt;li&gt;What points lie on this surface: Just plug in $(u,v)$ values&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJNoff.jpg&quot; alt=&quot;cg-7-1&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Take $f(u, v)=(\cos u \sin v, \sin u \sin v, \cos v)$ as an example
    &lt;ul&gt;
      &lt;li&gt;Is $(3/4, 1/2, 1/4)$ inside the sphere?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;No Best Representation: depends on tasks&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;explicit-geometry&quot;&gt;Explicit Geometry&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;triangle meshes&lt;/li&gt;
  &lt;li&gt;Bezier surfaces&lt;/li&gt;
  &lt;li&gt;subdivision surfaces&lt;/li&gt;
  &lt;li&gt;NURBS&lt;/li&gt;
  &lt;li&gt;point clouds&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;polygon-mesh&quot;&gt;Polygon Mesh&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Store vertices &amp;amp; polygons (often triangles or quads)&lt;/li&gt;
  &lt;li&gt;Easier to do processing / simulation, adaptive sampling&lt;/li&gt;
  &lt;li&gt;More complicated data structures&lt;/li&gt;
  &lt;li&gt;Perhaps most common representation in graphics&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJIepT.jpg&quot; alt=&quot;cg-7-1&quot; width=&quot;550px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The Wavefront Object File (.obj) Format
    &lt;ul&gt;
      &lt;li&gt;a text file that specifies vertices, normals, texture coordinates and their connectivities&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;point-cloud&quot;&gt;Point Cloud&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Easiest representation: list of points $(x, y, z)$&lt;/li&gt;
  &lt;li&gt;Easily represent any kind of geometry&lt;/li&gt;
  &lt;li&gt;Useful for large datasets (&amp;gt;&amp;gt; 1 point/pixel)&lt;/li&gt;
  &lt;li&gt;Often converted into polygon mesh&lt;/li&gt;
  &lt;li&gt;Difficult to draw in undersampled (采样不足的) regions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJIm1U.gif&quot; alt=&quot;cg-7-10&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;curves&quot;&gt;Curves&lt;/h2&gt;

&lt;h3 id=&quot;bézier-curve&quot;&gt;Bézier Curve&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Defining Cubic Bézier Curve With Tangent&lt;/li&gt;
  &lt;li&gt;Start point and the end point is $b_0$ and $b_2$&lt;/li&gt;
  &lt;li&gt;Tangent of start and end is the tangent at $b_0$ and $b_2$&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Bézier Curve is a representation of explicit geometry since it is way of &lt;strong&gt;parameter mapping&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJIVhV.jpg&quot; alt=&quot;cg-7-12&quot; width=&quot;75%&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;de-casteljau-algorithm&quot;&gt;de Casteljau Algorithm&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Evaluate Bézier Curve
    &lt;ul&gt;
      &lt;li&gt;Consider three points (quadratic Bezier)&lt;/li&gt;
      &lt;li&gt;Insert a point using linear interpolation&lt;/li&gt;
      &lt;li&gt;Insert on both edges&lt;/li&gt;
      &lt;li&gt;Repeat recursively until only one intermediate point exists&lt;/li&gt;
      &lt;li&gt;Run the same algorithm for every $t$ in $[0, 1]$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJIMnJ.gif&quot; alt=&quot;cg-7-13&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;algebraic-formula&quot;&gt;Algebraic Formula&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;de Casteljau Algorithm gives a pyramid of coefficients&lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned} \mathbf{b}_{0}^{1}(t) &amp;amp;=(1-t) \mathbf{b}_{0}+t \mathbf{b}_{1} \\ \mathbf{b}_{1}^{1}(t) &amp;amp;=(1-t) \mathbf{b}_{1}+t \mathbf{b}_{2} \\ \mathbf{b}_{0}^{2}(t) &amp;amp;=(1-t) \mathbf{b}_{0}^{1}+t \mathbf{b}_{1}^{1} \\ \mathbf{b}_{0}^{2}(t) &amp;amp;=(1-t)^{2} \mathbf{b}_{0}+2 t(1-t) \mathbf{b}_{1}+t^{2} \mathbf{b}_{2} \end{aligned}\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJIEt0.jpg&quot; alt=&quot;cg-7-14&quot; width=&quot;85%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;General Algebraic Formula&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJIncF.jpg&quot; alt=&quot;cg-7-15&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bernstein polynomials&lt;/li&gt;
&lt;/ul&gt;

\[B_{i}^{n}(t)=\left(\begin{array}{l}n \\ i\end{array}\right) t^{i}(1-t)^{n-i}\]

&lt;ul&gt;
  &lt;li&gt;For each $t$ moment, the sum of Bernstein Polynomials is 1. Drawing a vertical line at any $t$ moment, the sum of the y-coordinate of the intersection with the curve is 1.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sJIuX4.jpg&quot; alt=&quot;cg-7-16&quot; width=&quot;350px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;assume $n=3$ in $R^3$:&lt;/li&gt;
&lt;/ul&gt;

\[\mathbf{b}^{n}(t)=\mathbf{b}_{0}(1-t)^{3}+\mathbf{b}_{1} 3 t(1-t)^{2}+\mathbf{b}_{2} 3 t^{2}(1-t)+\mathbf{b}_{3} t^{3}\]

&lt;ul&gt;
  &lt;li&gt;The tangent of the curve in cubic case: the slope for Bézier Curve is the derivative with respect to $t$&lt;/li&gt;
&lt;/ul&gt;

\[\frac{d \mathbf{b}(t)}{d t}=\mathbf{b}^{\prime}(t)=3(1-t)^{2}\left(\mathbf{b}_{1}-\mathbf{b}_{0}\right)+6(1-t) t\left(\mathbf{b}_{2}-\mathbf{b}_{1}\right)+3 t^{2}\left(\mathbf{b}_{3}-\mathbf{b}_{2}\right)\]

&lt;h4 id=&quot;properties-of-bézier-curve&quot;&gt;Properties of Bézier Curve&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Interpolate endpoints: Start from $B_0$, end at $B_n$&lt;/li&gt;
  &lt;li&gt;Tangent to end segment: In cubic case $\mathbf{b}^{\prime}(0)=3\left(\mathbf{b}_{1}-\mathbf{b}_{0}\right)$, $\mathbf{b}^{\prime}(1)=3\left(\mathbf{b}_{3}-\mathbf{b}_{2}\right)$&lt;/li&gt;
  &lt;li&gt;Transform curve by transforming control points
    &lt;ul&gt;
      &lt;li&gt;Since the Bézier Curve is the result of linear combinations&lt;/li&gt;
      &lt;li&gt;But it doesn’t work for &lt;strong&gt;projection transformation&lt;/strong&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Convex hull (凸包) property
    &lt;ul&gt;
      &lt;li&gt;Curve is within convex hull of control points&lt;/li&gt;
      &lt;li&gt;Convex hull is a concept in computational geometry. Briefly, it can be thought of as a rubber band that fits around all the points in 2D space&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;piecewise-bézier-curve&quot;&gt;Piecewise Bézier Curve&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Higher-order (high-degree 高阶) Bézier Curve is hard to control: Instead, Piecewise (逐段的) Bézier Curve is put forward
    &lt;ul&gt;
      &lt;li&gt;Chain many low-order Bézier Curves&lt;/li&gt;
      &lt;li&gt;Piecewise cubic Bézier Curve is the most common technique and widely used in Apps (Illustrator, SVG, etc.)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;For Cubic Curve, each four pair of point defining a piece of Bézier Curve
    &lt;ul&gt;
      &lt;li&gt;The curve is continuous when each piece of curve is connected&lt;/li&gt;
      &lt;li&gt;The curve is smooth when the connection of each curve is smooth
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;Smooth&lt;/strong&gt;: the derivative (slope) of the previous ending point of the curve is the same as the subsequent curve. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Same&lt;/code&gt; means both &lt;strong&gt;direction&lt;/strong&gt; and &lt;strong&gt;the amount of value&lt;/strong&gt;.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sYGH7q.jpg&quot; alt=&quot;cg-7-17&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Continuity
    &lt;ul&gt;
      &lt;li&gt;$C^0$ continuity: $a_n = b_0$&lt;/li&gt;
      &lt;li&gt;$C^1$ continuity: $a_n = b_0 = \frac{1}{2}(a_{n-1}+b_1)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sYGqA0.jpg&quot; alt=&quot;cg-7-18&quot; width=&quot;550px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://math.hws.edu/eck/cs424/notes2013/canvas/bezier.html&quot;&gt;Animation of Bézier Curve&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;spline&quot;&gt;Spline&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Spline&lt;/strong&gt; (样条): a continuous curve constructed so as to pass through a given set of points and have a certain number of continuous derivatives
    &lt;ul&gt;
      &lt;li&gt;In short, a curve under control directly&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sYG7Bn.jpg&quot; alt=&quot;cg-7-19&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;b-splines&quot;&gt;B-splines&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;B-spline&lt;/strong&gt;: Short for basis splines&lt;/li&gt;
  &lt;li&gt;Require more information than Bézier Curve curbes&lt;/li&gt;
  &lt;li&gt;Satisfy all important properties that Bézier Curve have (i.e. superset)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;# TODO&lt;/strong&gt;: refer to &lt;a href=&quot;https://www.bilibili.com/video/
av66548502?from=search&amp;amp;seid=65256805876131485&quot;&gt;Shi-Min Hu’s course&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;nurbs&quot;&gt;NURBS&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;# TODO&lt;/strong&gt;: refer to &lt;a href=&quot;https://www.bilibili.com/video/
av66548502?from=search&amp;amp;seid=65256805876131485&quot;&gt;Shi-Min Hu’s course&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;surface&quot;&gt;Surface&lt;/h2&gt;

&lt;h3 id=&quot;bézier-surface&quot;&gt;Bézier Surface&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Extend Bézier curves to surfaces under control of 2D control points&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sYGv3F.gif&quot; alt=&quot;cg-7-20&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For Bicubic Bézier surface patch, evaluate surface position for parameters $(u, v)$
    &lt;ul&gt;
      &lt;li&gt;$(u, v)$ is parameters to describe two-dimensional $t$, which proves again that Bézier (parameter mapping) is explicit geometry representation&lt;/li&gt;
      &lt;li&gt;Input: 4x4 control points&lt;/li&gt;
      &lt;li&gt;Output: 2D surface parameterized by $(u, v)$ in $[0,1]^2$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sYGTns.jpg&quot; alt=&quot;cg-7-21&quot; width=&quot;550px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bicubic operation: similar to ‘Bicubic interpolation’&lt;/li&gt;
  &lt;li&gt;Separable 1D de Casteljau Algorithm
    &lt;ul&gt;
      &lt;li&gt;Goal: evaluate surface position corresponding to $(u, v)$&lt;/li&gt;
      &lt;li&gt;(u, v)-separable application of de Casteljau algorithm
        &lt;ul&gt;
          &lt;li&gt;Use de Casteljau to evaluate point $u$ on each of the 4 Bézier curves in $u$. This gives 4 control points for the ‘moving’ Bézier curve&lt;/li&gt;
          &lt;li&gt;Use 1D de Casteljau to evaluate point $v$ on the ‘moving’ curve
&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sYGLNV.jpg&quot; alt=&quot;cg-7-22&quot; width=&quot;600px&quot; /&gt;&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sYGOhT.jpg&quot; alt=&quot;cg-7-23&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;TIP&lt;/strong&gt;: piecewise (片段) in 2D curve vs patch (片) in 3D surface&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;#TODO&lt;/strong&gt;: Continuity&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;mesh-operations&quot;&gt;Mesh Operations&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Mesh (网格) Operations: Geometry Processing
    &lt;ul&gt;
      &lt;li&gt;Mesh subdivion (细分): increase resolution (upsampling)&lt;/li&gt;
      &lt;li&gt;Mesh simplification: decrease resolution (downsampling) while preserving shape/appearance&lt;/li&gt;
      &lt;li&gt;Mesh regularization: modify sample distribution to improve quality&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/12/sYGj9U.jpg&quot; alt=&quot;cg-7-24&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;subdivision&quot;&gt;Subdivision&lt;/h3&gt;

&lt;h4 id=&quot;loop-subdivision&quot;&gt;Loop Subdivision&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Common subdivison rule for triangle meshes
    &lt;ul&gt;
      &lt;li&gt;First create more triangles (vertices)&lt;/li&gt;
      &lt;li&gt;Second, tune their positions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/15/swSW36.jpg&quot; alt=&quot;cg-7-25&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Split each triangle into four&lt;/li&gt;
  &lt;li&gt;Assign new vertex positions according to weights
    &lt;ul&gt;
      &lt;li&gt;New / old vertices updated differently&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/15/swSg41.jpg&quot; alt=&quot;cg-7-26&quot; width=&quot;700px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;For new vertices: $ v = 3/8 * (A+B) + 1/8 * (C+D)$&lt;/li&gt;
  &lt;li&gt;For old vertices:  \(\begin{aligned}v=(1-\beta) * original\_position + \beta * \sum^{n} neighbour\_position, \end{aligned} \\ where:\quad \beta=\left\{\begin{array}{l}\frac{3}{8 \mathrm{n}},\quad when\quad n&amp;gt;3 \\ \frac{3}{16},\quad when\quad \mathrm{n}=3\end{array}\right.\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: $n$ is vertex degree. In graph theory, the degree of a vertex is the number of edges that are incident to the vertex.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/15/swSR9x.jpg&quot; alt=&quot;cg-7-27&quot; width=&quot;700px&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Loop is family name of the founder Charles Loop of Loop Subdivision, so it has nothing to do with looping.&lt;/p&gt;

&lt;h4 id=&quot;catmul-clark-subdivision&quot;&gt;Catmul-Clark Subdivision&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Catmul-Clark subdivision is more general than Loop Subdivision since Catmul-Clark Subdivision can handle mesh with not only triangles but quadrangles.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/15/swSHUA.jpg&quot; alt=&quot;cg-7-28&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Each subdivision step:
    &lt;ul&gt;
      &lt;li&gt;Keep all original vertex $d$&lt;/li&gt;
      &lt;li&gt;Add vertex in each face $V_i$&lt;/li&gt;
      &lt;li&gt;Add midpoint on each edge $E_i$&lt;/li&gt;
      &lt;li&gt;Connect all new vertices&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\mathbf{V}_{i}=\frac{1}{n} \times \sum_{j=1}^{n} \mathbf{d}_{j}\]

\[\mathbf{E}_{i}=\frac{1}{4}\left(\mathbf{d}_{1}+\mathbf{d}_{2 i}+\mathbf{V}_{i}+\mathbf{V}_{i+1}\right)\]

\[\mathbf{d}_{i}^{\prime}=\frac{(n-3)}{n} \mathbf{d}_{i}+\frac{2}{n} \mathbf{R}+\frac{1}{n} \mathbf{S}\]

\[\mathbf{R}=\frac{1}{m} \sum_{i=1}^{m} \mathbf{E}_{i}, \mathbf{S}=\frac{1}{m} \sum_{i=1}^{m} \mathbf{V}_{i}\]

&lt;ul&gt;
  &lt;li&gt;After each subdivision
    &lt;ul&gt;
      &lt;li&gt;No extraordinatry (奇异点) vertices (degree != 4) left&lt;/li&gt;
      &lt;li&gt;No non-quad face left&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/15/swS7Ed.jpg&quot; alt=&quot;cg-7-29&quot; width=&quot;750px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;mesh-simplification&quot;&gt;Mesh Simplification&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Goal&lt;/strong&gt;: reduce number of mesh elements while maintaining the overall shape&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/15/swSfgK.jpg&quot; alt=&quot;cg-7-30&quot; width=&quot;750px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Difficulty&lt;/strong&gt;: For image simplification (downsampling), take Mipmap as an example, which can be performed by reducing the image resolution for several times, image pyramid (mip hierarchy) is used to represent different level of vision field. While for the geometry, it is difficult to use the similar pattern to divide the hierarchy of geometry, like how to make the number of geometric mesh change smoothly from far to near.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;edge-collapsing&quot;&gt;Edge Collapsing&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Suppose we simplify a mesh using edge collapsing&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/15/swShjO.jpg&quot; alt=&quot;cg-7-31&quot; width=&quot;550px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Geometric error will be introduced by simplification .&lt;/li&gt;
  &lt;li&gt;Comparing to average and median simplification, error of quadric is minimum.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/15/swS5uD.jpg&quot; alt=&quot;cg-7-32&quot; width=&quot;700px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Quadric Error Metrics (二次误差度量)
    &lt;ul&gt;
      &lt;li&gt;Not a good idea to perform local averaging or median of vertices&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Quadric error&lt;/strong&gt;: new vertex should minimize its &lt;strong&gt;sum of square distance&lt;/strong&gt; (&lt;strong&gt;L2 distance&lt;/strong&gt;) to previously related triangle planes&lt;/li&gt;
      &lt;li&gt;Idea: choose point that minimizes quadric error&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Suppose squared distance of point $p$ to plane $q$&lt;/li&gt;
&lt;/ul&gt;

\[p=(x, y, z, 1)^{T}, q=(a, b, c, d)^{T}\]

\[d i s t(q, p)^{2}=\left(q^{T} p\right)^{2}=p^{T}\left(q q^{T}\right) p=: p^{T} Q_{q} p\]

\[where\quad Q_{q}=\left[\begin{array}{cccc}a^{2} &amp;amp; a b &amp;amp; a c &amp;amp; a d \\ a b &amp;amp; b^{2} &amp;amp; b c &amp;amp; b d \\ a c &amp;amp; b c &amp;amp; c^{2} &amp;amp; c d \\ a d &amp;amp; b d &amp;amp; c d &amp;amp; d^{2}\end{array}\right]\]

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: $q$ is a regularized parameter of plane, where $a^2+b^2+c^2 = 1$.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sum distances to planes $q_i$ of vertex’ neighbouring triangles&lt;/li&gt;
&lt;/ul&gt;

\[\sum_{i} \operatorname{dist}\left(q_{i}, p\right)^{2}=\sum_{i} p^{T} Q_{q_{i}} p=p^{T}\left(\sum_{i} Q_{q_{i}}\right) p=: p^{T} Q_{p} p\]

&lt;ul&gt;
  &lt;li&gt;Point $p^{\star}$ that minimizes the error satisfies
    &lt;ul&gt;
      &lt;li&gt;Which turn into the optimization problem&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\left[\begin{array}{cccc}
q_{11} &amp;amp; q_{12} &amp;amp; q_{13} &amp;amp; q_{14} \\
q_{21} &amp;amp; q_{22} &amp;amp; q_{23} &amp;amp; q_{24} \\
q_{31} &amp;amp; q_{32} &amp;amp; q_{33} &amp;amp; q_{34} \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{array}\right] \boldsymbol{p}^{*}=\left[\begin{array}{c} 0 \\ 0 \\ 0 \\ 1 \end{array}\right]\]

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Simplification via Quadric Error&lt;/strong&gt;: assign score with quadric error metric (&lt;em&gt;Garland &amp;amp; Heckbert 1997&lt;/em&gt;)
    &lt;ul&gt;
      &lt;li&gt;Approximate distance to surface as sum of distances to planes containing triangles&lt;/li&gt;
      &lt;li&gt;Assign score with quadric error metric for &lt;strong&gt;each edge&lt;/strong&gt; of the total geometric figure&lt;/li&gt;
      &lt;li&gt;Sort the score of &lt;strong&gt;each edge&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Select the smallest score with &lt;strong&gt;least&lt;/strong&gt; quadric error metric and perform edge collapsing&lt;/li&gt;
      &lt;li&gt;Update the corresponding changed edges with new quadric error&lt;/li&gt;
      &lt;li&gt;Iteratively execute until the simplification reaches condition&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: For each step, the edge corresponding to the least quadric error is selected to be collasped. Clearly, this is a way of reaching local optimum for each step to achieve global optimum, namely greedy strategy. However strictly speaking, this approch does not prove that the global optimal solution can be reached, but this insignificant error is allowed by default in CG.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Cp5WWtMoeKg&quot;&gt;ray marching and distance function&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.bilibili.com/read/cv7933990?from=search&quot;&gt;光线步进和距离函数&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;[SPH算法](https://blog.csdn.net/liuyunduo/article/details/84098884)&quot;&gt;SPH算法&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Smoothed-particle_hydrodynamics&quot;&gt;Smoothed-particle hydrodynamics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://acko.net/blog/making-mathbox/&quot;&gt;Visualization of Bézier Surface&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">Geometry, Implicit &amp;amp; Explicit Geometry, Curve, Surface, Subdivision, Mesh Simplification</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅵ</title><link href="https://harrypotterrrr.github.io//2020/09/07/cg-6.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅵ" /><published>2020-09-07T00:00:00+08:00</published><updated>2020-09-07T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/09/07/cg-6</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/09/07/cg-6.html">&lt;p&gt;Texture, Texture Mapping, Interpolation, Texture Filtering&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;texture-mapping&quot;&gt;Texture Mapping&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Texture mapping&lt;/strong&gt; is to apply different colors at different places&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Texture&lt;/strong&gt; defines property and color for each vertex&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;surface&quot;&gt;Surface&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Surfaces are 2D though lives in 3D world space&lt;/li&gt;
  &lt;li&gt;Every 3D surface point also has a place where it goes in the 2D image (&lt;strong&gt;texture&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;In other words, each vertex of primitives in 3D world corresponds to the vertex of the primitive in 2D texture.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVCEp4.jpg&quot; alt=&quot;cg-6-1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;texture&quot;&gt;Texture&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Texture is applied to Surface&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We didn’t care about how mapping relationship of triangles produces between model and texture. The mapping and definition of primitives (triangles) are known.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVCZc9.jpg&quot; alt=&quot;cg-6-2&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Generally, texture comes in two ways:
    &lt;ul&gt;
      &lt;li&gt;Art designer design and produce the texture&lt;/li&gt;
      &lt;li&gt;Parameterization of triangular meshes&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parameterization&lt;/strong&gt; is the process of finding parametric equations of a curve, a surface, a manifold or a variety, defined by an implicit equation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;texture-coordinates&quot;&gt;Texture Coordinates&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Each triangle vertex is assigned a texture coordinate $(u,v)$.&lt;/li&gt;
  &lt;li&gt;Define mapping between points on triangle’s surface (object coordinate space) to points in texture coordinate space.&lt;/li&gt;
  &lt;li&gt;Each vertex corresponds to one texture mapping. Again, this mapping is known and we don’t care how this mapping come from.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: No matter the texture is square or not, $u$ and $v$ are in range of $(0,1)$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVeE90.jpg&quot; alt=&quot;cg-6-3&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;texture-tile&quot;&gt;Texture Tile&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Textures can be applied multiple times&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVZlSf.jpg&quot; alt=&quot;cg-6-4&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Well-designed texture is tileable when multiple textures blend together profesionally and seamlessly together, borders of texture is not easily conspicuous.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVi2kV.png&quot; alt=&quot;cg-6-5&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;interpolation&quot;&gt;Interpolation&lt;/h2&gt;

&lt;h3 id=&quot;interpolation-across-triangles-barycentric-coordinates&quot;&gt;Interpolation Across Triangles: Barycentric Coordinates&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Why to interpolate
    &lt;ul&gt;
      &lt;li&gt;Specify values at vertices&lt;/li&gt;
      &lt;li&gt;Obtain smoothly varying values across triangles&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What to interpolate
    &lt;ul&gt;
      &lt;li&gt;Texture coordinates, colors, normal vectors. etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How to interpolate
    &lt;ul&gt;
      &lt;li&gt;Barycentric coordinate&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;barycentric-coordinate&quot;&gt;Barycentric Coordinate&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Any point $(x,y)$ in the plane can be represented as a linear combination of triangular vertices.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sZUVNq.jpg&quot; alt=&quot;cg-6-6&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A coordinate system for triangles $(\alpha, \beta, \gamma)$
    &lt;ul&gt;
      &lt;li&gt;Proved by using &lt;a href=&quot;https://zh.wikipedia.org/wiki/%E5%AE%9A%E6%AF%94%E5%88%86%E7%82%B9%E5%85%AC%E5%BC%8F&quot;&gt;point-scored formula&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[(x, y)= \alpha A+\beta B+\gamma C\]

\[\alpha+\beta+\gamma=1\]

\[0 \le \alpha,\ \beta,\ \gamma \le 1\]

&lt;ul&gt;
  &lt;li&gt;Point $(x,y)$ is not in the plane of $ABC$ if $\alpha+\beta+\gamma \neq1$&lt;/li&gt;
  &lt;li&gt;Point $(x,y)$ is inside the triangle if and only if all three $(\alpha, \beta, \gamma)$ are non-negative.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;e.g. $A$ is when $(\alpha, \beta, \gamma) = (1, 0, 0)$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Geometric viewpoint: proportional areas
    &lt;ul&gt;
      &lt;li&gt;It is available to get $(\alpha, \beta, \gamma)$ by given a spcified point $(x,y)$.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned} \alpha &amp;amp;=\frac{A_{A}}{A_{A}+A_{B}+A_{C}} \\ \beta &amp;amp;=\frac{A_{B}}{A_{A}+A_{B}+A_{C}} \\ \gamma &amp;amp;=\frac{A_{C}}{A_{A}+A_{B}+A_{C}} \end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Barycentric coordinate&lt;/strong&gt; of centroid: $(\alpha, \beta, \gamma) = (\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$, then $(x, y)=\frac{1}{3} A+\frac{1}{3} B+\frac{1}{3} C$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Linear interpolate values at vertices&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;$V_A, V_B, V_C$ can be positions, texture coordinates, color, normal, depth, material attributes…&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[V=\alpha V_{A}+\beta V_{B}+\gamma V_{C}\]

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: barycentric coordinates are not invariant under projection! Thus interpolate every time after projections.&lt;/p&gt;

&lt;h3 id=&quot;texture-applying&quot;&gt;Texture Applying&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Simple texture mapping: diffuse color&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rasterized&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;           &lt;span class=&quot;c1&quot;&gt;// Usually a pixel's center&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texture&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coordinate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Using barycentric coordinates&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;texcolor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;// get texture (u,v)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;                 &lt;span class=&quot;c1&quot;&gt;// Usually the diffuse albedo Kd of Blinn-Phong reflectance model&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;texture-filtering&quot;&gt;Texture Filtering&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;To determine the texture color for a texture mapped pixel, using the colors near by &lt;strong&gt;texels&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Texel&lt;/strong&gt; (纹素): a pixel on a texture&lt;/li&gt;
  &lt;li&gt;Two main categories of texture filtering, depending on the situation texture filtering
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Magnification filtering&lt;/strong&gt;: a type of reconstruction filter where sparse data is interpolated to fill gaps&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Minification filtering&lt;/strong&gt;: a type of anti-aliasing (AA), where texture samples exist at a higher frequency than required for the sample frequency needed for texture fill&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;texture-magnification&quot;&gt;Texture Magnification&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Insufficient texture resolution: texture is too small comparing to the object, then the texture has to be enlarged than its actual resolution.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: For each point on the object or scene, mapping it to the corresponding point on the low resolution texture will get non-integer coordinates of texture. Rounding off is the common process to obtain non-floating coordinate texel. As a result, multiple pixels of the object or scene will corresponds to the same texel of the texture, which means the generated figure is obscure of low quality. Thus interpolation handle it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sZN7cD.jpg&quot; alt=&quot;cg-6-7&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;bilinear-interpolation&quot;&gt;Bilinear Interpolation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Linear interpolation (1D)&lt;/li&gt;
&lt;/ul&gt;

\[\operatorname{lerp}\left(x, v_{0}, v_{1}\right)=v_{0}+x\left(v_{1}-v_{0}\right)\]

&lt;ul&gt;
  &lt;li&gt;Two horizontal interpolations&lt;/li&gt;
&lt;/ul&gt;

\[u_{0}=\operatorname{lerp}\left(s, u_{00}, u_{10}\right) \\
u_{1}=\operatorname{lerp}\left(s, u_{01}, u_{11}\right)\]

&lt;ul&gt;
  &lt;li&gt;Final vertical interpolation&lt;/li&gt;
&lt;/ul&gt;

\[f(x, y)=\operatorname{lerp}\left(t, u_{0}, u_{1}\right)\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sZNOHA.jpg&quot; alt=&quot;cg-6-8&quot; width=&quot;350px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Red point: want to sample texture value $f(x,y)$&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Black points: indicate texture sample locations (the center of texel)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For the nearest method of texture applying, take the red point as an example, any mapping point in the square which the red point and $u_{11}$ locates at will take $u_{11}$ as a texel. When the object or scene is very large comparing to the texture, multiple pixels will map to the same texel as $u_{11}$. That is the reason why jaggies and artifacts are consipicuous in the above nearest figure.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For the bilinear interpolation, it takes 4 nearest sample locations with textrue values as labeled, blending the property and information of 4 texels, so the result is more smooth and realistic.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Bilinear interpolation usually gives pretty good results at reasonable costs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;bicubic-interpolation&quot;&gt;Bicubic Interpolation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Bicubic interpolation is to use 4 x 4 point to do interpolation, which has better performance but higher costs. (Look into the canthus of the above figure, bilinear create jaggies but bicubic is more realistic)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sZNjAI.png&quot; alt=&quot;cg-6-9&quot; width=&quot;650px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;texture-minification&quot;&gt;Texture Minification&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Superadundant texture resolution: Texture is too large comparing to the screen space required, so it has to be shrunken relative to its natural resolution.
    &lt;ul&gt;
      &lt;li&gt;Intuitively, when the texture is large, every information is available. But it is incorrect.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sehxtP.jpg&quot; alt=&quot;cg-6-10&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Screen Pixel’s “Footprint” in Texture
    &lt;ul&gt;
      &lt;li&gt;As the pixel in the screen space get growingly further, the number of corresponding texels in texture gets more and more.&lt;/li&gt;
      &lt;li&gt;Take the above image as an example, the pixels close to the horizon represent a large region of texture. The information lost happens when the square which the blue point is inside is selected as texel&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sehvkt.jpg&quot; alt=&quot;cg-6-11&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Supersampling to antialiasing: yes, high quality, but costly.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;The reason of aliasing when perform minification
    &lt;ul&gt;
      &lt;li&gt;When highly minified, many texels in pixel footprint&lt;/li&gt;
      &lt;li&gt;Signal frequency too large in a pixel&lt;/li&gt;
      &lt;li&gt;Need even higher sampling frequency&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Solution: Not do sampling but get the average value within a range, &lt;strong&gt;Range Query&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: Some data structure like K-d tree, segment tree, binary indexed tree etc. are good ways to solve range query problem.&lt;/p&gt;

&lt;h4 id=&quot;mipmap&quot;&gt;Mipmap&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Precompute and store the averages of the texture over various areas of different size and position.&lt;/li&gt;
  &lt;li&gt;Allowing &lt;strong&gt;fast&lt;/strong&gt;, &lt;strong&gt;approximate&lt;/strong&gt;, &lt;strong&gt;square&lt;/strong&gt; range queries.
    &lt;ul&gt;
      &lt;li&gt;“Mip” comes from the Latin, meaning a multitude in a small space.&lt;/li&gt;
      &lt;li&gt;A sequence of textures that contains the same image but at lower and lower resolution. 
 &lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sehXTI.jpg&quot; alt=&quot;cg-6-12&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;There are total of $log(n)$ images&lt;br /&gt;
 &lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sehO0A.jpg&quot; alt=&quot;cg-6-13&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;The total storage overhead of a mipmap is the summation of series: $\frac{4}{3}$ to the original image.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: We call this kind of structure, with images that represent the same content at a series of lower and lower sampling rates, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;image pyramid&lt;/code&gt; in computer vision field.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Computing Mipmap at level $D$: estimate texture footprint using texture coordinates of &lt;strong&gt;neighboring&lt;/strong&gt; screen samples&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/su7yKx.jpg&quot; alt=&quot;cg-6-14&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The distance between the pixel and neighbouring in screen space is 1&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Denote the pixel $(x,y)$ in screen space and texel $(u,v)$ in texture space&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Denote transformation $\psi$ the mapping from image sapce to texture space as a linear mapping, the transformation equation, thus $u = \psi_{x}(x, y), v = \psi_{y}(x, y)$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/jacobian/v/the-jacobian-matrix&quot;&gt;&lt;em&gt;Jacobian matrix&lt;/em&gt;&lt;/a&gt; $J$ is the best linear approximation of $\psi$ in a neighbourhood of $(u,v)$ where $\psi$ is differentiable.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\lim_{\Delta p \to 0}\psi(\mathbf{p}+\Delta \mathbf{p})=\psi(\mathbf{p} )+ \mathbf{J}\Delta \mathbf{p}\]

\[\mathbf{J}=\frac{\partial (u, v)}{\partial (x, y)}=\left[\begin{array}{ll}\frac{\partial u}{\partial x} &amp;amp; \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} &amp;amp; \frac{\partial v}{\partial y}\end{array}\right]\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKmMo8.gif&quot; alt=&quot;cg-6-15&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Recall that in linear transformation \(\left[\begin{array}{ll}a_{x} &amp;amp; b_{x} \\ a_{y} &amp;amp; b_{y}\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]=\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right]\),\(\left[\begin{array}{ll}a_{x} &amp;amp; b_{x} \\ a_{y} &amp;amp; b_{y}\end{array}\right]\) is transformation matrix, the two columns of it \(\left[\begin{array}{l}a_{x} \\ a_{y}\end{array}\right]\) and \(\left[\begin{array}{l}a_{x} \\ a_{y}\end{array}\right]\) are two basis vector of the new space if the original basis is  \(\left[\begin{array}{l}1 \\ 0\end{array}\right]\) and \(\left[\begin{array}{l}0 \\ 1\end{array}\right]\). Thus, we could take Jacobian matrix as transformation matrix mapping the pixel $(x, y)$ in screen space to the texture space $(u, v)$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In screen space, suppose $(u, v)_{10}$ and $(u, v)_{01}$ as $(1, 0)$ and $(0, 1)$ relatively, the corresponding texel coordinate is computed by multiplying the transformation Jacobian matrix $J$:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\left(\begin{array}{l}u^{\prime}_{10} \\ v^{\prime}_{10}\end{array}\right)=\left[\begin{array}{cc}\frac{\partial u}{\partial x} &amp;amp; \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} &amp;amp; \frac{\partial v}{\partial y}\end{array}\right]\left(\begin{array}{l}1 \\ 0\end{array}\right)=\left(\begin{array}{c}\frac{\partial u}{\partial x} \\ \frac{\partial v}{\partial x}\end{array}\right)\]

\[\left(\begin{array}{l}u^{\prime}_{01} \\ v^{\prime}_{01}\end{array}\right)=\left[\begin{array}{cc}\frac{\partial u}{\partial x} &amp;amp; \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} &amp;amp; \frac{\partial v}{\partial y}\end{array}\right]\left(\begin{array}{l}0 \\ 1\end{array}\right)=\left(\begin{array}{c}\frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial y}\end{array}\right)\]

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Each column of Jacobian matrix is the new basis vector of the transformed space. &lt;a href=&quot;https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/jacobian/v/jacobian-prerequisite-knowledge&quot;&gt;More details&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sK3AKg.jpg&quot; alt=&quot;cg-6-17&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Choose the level $D$ so that the size covered by the texels at that level is roughly the same as the overall size of the pixel footprint.&lt;/li&gt;
&lt;/ul&gt;

\[D=\log _{2} L\]

\[\quad L=\max \left(\sqrt{\left(\frac{d u}{d x}\right)^{2}+\left(\frac{d v}{d x}\right)^{2}}, \sqrt{\left(\frac{d u}{d y}\right)^{2}+\left(\frac{d v}{d y}\right)^{2}}\right)\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/su7UVU.jpg&quot; alt=&quot;cg-6-16&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$D$ rounded to nearest integer level
    &lt;ul&gt;
      &lt;li&gt;near (in red) corresponds to low level of texture&lt;/li&gt;
      &lt;li&gt;far (in blue) corresponds to high level of texture&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKJYZQ.jpg&quot; alt=&quot;cg-6-18&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;But Bilinear filtering only, where $D$ is clamped to nearest level, not support floating $D$ and the level $D$ is not continuous.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Trilinear Interpolation&lt;/strong&gt;: perform two Bilinear interpolation in neighbouring levels and interpolate the interpolated result again.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[u_{d}= BilinearInterpolate(p_{d})\\
u_{d+1}= BilinearInterpolate(p_{d+1})\\
f(x, y) = lerp(r, u_{d}, u_{d+1})\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKs5lQ.jpg&quot; alt=&quot;cg-6-19&quot; width=&quot;650px&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;isotrpic-limitation&quot;&gt;Isotrpic Limitation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Mipmap limitation
    &lt;ul&gt;
      &lt;li&gt;the pixel footprint might be quite different in shape from the area represented by the texel, not always approximately square&lt;/li&gt;
      &lt;li&gt;Mipmap is unable to handle the pixel footprint with an elongated shape&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKs4Sg.jpg&quot; alt=&quot;cg-6-20&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tilinear (&lt;strong&gt;isotropic&lt;/strong&gt;) sampling will cause overblur problem most commonly when the points are on the floor that are far away viewed at very steep angles, which results in the pixel footprint covering much larger square areas.&lt;/li&gt;
  &lt;li&gt;As a result, most footprints far from the viewer are averaged over the large area of the texture, which causes &lt;strong&gt;overblur&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKsffS.jpg&quot; alt=&quot;cg-6-21&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;anisotropic-filtering&quot;&gt;Anisotropic filtering&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Anisotropic filtering&lt;/strong&gt;(Ripmap, or abbreviated &lt;strong&gt;AF&lt;/strong&gt;): use multiple lookups to approximate an elongated footprint better
    &lt;ul&gt;
      &lt;li&gt;select the mipmap level based on the shortest axis of the footprint rather than the largest&lt;/li&gt;
      &lt;li&gt;average together several lookups spaced along the long axis&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Look up axis-aligned rectangular zones and preserve detail at extreme viewing angles.&lt;/li&gt;
  &lt;li&gt;Comparing to isotropic filtering which consume on third of extra space, anisotropic filtering takes three times of extra space consumption.
    &lt;ul&gt;
      &lt;li&gt;Bilinear / trilinear filtering is insotropic and thus will overblur to avoid aliasing&lt;/li&gt;
      &lt;li&gt;Anisotropic texture filtering provides higher image quality at higher computation and memory bandwidth cost&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKsIyj.png&quot; alt=&quot;cg-6-22&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: N x Anisotropic filtering in video games means the original figure will be copied of reduced size up to N times along horizontal and vertial axis. No matter the N increases to 4x, 8x, 16x or more, the ceiling of the space consumption is 4 times of the original texture. Generally, as long as the graphics memory is enough, the larger anisotropy will has no influence on the computing performance.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Limitation so far: diagonal footprints still a problem&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;EWA filtering&lt;/strong&gt; (Elliptically Weighted Average Filtering) to enhance further
    &lt;ul&gt;
      &lt;li&gt;Use multiple lookups&lt;/li&gt;
      &lt;li&gt;Weighted average&lt;/li&gt;
      &lt;li&gt;Mipmap hierarchy still helps&lt;/li&gt;
      &lt;li&gt;Can handle irregular footprints&lt;/li&gt;
      &lt;li&gt;Trade time for better performance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;short-summary&quot;&gt;Short summary&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Texture mapping is a sampling operation and is prone to aliasing.&lt;/li&gt;
  &lt;li&gt;Solution: prefilter texture map to eliminate high frequencies in texture signal.&lt;/li&gt;
  &lt;li&gt;Mip-map: precompute and store multiple resampled versions of the texture image, each of which has different amounts of low-pass filtering.&lt;/li&gt;
  &lt;li&gt;During rendering: dynamically select how much low-pass filtering is required based on distance between nighbouring screen samples in texture space.
    &lt;ul&gt;
      &lt;li&gt;Goal is to retain as much high-frequency content (detail) in the texture as possible, while avoiding aliasing.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;applications-of-texture&quot;&gt;Applications of Texture&lt;/h2&gt;

&lt;h3 id=&quot;general-texturing&quot;&gt;General Texturing&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Generalize texturing into many usages&lt;/li&gt;
  &lt;li&gt;In modern GPUs, texture = memory + range query (filtering)
    &lt;ul&gt;
      &lt;li&gt;General method to bring data to fragment calculations&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Many applications
    &lt;ul&gt;
      &lt;li&gt;Environment lighting&lt;/li&gt;
      &lt;li&gt;Store microgeometry&lt;/li&gt;
      &lt;li&gt;Procedural textures&lt;/li&gt;
      &lt;li&gt;Solid modeling&lt;/li&gt;
      &lt;li&gt;Volumne rendering&lt;/li&gt;
      &lt;li&gt;etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Environment Map: render with the light from the envrionment as texture
    &lt;ul&gt;
      &lt;li&gt;We suppose the light is static and comes from an infinite distance. We only care about the direction of the light without any depth information.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/10/s1iK78.jpg&quot; alt=&quot;cg-6-23&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: Classic model in CG: Utah teapot, Stanford bunny, Stanford dragon, Cornell Box&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Spherical Map&lt;/strong&gt;: Sphere is used to store environment light (map). Unfolding the sphere is texture to render realistic lighting&lt;br /&gt;
 &lt;img src=&quot;https://s3.ax1x.com/2021/01/10/s1iu0f.jpg&quot; alt=&quot;cg-6-24&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;Sphere texture is prone to &lt;strong&gt;distortion&lt;/strong&gt; at top and bottom parts&lt;br /&gt;
 &lt;img src=&quot;https://s3.ax1x.com/2021/01/10/s1innP.jpg&quot; alt=&quot;cg-6-25&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cubic Map&lt;/strong&gt;: A vector map to cube point along the direction. The cube is textured with 6 square texture maps&lt;br /&gt;
&lt;img src=&quot;https://s3.ax1x.com/2021/01/10/s1iZ6I.jpg&quot; alt=&quot;cg-6-26&quot; /&gt;
    &lt;ul&gt;
      &lt;li&gt;less distortion&lt;/li&gt;
      &lt;li&gt;only need direction to face mapping computation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/10/s1ieXt.jpg&quot; alt=&quot;cg-6-27&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;bump--normal-mapping&quot;&gt;Bump / Normal mapping&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Previously, textures only represent colors (influence $k_d$ coefficient)&lt;/li&gt;
  &lt;li&gt;In fact, textures may store height / normal or other properties&lt;/li&gt;
  &lt;li&gt;Fake the detailed geometry, accordingly change the normal and &lt;strong&gt;affect shading&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Change how an illuminated surface reacts to light, without modifying the size or shape of the surface&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/10/s1iltg.png&quot; alt=&quot;cg-6-28&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Add surface detail without adding more triangles
    &lt;ul&gt;
      &lt;li&gt;Preturb surface normal per pixel (for shading computations only)&lt;/li&gt;
      &lt;li&gt;“Height shift” per texel defined by a texture&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;normal-in-flatland-case&quot;&gt;Normal in flatland case&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Flatland&lt;/strong&gt; (2D): texture in 1D and space in 2D&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/10/s1iQAS.jpg&quot; alt=&quot;cg-6-29&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Suppose original surface normal $\vec p = (0,1)$ directs upward&lt;/li&gt;
  &lt;li&gt;Approximate derivative at $p$ is $dp = c * [h(p+1) - h(p)]$
    &lt;ul&gt;
      &lt;li&gt;$c$ is a constant coefficient to scale the influence of bump texture&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Perturbed normal is then $\vec{n_p} = (-dp, 1).normalized()$
    &lt;ul&gt;
      &lt;li&gt;$(1, dp)$ rotate 90 degrees counterclockwise using rotate matrix and normalize&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;normal-in-3d-case&quot;&gt;Normal in 3D case&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;texture in 2D and space in 3D&lt;/li&gt;
  &lt;li&gt;Suppose original surface normal $\vec p = (0, 0, 1)$&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Approximate derivatives at $p$ are
\(dp/du = c_1 * [h(u+1) - h(u)] \\ dp/dv = c_2 * [h(v+1) - h(v)]\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Perturbed normal is $\vec{n_p} = (-dp/du, -dp/dv, 1).normalized()$
    &lt;ul&gt;
      &lt;li&gt;// not the cross product result of $(dp/du, 0, 1) \times (dp/dv, 0, 1)$ ?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: These are all in &lt;strong&gt;local coordinate&lt;/strong&gt;. Thus, the perturbed normal need to be transformed to &lt;strong&gt;world coordinate&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;displacement-mapping&quot;&gt;Displacement mapping&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Actually moves the vertices (instead of fake changing the normal only)
    &lt;ul&gt;
      &lt;li&gt;Actual geometric position of vertices over the textured are displaced&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Uses the same texture as in bumping mapping&lt;/li&gt;
  &lt;li&gt;Different with Bump / Normal mapping, Displacement mapping permits particular &lt;strong&gt;silhouettes&lt;/strong&gt;, &lt;strong&gt;self-occlusion&lt;/strong&gt;, &lt;strong&gt;self-shadowing&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/11/s3yRFs.jpg&quot; alt=&quot;cg-6-30&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Require primitives in object elaborated and small enough so that the triangles in object catch up with the high frequency in displacement mapping.
    &lt;ul&gt;
      &lt;li&gt;Displacement mapping only changes the vertex properties, thus if the primitive is large and displacement mapping is not able to change the properties inside of the triangle, displacementm mapping will cause poor result.&lt;/li&gt;
      &lt;li&gt;In order to render texture with delicated details, the sampling rate must be high enough.&lt;/li&gt;
      &lt;li&gt;Subdivision (细分) is needed to introduce more triangles to increase sampling rate.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Costly computation owing to the large amount of additional geometry&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: In DirectX on Windows system, &lt;strong&gt;dynamic tessellation&lt;/strong&gt; (动态曲面细分) is self-adaptive techniques to tessellate object geometry in displacement mapping stage, which dynamically splits the primitives of object into smaller part of triangle to match the frequency requirements of displacement mapping.&lt;/p&gt;

&lt;h3 id=&quot;noise-function-texture&quot;&gt;Noise function Texture&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;3D procedural noise and solid modeling produce texture.&lt;/li&gt;
  &lt;li&gt;Defining the noise function in 3D space, each point of the texture spreading over this space can be calculated by analysis formula of the noise and corresponding operations (binaryzation, linear operation).&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Perlin noise&lt;/code&gt; is a good example of noise function to generate marble crack, mountain fluctuation etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/11/s3ygoj.jpg&quot; alt=&quot;cg-6-31&quot; width=&quot;650px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;precomputed-shading&quot;&gt;Precomputed Shading&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Texture provide precomputed shading
    &lt;ul&gt;
      &lt;li&gt;Precomputed ambnient occlusion and shadow provided by the texture to save time of calculating shadow and occlusion later&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/11/s3ycwQ.jpg&quot; alt=&quot;cg-6-32&quot; width=&quot;700px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3d-texture-and-volumn-rendering&quot;&gt;3D Texture and Volumn Rendering&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Texture can be generalized to 3D space, storing the information and properties (far more than colors) which is to be used and processed in Shader program.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www3.cs.stonybrook.edu/~gu/lectures/2020/&quot;&gt;计算共形几何, 顾险峰，丘成桐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zh.wikipedia.org/wiki/%E5%AE%9A%E6%AF%94%E5%88%86%E7%82%B9%E5%85%AC%E5%BC%8F&quot;&gt;定比分点公式&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/65495373&quot;&gt;三角形重心坐标&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Texture_filtering&quot;&gt;Texture filtering&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant&quot;&gt;Jacobian matrix and determinant&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/jacobian/v/the-jacobian-matrix&quot;&gt;Jacobian matrix, Khan Academy&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/bigmonkey/p/8665498.htm&quot;&gt;雅可比行列式&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/bigmonkey/p/8665498.html&quot;&gt;多变量微积分———变量替换&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://kaba.hilvi.org/homepage/cg/ewa/ewa.htm&quot;&gt;Enhanced EWA filtering&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">Texture, Texture Mapping, Interpolation, Texture Filtering</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅴ</title><link href="https://harrypotterrrr.github.io//2020/09/02/cg-5.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅴ" /><published>2020-09-02T00:00:00+08:00</published><updated>2020-09-02T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/09/02/cg-5</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/09/02/cg-5.html">&lt;p&gt;Shading, Blinn-Phong Shading Model, Shading Frequency, Shadow Mapping, Graphics Pipeline&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;shading&quot;&gt;Shading&lt;/h2&gt;

&lt;h3 id=&quot;what-we-done-so-far&quot;&gt;What we done so far&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Model transformation&lt;/li&gt;
  &lt;li&gt;View transformation&lt;/li&gt;
  &lt;li&gt;Projection transformation&lt;/li&gt;
  &lt;li&gt;Viewport transformation&lt;/li&gt;
  &lt;li&gt;Rasterization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwP9U.jpg&quot; alt=&quot;cg-5-1&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The color applied to each pixel has not been determined yet.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;blinn-phong-reflectance-model&quot;&gt;Blinn-Phong Reflectance Model&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Shading&lt;/strong&gt;: The process of applying a material to an object.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Specular highlight&lt;/strong&gt;: the bright spot of light that apperas on shiny objects when illuminated. Direct light&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Diffuse lighting&lt;/strong&gt;: when a surface that faces an angle 90 degrees or less of the light, it will get a percentage of the light source. Direct light, but diverted from the light source&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ambient lighting&lt;/strong&gt;: light of the environment, most of which comes from reflected surfaces (by diffusion). Indirect light and not in the path of light source&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: We often assume ambient lighting is a constant.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skw9hT.jpg&quot; alt=&quot;cg-5-2&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;shading-point&quot;&gt;Shading point&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Compute light reflected toward camera at a specific &lt;strong&gt;shading point&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Inputs:
    &lt;ul&gt;
      &lt;li&gt;Viewer direction $v$&lt;/li&gt;
      &lt;li&gt;Surface normal $n$&lt;/li&gt;
      &lt;li&gt;Light direction $l$&lt;/li&gt;
      &lt;li&gt;Surface parameters, properties (color, shininess, etc.)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Caveat&lt;/strong&gt;: Above are all &lt;strong&gt;unit&lt;/strong&gt; vectors.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwFc4.jpg&quot; alt=&quot;cg-5-3&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Shading is local, so &lt;strong&gt;No Shadows&lt;/strong&gt; will be generated! (&lt;strong&gt;shading ≠ shadow&lt;/strong&gt;)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The below region in red rectangular is blocked by the object from the light source, but we still shade color to it since &lt;strong&gt;shading is local&lt;/strong&gt;. The shadow of this area will be discussed &lt;a href=&quot;&quot;&gt;later&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwi3F.jpg&quot; alt=&quot;cg-5-4&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;blinn-phong-model&quot;&gt;Blinn-Phong Model&lt;/h2&gt;

&lt;h3 id=&quot;diffuse-reflection&quot;&gt;Diffuse reflection&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Light is scattered uniformly in all directions&lt;/li&gt;
  &lt;li&gt;Surface color is the same for all viewing directions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwkjJ.jpg&quot; alt=&quot;cg-5-5&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lambert’s cosine law: determine how much light is received&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwZH1.jpg&quot; alt=&quot;cg-5-6&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;light-falloff&quot;&gt;Light Falloff&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Assume that ideally there is no loss of energy, for each moment of energy transmission, each spherical shell carries the same amount of luminous energy. For each unit space $dS$ on the spherical shell, we assume the energy is the same, so the for each spherical shell, the total amount of energy is $\oint IdS = 4\pi r^2 I$. Thus $I$ is inversely proportional to the square of the distance $r$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwEu9.jpg&quot; alt=&quot;cg-5-7&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Above proof is not strict, but intuitive. More strict prove is as follows:
We assume there is no energy loss, so the luminous energy $Q$ from the light source per unit time is the same. According to $\Phi = dQ / dt$, we can get the luminous flux $\Phi$ per time unit is the same. From the definition of luminance: $L_{v} = d^2\Phi / d\Omega dA cos\theta$, the total of luminance $4\pi r^2 L_{v} = d\Phi / d\Omega cos\theta$ should be the same. Thus luminance $L_{v}$ is inversely proportional to the square of  the distance $r$.&lt;/p&gt;

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Caveat&lt;/strong&gt;: More detail and the relationship between Luminous intensity $l_{v}$ and Luminance $L_{v}$ will be discussed in &lt;a href=&quot;/2020/11/25/cg-8.html#radiometry&quot;&gt;Radiometry part&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;diffuse-term&quot;&gt;Diffuse Term&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Lambertian Shading (Diffuse shading)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Shading &lt;strong&gt;independent&lt;/strong&gt; of view direction $v$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwVBR.jpg&quot; alt=&quot;cg-5-8&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\max (0, \mathbf{n} \cdot \mathbf{l})$ is to ensure the shading value is always positive even if the light comes from the back of the object&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;info&lt;/strong&gt;: The energy received is relative to the angle between normal $n$ and light $l$. This is also the reason why we feel cold in winter and hot in summer.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Diffuse coefficient&lt;/strong&gt;: often defined as 3 or 4 dimensional vector to store the percentage of energy the shading point reflects (not absorb in). Indirectly contain the material information of the object.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skDi38.jpg&quot; alt=&quot;cg-5-9&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;specular-term&quot;&gt;Specular Term&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Intensity &lt;strong&gt;depends&lt;/strong&gt; on view direction
    &lt;ul&gt;
      &lt;li&gt;Specular highlight close to mirror reflection direction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAURfS.jpg&quot; alt=&quot;cg-5-10&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$v$ close to mirror direction $\Leftrightarrow$ half vector close to normal&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUhlQ.jpg&quot; alt=&quot;cg-5-11&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Specular coefficient&lt;/strong&gt;: similar to &lt;strong&gt;diffuse coefficient&lt;/strong&gt;, to describe the property and material of the object, but specular coefficient always set to 1, which means the shading point emmits white color when the specular reflection happens.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;phong exponent&lt;/strong&gt;: increasing phong exponent $p$ will narrow the reflection lobe and accelerate the decay rate of the specular reflection effect as the angle increased.&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;When the angle between the reflected light and view direction more than 3~5 degree, we suppose specular reflection disappears.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUfSg.jpg&quot; alt=&quot;cg-5-12&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAU2Y8.jpg&quot; alt=&quot;cg-5-13&quot; width=&quot;780px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Compared to diffuse reflection, we ignore the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;energy received term&lt;/code&gt; for simplicity. Note that Blinn-Phong model is just an empirical model.&lt;/p&gt;

&lt;h3 id=&quot;ambient-term&quot;&gt;Ambient Term&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shading that does not depend on anything
    &lt;ul&gt;
      &lt;li&gt;Independent of light $l$ and view direction $v$&lt;/li&gt;
      &lt;li&gt;Add constant color to account for disregarded illumination and fill in black shadows&lt;/li&gt;
      &lt;li&gt;This is approximate / fake!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ambient coefficient&lt;/strong&gt;: similar to &lt;strong&gt;specular coefficient&lt;/strong&gt; and &lt;strong&gt;diffuse coefficient&lt;/strong&gt;, but this is always a constant.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUgFf.jpg&quot; alt=&quot;cg-5-14&quot; width=&quot;750px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;blinn-phong-model-1&quot;&gt;Blinn-Phong Model&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAU5Os.jpg&quot; alt=&quot;cg-5-15&quot; /&gt;&lt;/p&gt;

\[\begin{aligned} L &amp;amp;=L_{a}+L_{d}+L_{s} \\ &amp;amp;=k_{a} I_{a}+k_{d}\left(I / r^{2}\right) \max (0, \mathbf{n} \cdot \mathbf{l})+k_{s}\left(I / r^{2}\right) \max (0, \mathbf{n} \cdot \mathbf{h})^{p} \end{aligned}\]

&lt;h2 id=&quot;shading-frequencies&quot;&gt;Shading Frequencies&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Flat (Face) shading (逐片元)&lt;/li&gt;
  &lt;li&gt;Gouraud (Vertex) shading (逐顶点)&lt;/li&gt;
  &lt;li&gt;Phong (Pixel) shading (逐像素)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;flat-shading&quot;&gt;Flat shading&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shading for each triangle&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;normal vector&lt;/code&gt; of each face is caluculated by cross product of triangle’s two edges&lt;/li&gt;
  &lt;li&gt;Not good for smooth surfaces&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUomn.jpg&quot; alt=&quot;cg-5-16&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;gouraud-shading&quot;&gt;Gouraud shading&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shading for each vertices and &lt;strong&gt;interpolate&lt;/strong&gt; triangle from vertices&lt;/li&gt;
  &lt;li&gt;Each vertex has a normal vector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAU7T0.jpg&quot; alt=&quot;cg-5-17&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It is easy to obtain vertex normal from the underlying known geometry. e.g. sphere&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAaOEt.jpg&quot; alt=&quot;cg-5-20&quot; width=&quot;700px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Otherwise vertex normal can be inferred from surrounding triangle:
    &lt;ul&gt;
      &lt;li&gt;average surrounding face normals&lt;/li&gt;
      &lt;li&gt;weighted average surrounding face normals according to the area of each triangle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[N_{v}=\frac{\sum_{i} N_{i}}{\left\|\sum_{i} N_{i}\right\|}\]

&lt;h3 id=&quot;phong-shading&quot;&gt;Phong shading&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shading for each pixels across triangle&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;normal vector&lt;/code&gt; of each pixels is interpolated by vertex vector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUTwq.jpg&quot; alt=&quot;cg-5-18&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Phong shading&lt;/code&gt; is distinct from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Blinn-Phong reflectance model&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;pixel vector is computed by Barycentric interpolation of vertex normal&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUXpF.jpg&quot; alt=&quot;cg-5-22&quot; width=&quot;650px&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Caveat&lt;/strong&gt;: remember to normalize each normal vector after each step of interpolation.&lt;/p&gt;

&lt;h3 id=&quot;shading-difference&quot;&gt;Shading difference&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;As the model becomes more complex and has more vertices, the difference between three shading models become smaller&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUqYT.jpg&quot; alt=&quot;cg-5-19&quot; width=&quot;750px&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;shadow-mapping&quot;&gt;Shadow Mapping&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Draw shadows using rasterization&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Shadow gives people the feeling of objects in contact with each other&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;An Image-space Algorithm
    &lt;ul&gt;
      &lt;li&gt;no knowledge of scene’s geometry required during shadow computation&lt;/li&gt;
      &lt;li&gt;must deal with aliasing artifaces&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Key idea: the points NOT in shadow must be seen both by the light and by the camera&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Suppose the point light is the only source of light, which means the shadow of the object is 0 or 1, that is so-called &lt;strong&gt;hard shadow&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Step 1&lt;/strong&gt;: Assume the camera is at the point light source, perform depth test to record the depth information on the buffer.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 2&lt;/strong&gt;: From the view of the real camera, project all point in the view back to the point source light. If the the distance from the point to the light matches the depth, the point is visible, otherwise the point is blocked by other objects.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/16/sBaJCF.jpg&quot; alt=&quot;cg-5-25&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;visualizing-shadow-mapping&quot;&gt;Visualizing Shadow Mapping&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;A complex scene with shadows and without shadows&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/16/sBa68e.jpg&quot; alt=&quot;cg-5-26&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The depth buffer from the light’s point of view&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/16/sBa3NT.jpg&quot; alt=&quot;cg-5-27&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The shadow from the camera’s point of view
    &lt;ul&gt;
      &lt;li&gt;Green is where the distance from the light to shading point approximates to depth on buffer&lt;/li&gt;
      &lt;li&gt;Non-green is where shadows should be&lt;/li&gt;
      &lt;li&gt;Quality of shadow mapping is pretty bad due to the error caused by equality comparison of floating value&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/16/sBa1EV.jpg&quot; alt=&quot;cg-5-28&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;problems-with-shadow-mapping&quot;&gt;Problems with Shadow Mapping&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Only hard shadows in point light source can be mapped
    &lt;ul&gt;
      &lt;li&gt;If the light source is not limited to one and no more point-like, the shadow will be not hard.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Quality greatly depends on shadow map resolution, which is general problem with image-based rasterization techniques&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: In many games settings, the &lt;strong&gt;shadow quality&lt;/strong&gt; refers to the resolution of shadow map. The higher shadow quality sets, the better and more realistic the shadow will be mapped, and the higher it will cost.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Errors involves equality comparison of floating point
    &lt;ul&gt;
      &lt;li&gt;Sometimes use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bias&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eps&lt;/code&gt; to approximate the equality between distance and depth in buffer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hard-vs-soft-shadow&quot;&gt;Hard vs. Soft Shadow&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Soft shadow is caused by the &lt;strong&gt;size&lt;/strong&gt; of light source.
    &lt;ul&gt;
      &lt;li&gt;The light is not able to reach anywhere in &lt;strong&gt;Umbra region&lt;/strong&gt;.&lt;/li&gt;
      &lt;li&gt;Part of light is blocked but still some light can illuminate &lt;strong&gt;Penumbra&lt;/strong&gt; region.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/16/sBaQH0.jpg&quot; alt=&quot;cg-5-29&quot; width=&quot;65%&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Soft shadow is the transition from the umbra to penumbra to the illuminated region.
    &lt;ul&gt;
      &lt;li&gt;The shadow corresponding to the edge of the object is gradually vague and soft due to the light illumination.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Soft shadow is more realistic and natural because light source is not always point-like.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/16/sBaY34.jpg&quot; alt=&quot;cg-5-30&quot; width=&quot;80%&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;graphics-pipeline&quot;&gt;Graphics Pipeline&lt;/h2&gt;

&lt;h3 id=&quot;real-time-rendering-pipeline&quot;&gt;Real-time Rendering pipeline&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sEh9XR.jpg&quot; alt=&quot;cg-5-22&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;According to different shading frequency (face, vertex, pixel), Shading happens in Vertex Processing or Fragment Processing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Texture mapping also happens in Vertex Processing and Fragment Processing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Texture mapping is to assign vertices with different colors (properties, materials). This is the reason why objects look different in color and material after rendering. Detail in &lt;a href=&quot;/2020/09/07/cg-6&quot;&gt;Texture&lt;/a&gt; later.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sEhPn1.png&quot; alt=&quot;cg-5-23&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Fragment (片元) is widely used in OpenGL and other modern API, which commonly means Pixel. Fragment shading (processing) = Pixel shading (processing).&lt;/p&gt;

&lt;h3 id=&quot;shader-programs&quot;&gt;Shader Programs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Modern GPU allows to custom various shader by writing &lt;strong&gt;shader program&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Program vertex and fragment processing stages&lt;/li&gt;
      &lt;li&gt;Describe operation on a single vertex or fragment. Shader function executes once per fragment, thus there is no need to loop or traverse each vertex or fragment&lt;/li&gt;
      &lt;li&gt;Outputs color of surface at the current fragment’s screen sample position&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Example GLSL fragment shader program&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sampler2D&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myTexture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;// texture property&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lightDir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;// inversed light direction vector&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;varying&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;                    &lt;span class=&quot;c1&quot;&gt;// perfragment value (interp. by rasterizer)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;varying&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;                  &lt;span class=&quot;c1&quot;&gt;// norm vector, perfragment value (interp. by rasterizer)&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;diffuseShader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vec3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;                        &lt;span class=&quot;c1&quot;&gt;// vector3d to store color value&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;kd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texture2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;myTexture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// material color and property from texture&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;kd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;–&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lightDir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// diffuse shading&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;gl_FragColor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;// assign fragment color value to gl_FragColor&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;This shader performs a texture lookup to obtain the surface’s material color at this point&lt;/li&gt;
  &lt;li&gt;Then performs a diffuse lighting calculation&lt;/li&gt;
  &lt;li&gt;Vertex shader (顶点着色器) programs to each vertex, fragment shader （片元/像素着色器) programs to each pixel&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Info&lt;/strong&gt;: Incredible shader program and website: shadertoy.com&lt;/p&gt;

&lt;h3 id=&quot;highly-complex-3d-scenes-in-realtime&quot;&gt;Highly Complex 3D Scenes in Realtime&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Modern GPU could handle much complex 3D scenes in realtime by deploying great amount of computation in parallel.
    &lt;ul&gt;
      &lt;li&gt;thousands to millions of triangles in a scene&lt;/li&gt;
      &lt;li&gt;Complex vertex and fragment shader computations&lt;/li&gt;
      &lt;li&gt;High resolution (2-4 megapixel and supersampling)&lt;/li&gt;
      &lt;li&gt;30-60 fps (frames per second) and even higher for VR&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Game engine&lt;/strong&gt; (architecture) is designed for developers to focus more on constructing games instead of techniques of graphics or rendering. The core functionality typically by a game engine includes a rendering engine (renderer) for 2D or 3D graphics (including shadows, global illumination etc.), a physics engine including collision detection and response, animation, artifical intelligence, sounding, memory management, threading, precomputation etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gpu-graphics-pipeline-implementation&quot;&gt;GPU: Graphics Pipeline Implementation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Specialized processors for executing graphics pipeline computations&lt;/li&gt;
  &lt;li&gt;Heterogeneous, Multi-core Processor&lt;/li&gt;
  &lt;li&gt;Emerge different new shaders:
    &lt;ul&gt;
      &lt;li&gt;Geometry shader: govern the processing of primitives and produce more triangles&lt;/li&gt;
      &lt;li&gt;Compute shader: more general purpose for different computing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVF90I.jpg&quot; alt=&quot;cg-5-24&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;FLOPS (floating point operatins per second): measure of computer performance:&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Prefix&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Abbreviation&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Order of magnitude&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Computer performance&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Storage capacity&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;mega-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;M&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^6$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;megaFLOPS (MFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;megabyte (MB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;giga-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;G&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^9$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;gigaFLOPS (GFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;gigabyte (GB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;tera-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^{12}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;teraFLOPS (TFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;terabyte (TB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;peta-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;P&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^{15}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;petaFLOPS (PFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;petabyte (PB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;exa-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;E&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^{18}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;exaFLOPS (EFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;exabyte (EB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;zetta-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Z&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^{21}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;zettaFLOPS (ZFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;zettabyte (ZB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yotta-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^{24}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yottaFLOPS (YFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yottabyte (YB)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/53080536/answer/133398317&quot;&gt;光能、光通量、光强、亮度&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">Shading, Blinn-Phong Shading Model, Shading Frequency, Shadow Mapping, Graphics Pipeline</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅳ</title><link href="https://harrypotterrrr.github.io//2020/08/19/cg-4.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅳ" /><published>2020-08-19T00:00:00+08:00</published><updated>2020-08-19T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/08/19/cg-4</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/08/19/cg-4.html">&lt;p&gt;Rasterization, Sampling, Frequency and Filtering, Antialiasing, Z-buffer&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;after-viewing-transformation&quot;&gt;After Viewing transformation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Viewport transformation&lt;/strong&gt;: project the canonical cube $\left[-1, 1\right]^3$, we get from viewing transformation, to the screen.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;screen&quot;&gt;Screen&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;An array of pixels&lt;/li&gt;
  &lt;li&gt;Size of the array: resolution (i.e. 1920 x 1080)&lt;/li&gt;
  &lt;li&gt;A typical kind of raster display&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;raster&quot;&gt;Raster&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Raster&lt;/strong&gt; == screen in German&lt;/li&gt;
  &lt;li&gt;Rasterize – drawing onto the screen&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pixel&quot;&gt;Pixel&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;short for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;picture element&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;For now: A pixel is a little square with uniform color. &lt;a href=&quot;#Raster-displays&quot;&gt;Actually not&lt;/a&gt; in actual electronic display.&lt;/li&gt;
  &lt;li&gt;Color is a mixture of (red, green, blue)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the real displays of LCD screen. Each pixel is not uniform color, but R,G,B pixel geometry. Even so, now we assume a colored square full-color pixel.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rx0xXT.jpg&quot; alt=&quot;cg-4-7&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: Bayer Pattern(Filter) is shown on the right, where green elements are twice as many as  red or blue to mimic the physiology of the human eye which is more sensitive to green light.&lt;/p&gt;

&lt;h3 id=&quot;screen-space&quot;&gt;Screen space&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxwcR0.jpg&quot; alt=&quot;cg-4-1&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Following definition is slightly different from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tiger book&lt;/code&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Pixels indices are in the form of $(x,y)$, where both $x$ and $y$ are integers&lt;/li&gt;
      &lt;li&gt;Pixels indices are from $(0,0)$ to $(width-1, height-1)$&lt;/li&gt;
      &lt;li&gt;Pixel $(x,y)$ is centered at $(x+0.5, y+0.5)$&lt;/li&gt;
      &lt;li&gt;The screen covers range $(0,0)$ to $(width, height)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;canonical-cube-to-screen&quot;&gt;Canonical Cube to Screen&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxw6Gq.jpg&quot; alt=&quot;cg-4-2&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;irrelevant to $z$&lt;/li&gt;
  &lt;li&gt;Transform in $xy$ plane: $\left[-1, 1\right]^2$ to $\left[0, width\right]^2 \times \left[0, height\right]^2$&lt;/li&gt;
  &lt;li&gt;Viewport transform matrix&lt;/li&gt;
&lt;/ul&gt;

\[M_{\text {viewport}}=\left(\begin{array}{cccc}\frac{\text {width}}{2} &amp;amp; 0 &amp;amp; 0 &amp;amp; \frac{\text {width}}{2} \\ 0 &amp;amp; \frac{\text {height}}{2} &amp;amp; 0 &amp;amp; \frac{\text {height}}{2} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right)\]

&lt;h3 id=&quot;raster-displays&quot;&gt;Raster Displays&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;CRT (Cathode Ray Tube)&lt;/li&gt;
  &lt;li&gt;Television: Raster Display CRT&lt;/li&gt;
  &lt;li&gt;In fact, pixel, the component geometry in an image sensor or display, has three primary color: red, blue and green, which can be ordered in different patterns&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: On the memory of PC or Graphic Processing Unit (GPU), &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Frame Buffer&lt;/code&gt; is the memory for a raster display.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LCD (Liquid Crystal Display)
    &lt;ul&gt;
      &lt;li&gt;Principle: block or transmit light by twisting polarization(极化, 偏振方向)&lt;/li&gt;
      &lt;li&gt;Base on the wave property of light&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Electrophoretic&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rasterization&quot;&gt;Rasterization&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Rasterization&lt;/strong&gt;: Drawing to Raster Display&lt;/p&gt;

&lt;h3 id=&quot;triangles--fundamental-shape&quot;&gt;Triangles = Fundamental Shape&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Most basic polygon
    &lt;ul&gt;
      &lt;li&gt;break up other polygons&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Unique properties
    &lt;ul&gt;
      &lt;li&gt;Guaranteed to be planar&lt;/li&gt;
      &lt;li&gt;Well-defined interior (How about the polygon which has holes in it, and how about concave polygons?)&lt;/li&gt;
      &lt;li&gt;Well-defined method for interpolating values at vertices over triangle (barycentric interpolation)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;from-triangle-to-pixels&quot;&gt;From Triangle to pixels&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Input: position of traingle vertices projected on screen&lt;/li&gt;
  &lt;li&gt;Output: set of pixel values approximating triangle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxUIII.jpg&quot; alt=&quot;cg-4-3&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;sampling-a-function&quot;&gt;Sampling a Function&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Evaluating a function at a point is sampling, we can &lt;strong&gt;discretize&lt;/strong&gt; a function by sampling&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxbGnO.jpg&quot; alt=&quot;cg-4-8&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: Sampling is a core idea in graphics. i.e. We sample time(1D), area (2D), direction (2D), volumn (3D). Here, &lt;strong&gt;the centers&lt;/strong&gt; of pixels are used to sample &lt;strong&gt;screen space&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;rasterization-as-2d-sampling&quot;&gt;Rasterization as 2D Sampling&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Sample if each pixel center is inside triangle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxU5dA.jpg&quot; alt=&quot;cg-4-4&quot; width=&quot;430px&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;inside&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// x, y: not necessarily integers&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;triangle&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inside&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tri&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Use three &lt;a href=&quot;/2020/08/11/cg-2#cross-product&quot;&gt;cross product&lt;/a&gt; to check if the Point is inside the triangle or not.&lt;/li&gt;
  &lt;li&gt;Disregard edge cases when the sample point is exactly on the edge of the triangle.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Pixel values are integers so the center should be additional 0.5 amount.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use Bounding Box (axis aligned) to avoid checking all pixels on the screen and reduce great time consumption.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxUfqH.jpg&quot; alt=&quot;cg-4-5&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Incremental triangle traversal: traverse from the beginning of the left side of the triangle to the right.
    &lt;ul&gt;
      &lt;li&gt;Suitable for thin and rotated triangles, especially for those which has small area but consume the large proportion of bounding box&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxUTit.jpg&quot; alt=&quot;cg-4-6&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;sampling&quot;&gt;Sampling&lt;/h2&gt;

&lt;h3 id=&quot;ubiquitous-sampling&quot;&gt;Ubiquitous Sampling&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Rasterization = Sample 2D Positions&lt;/li&gt;
  &lt;li&gt;Photograph = Sample Image Sensor Plane&lt;/li&gt;
  &lt;li&gt;Video =  Sample Time&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;artifacts&quot;&gt;Artifacts&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Artifacts&lt;/strong&gt;: Errors, Mistakes, Inaccuracies&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Aliasing Artifacts due to sampling&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Jaggies: sampling in space
&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxbJBD.jpg&quot; alt=&quot;cg-4-9&quot; width=&quot;600px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Moire pattern: undersampling (skip odd rows and columns) images
&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxbh3q.jpg&quot; alt=&quot;cg-4-10&quot; width=&quot;600px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Wagon wheel effect: sampling in time of our eyes
&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxbgEQ.gif&quot; alt=&quot;cg-4-11&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-reason-behind-the-aliasing-artifact&quot;&gt;The reason behind the Aliasing Artifact&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Signals are changing too &lt;strong&gt;fast&lt;/strong&gt; (high frequency) but sampled too &lt;strong&gt;slowly&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;frequency-and-filtering&quot;&gt;Frequency and Filtering&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Central Idea: Blurring (pre-filtering) before sampling&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Directly sample: pixel values of jaggies in rasterized triangle are pure red or white&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/rzHG59.jpg&quot; alt=&quot;cg-4-12&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pre-filter before sample: pixel values of antialiased edges have intermediate values&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/rzH8UJ.jpg&quot; alt=&quot;cg-4-13&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: remove frequencies above &lt;a href=&quot;#nyquist-theory&quot;&gt;Nyquist&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The order of blurring and sampling matters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/rzH3E4.jpg&quot; alt=&quot;cg-4-14&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The above figures are sampling, antialiasing (filter then sample), blurred alisaing (sample then filter)&lt;/p&gt;

&lt;p&gt;The reason why undersampling introduces aliasing, and prefiltering then sampling can do antialiasing instead of the inversed operation will be explained at &lt;a href=&quot;#antialiasing&quot;&gt;Antialiasing&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;fourier-transform&quot;&gt;Fourier Transform&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Frequency&lt;/strong&gt;: $f$ in $sin(2\pi fx)$, where $f = \frac{1}{T}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Represent a function as a weighted sum of sines and cosines.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/sS9m8O.jpg&quot; alt=&quot;cg-4-15&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fourier transform decomposes a signal into frequencies, from spatial domain to frequency domain&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPyISO.png&quot; alt=&quot;cg-4-27&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;nyquist-theory&quot;&gt;Nyquist Theory&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Low frequency signal: sampled adequately for reasonable reconstruction&lt;/li&gt;
  &lt;li&gt;High frequency signal: insufficiently sampled and reconstruction is correct&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/sSiDZd.jpg&quot; alt=&quot;cg-4-16&quot; width=&quot;650px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Thus, higher frequencies need faster sampling&lt;/li&gt;
  &lt;li&gt;Strictly, the sampling frequency should at least be &lt;strong&gt;twice&lt;/strong&gt; the signal bandwidth. This frequency is called &lt;strong&gt;Nyquist rate&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/sSi0qH.jpg&quot; alt=&quot;cg-4-17&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Two frequencies (above blue and black) that are indistinguishable at a given sampling rate called &lt;strong&gt;aliases&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;filtering&quot;&gt;Filtering&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Filtering&lt;/strong&gt;: Getting rid of certain frequency contents&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/sSTicV.jpg&quot; alt=&quot;cg-4-18&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The right image shows the value of frequency domain which is transformed by Fourier Transform from the left image, spatial domain.&lt;/li&gt;
&lt;/ul&gt;

\[F(u, v)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} f(x, y) e^{-j 2 \pi(u x+v y)} d x d y\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Above two-dimensional transform formula shows that the original image $f(x,y)$ is transformed into $F(u,v)$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In the right figure, the center represents $u =0,v=0$, that is $F(0,0)$. This means the center of the image is the low frequency region, otherwise high frequency region.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;High-pass filter will get rid of all low frequency and keep edges of the image.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/03/spKY6A.jpg&quot; alt=&quot;cg-4-19&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Low-pass filter will filter the high frequency and retain the smooth part of the image.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/03/spKJld.jpg&quot; alt=&quot;cg-4-20&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: For the two-dimensional Fourier Transform, the image can be thought of as being tiled (stacked vertically and horizontally) infinitely. Thus two highlight strips in a cross shape at the center of the image is caused by the drastic change of the edges of the left figures.&lt;/p&gt;

&lt;h3 id=&quot;convolution&quot;&gt;Convolution&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Convolution in spatial domain is equivalent to multiplication in frequency domain, and vice versa&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;An intuitive proof&lt;/strong&gt;: The spatial domain signal can be decomposed into a series of sinusoidal signals with different frequencies. According to the distributive property of convolution operation, the convolution of two spatial signals can be regarded as the sum of the convolutions of pairwise sinusoidal signals. Since the result of the convolution of sinusodial signals with different frequencies is zero, only the convolution of sinusoidal signals with the same frequency is left. As a result, the output of convolution is that the frequency remains unchanged and the amplitude is to be multiplied. For frequency domain, it appears as direct multiplication.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Option 1:
    &lt;ul&gt;
      &lt;li&gt;Filter by convolution in the spatial domain&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Option 2:
    &lt;ul&gt;
      &lt;li&gt;Transform to frequency domain (Fourier transform)&lt;/li&gt;
      &lt;li&gt;Multiply by Fourier transform of convolution kernel&lt;/li&gt;
      &lt;li&gt;Transform back to spatial domain (inverse Fourier)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sCjpr9.jpg&quot; alt=&quot;cg-4-21&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Regularization term (i.e. $\frac{1}{9}$ in the above image) is to ensure the brightness of theimage does not change after transformation.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Wider Filter Kernel = Lower Frequency&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPyhY6.jpg&quot; alt=&quot;cg-4-22&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sampling = Repeating Frequency Contents&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPy4fK.jpg&quot; alt=&quot;cg-4-23&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(a) band-unlimited signal&lt;/li&gt;
  &lt;li&gt;(b) frequency spectrum of (a)&lt;/li&gt;
  &lt;li&gt;(c) unit-impulse function, which is used to simulate sampling&lt;/li&gt;
  &lt;li&gt;(d) frequency spectrum of (b)&lt;/li&gt;
  &lt;li&gt;(e) result of convolution of (a) and (c)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(f) result of multiplication of (d) and (f). More intuitive, (f) is copied for many times along the frequency axis.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Aliasing = Mixed Frequency Contents&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPygm9.jpg&quot; alt=&quot;cg-4-24&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;When the sampling interval becomes small, the corresponding sampling frequency will become relatively large, which will lead to the overlapping phenomenon in final frequency spectrum. Thus, aliasing is caused by information lost.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;antialiasing&quot;&gt;Antialiasing&lt;/h2&gt;

&lt;h3 id=&quot;basic-theory&quot;&gt;Basic theory&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Option 1: Increase sampling rate
    &lt;ul&gt;
      &lt;li&gt;Eseentially increasing the distance between replicas in the Fourier domain&lt;/li&gt;
      &lt;li&gt;Higher resolution displays, sensors, framebuffers..&lt;/li&gt;
      &lt;li&gt;Disadvantage: costly &amp;amp; may need very high resolution&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Option 2: Antialiasing
    &lt;ul&gt;
      &lt;li&gt;Making Fourier contents “narrower” before repeating&lt;/li&gt;
      &lt;li&gt;i.e. Filtering out high frequencies before sampling&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPy2wR.jpg&quot; alt=&quot;cg-4-25&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Perform filtering before the sampling will discard the high frequency and reduce the overlapping phenomenon, consequently reduce the loss of information and aliasing.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Antialiasing by averaging values in pixel area
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Convolve&lt;/strong&gt; by a 1-pixel box-blur (convolving = filtering = averaing)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Sample&lt;/strong&gt; at every pixel’s center&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;In rasterizing one triangle, the average value inside a pixel area is equal to the area of the pixel covered by the triangle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPyRT1.jpg&quot; alt=&quot;cg-4-26&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Sampling is an irreversable mapping, so the combination of convolution mapping and sampling is not commutative.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generally, antialiasing is to filter the high frequency signal so that the sampling frequency could catch up with the signal frequency.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;msaa&quot;&gt;MSAA&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;MSAA (multi-sample antialiasing) is to antialias by supersampling: Approximate the effect of the 1-pixel box filter by sampling multiple locations within a pixel and averagin their values.
    &lt;ul&gt;
      &lt;li&gt;One sample per pixel
&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sP2Ghq.jpg&quot; alt=&quot;cg-4-28&quot; width=&quot;650px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Take N x N samples in each pixel
&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sP2t3V.jpg&quot; alt=&quot;cg-4-29&quot; width=&quot;650px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Average the N x N samples inside each pixel
&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sP2Y90.jpg&quot; alt=&quot;cg-4-30&quot; width=&quot;650px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Until all pixel are averaged
&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sP28Nn.jpg&quot; alt=&quot;cg-4-31&quot; width=&quot;650px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Corresponding signal emitted by the display
&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sP23As.jpg&quot; alt=&quot;cg-4-32&quot; width=&quot;650px&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Take 4 x MSAA as an example, given a screen with a resolution of 800 x 600, MSAA firstly render the image to the buffer of 1600 x 1200, and downsample it back to the original 800 x 600.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The cost of MSAA is time consuming, the size of render target increases to the MSAA multiple times.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The more multiplier of MSAA, the better performace of antialiasing, the more cost of time.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;milestones-of-antialiasing&quot;&gt;Milestones of Antialiasing&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;FXAA (Fast Approximate AA): screen-space anti-aliasing algorithm. Different with MSAA which process the image before the sampling, FXAA postprocess the image after sampled and rasterized. FXAA contrast pixels to heuristically find edges and optimize jaggies in different directions. Very fast!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;TAA (Temporal AA) : reuse the previous frame and accordingly reduce the effects of temporal aliasing caused by the sampling rate of a scene being too low compared to the transformation speed of objects inside of the scene.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: We often pronounce &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[temˈporəl]&lt;/code&gt; in industry to distinguish with ‘temporary’ meaning.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Super resolution / super sampling
    &lt;ul&gt;
      &lt;li&gt;low resolution to high resolution&lt;/li&gt;
      &lt;li&gt;DLSS (Deep Learning Super Sampling): to understand and predict the missing information&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;visibility-and-occlusion&quot;&gt;Visibility and Occlusion&lt;/h2&gt;

&lt;h3 id=&quot;painters-algorithm&quot;&gt;Painter’s Algorithm&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Solve the problem of triangles rendering order&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Inspired by how painters paint: Paint from back to front, &lt;strong&gt;overwrite&lt;/strong&gt; in the framebuffer.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Require sorting in depth $Olog(n)$ for n triangles&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;unresolvable depth order exist:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/si29sS.png&quot; alt=&quot;cg-4-33&quot; width=&quot;250px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;z-buffer&quot;&gt;Z-Buffer&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;store current minimum of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z-value&lt;/code&gt; for each pixel&lt;/li&gt;
  &lt;li&gt;need an additional buffer for depth values
    &lt;ul&gt;
      &lt;li&gt;frame buffer stores color values&lt;/li&gt;
      &lt;li&gt;depth buffer (z-buffer) stores depth&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: For simplicity we suppose &lt;em&gt;z is always positive&lt;/em&gt; (smaller z is closer, larger z is further)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/si2pM8.jpg&quot; alt=&quot;cg-4-34&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Initialize&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buffer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inf&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// During rasterization&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;triangle&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// closest sample so far&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;frame_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rgb&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// update color&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;z_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// update depth&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pass&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// do nothing, this sample is occluded&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Complexity: $O(n)$ for traversing $n$ triangles&lt;/li&gt;
  &lt;li&gt;Different order of drawing triangles has nothing to do with the result&lt;/li&gt;
  &lt;li&gt;Most important visibility algorithm implemented in hardware for all GPUs&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: z-buffer can not deal with transparent objects.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/29246532&quot;&gt;图像傅里叶变换的频率&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/22611929&quot;&gt;二维傅里叶变换&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/20236638&quot;&gt;FXAA、MSAA区别&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">Rasterization, Sampling, Frequency and Filtering, Antialiasing, Z-buffer</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅲ</title><link href="https://harrypotterrrr.github.io//2020/08/15/cg-3.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅲ" /><published>2020-08-15T00:00:00+08:00</published><updated>2020-08-15T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/08/15/cg-3</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/08/15/cg-3.html">&lt;p&gt;2D/3D Transformation, Viewing Transformation&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;linear-transformations&quot;&gt;Linear Transformations&lt;/h2&gt;

&lt;h3 id=&quot;scale&quot;&gt;Scale&lt;/h3&gt;

\[\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right]=\left[\begin{array}{ll}s_{x} &amp;amp; 0 \\ 0 &amp;amp; s_{y}\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]\]

&lt;h3 id=&quot;reflection&quot;&gt;Reflection&lt;/h3&gt;

\[\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right]=\left[\begin{array}{cc}-1 &amp;amp; 0 \\ 0 &amp;amp; 1\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]\]

&lt;h3 id=&quot;shear&quot;&gt;Shear&lt;/h3&gt;

\[\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right]=\left[\begin{array}{ll}1 &amp;amp; a \\ 0 &amp;amp; 1\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]\]

&lt;h3 id=&quot;rotation&quot;&gt;Rotation&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rHDd58.jpg&quot; alt=&quot;cg-3-1&quot; /&gt;&lt;/p&gt;

\[\mathbf{R}_{\theta}=\left[\begin{array}{cc}\cos \theta &amp;amp; -\sin \theta \\ \sin \theta &amp;amp; \cos \hat{\theta}\end{array}\right]\]

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: For the rotation matrix $M$, which is always normalized in orthogonal form. Thus the transposed matrix $M^{T}$ is exactly inversed matrix $M^{-1}$, that is:
$M^{T}=M^{-1}$, where $M$ is orthogonal matrix&lt;/p&gt;

&lt;h3 id=&quot;linear-transformations-1&quot;&gt;Linear Transformations&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Use the same dimension matrix&lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned}\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right] &amp;amp;=\left[\begin{array}{ll}a &amp;amp; b \\ c &amp;amp; d\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right] \\ \mathbf{x}^{\prime} &amp;amp;=\mathbf{M} \mathbf{x} \end{aligned}\]

&lt;h2 id=&quot;affine-transformations&quot;&gt;Affine Transformations&lt;/h2&gt;

&lt;h3 id=&quot;homogeneous-coordinate&quot;&gt;Homogeneous Coordinate&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Translation cannot be represented in matrix form&lt;/li&gt;
&lt;/ul&gt;

\[\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right]=\left[\begin{array}{ll}a &amp;amp; b \\ c &amp;amp; d\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]+\left[\begin{array}{l}t_{x} \\ t_{y}\end{array}\right]\]

&lt;p&gt;Hence, translation is &lt;strong&gt;Not&lt;/strong&gt; linear transform&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;But we don’t want translation to be a special case, so is there a unified way to represent all transformations?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Add a third coordinate, and use 3D matrix to represent translations:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;2D point $=(x, y, 1)^{\top}$&lt;/li&gt;
      &lt;li&gt;2D vector $=(x, y, 0)^{\top}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\left(\begin{array}{c}x^{\prime} \\ y^{\prime} \\ w^{\prime}\end{array}\right)=\left(\begin{array}{ccc}1 &amp;amp; 0 &amp;amp; t_{x} \\ 0 &amp;amp; 1 &amp;amp; t_{y} \\ 0 &amp;amp; 0 &amp;amp; 1\end{array}\right) \cdot\left(\begin{array}{l}x \\ y \\ 1\end{array}\right)=\left(\begin{array}{c}x+t_{x} \\ y+t_{y} \\ 1\end{array}\right)\]

&lt;ul&gt;
  &lt;li&gt;Valid operation if w-coordinate of result is 1 or 0
    &lt;ul&gt;
      &lt;li&gt;vector + vector = vector&lt;/li&gt;
      &lt;li&gt;point - point = vector&lt;/li&gt;
      &lt;li&gt;point + vector = point&lt;/li&gt;
      &lt;li&gt;point + point = ?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: In homogenous coordinates,&lt;br /&gt;
\(\left(\begin{array}{l}x \\ y \\ w\end{array}\right)\) is the 2D point \(\left(\begin{array}{c}x / w \\ y / w \\ 1\end{array}\right), w \neq 0\)&lt;br /&gt;
Thus, &lt;strong&gt;point + point = midpoint of two points&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;affine-transformations-1&quot;&gt;Affine Transformations&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Affine map = linear map + translation&lt;/li&gt;
&lt;/ul&gt;

\[\left(\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right)=\left(\begin{array}{ll}a &amp;amp; b \\ c &amp;amp; d\end{array}\right) \cdot\left(\begin{array}{l}x \\ y\end{array}\right)+\left(\begin{array}{l}t_{x} \\ t_{y}\end{array}\right)\]

&lt;ul&gt;
  &lt;li&gt;Using homogenous coordinates:&lt;/li&gt;
&lt;/ul&gt;

\[\left(\begin{array}{l}x^{\prime} \\ y^{\prime} \\ 1\end{array}\right)=\left(\begin{array}{lll}a &amp;amp; b &amp;amp; t_{x} \\ c &amp;amp; d &amp;amp; t_{y} \\ 0 &amp;amp; 0 &amp;amp; 1\end{array}\right) \cdot\left(\begin{array}{l}x \\ y \\ 1\end{array}\right)\]

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: This means linear transform first, and then translation.&lt;/p&gt;

&lt;h3 id=&quot;inverse-transform&quot;&gt;Inverse Transform&lt;/h3&gt;

&lt;p&gt;$\mathbf{M}^{-1}$ is the inverse of transform $\mathbf{M}$ in both a matrix and geometric sense.&lt;/p&gt;

&lt;h2 id=&quot;composite-transform&quot;&gt;Composite transform&lt;/h2&gt;

&lt;h3 id=&quot;composing-transforms&quot;&gt;Composing Transforms&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Matrix multiplication is not &lt;strong&gt;commutative&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;For a sequence of affine transforms $A_{1}, A_{2}, A_{3}, \ldots$
    &lt;ul&gt;
      &lt;li&gt;Compose by matrix multiplication to speed up:
  \(A_{n}\left(\ldots A_{2}\left(A_{1}(\mathbf{x})\right)\right)=\mathbf{A}_{n} \cdots \mathbf{A}_{2} \cdot \mathbf{A}_{1} \cdot\left(\begin{array}{l}x \\ y \\ 1\end{array}\right)\)&lt;/li&gt;
      &lt;li&gt;Pre-multiply n matrices to obtain a single matrix $\mathbf{A}_{n} \cdots \mathbf{A}_{2} \cdot \mathbf{A}_{1}$ representing combined transform&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;decomposing-complex-transforms&quot;&gt;Decomposing Complex Transforms&lt;/h3&gt;

&lt;p&gt;How to rotate around a given point c?&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Translate center to origin&lt;/li&gt;
  &lt;li&gt;Rotate&lt;/li&gt;
  &lt;li&gt;Translate Back&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rH7d3j.jpg&quot; alt=&quot;cg-3-2&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3d-transformations&quot;&gt;3D transformations&lt;/h2&gt;

&lt;h3 id=&quot;rotation-around-x-y-z-axis&quot;&gt;Rotation around x, y, z-axis&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rHLZMd.jpg&quot; alt=&quot;cg-3-3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;\(\mathbf{R}_{x}(\alpha)=\left(\begin{array}{cccc}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \cos \alpha &amp;amp; -\sin \alpha &amp;amp; 0 \\ 0 &amp;amp; \sin \alpha &amp;amp; \cos \alpha &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right)\)&lt;br /&gt;
\(\mathbf{R}_{y}(\alpha)=\left(\begin{array}{cccc}\cos \alpha &amp;amp; 0 &amp;amp; \sin \alpha &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\ -\sin \alpha &amp;amp; 0 &amp;amp; \cos \alpha &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right)\)&lt;br /&gt;
\(\mathbf{R}_{z}(\alpha)=\left(\begin{array}{cccc}\cos \alpha &amp;amp; -\sin \alpha &amp;amp; 0 &amp;amp; 0 \\ \sin \alpha &amp;amp; \cos \alpha &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right)\)&lt;/p&gt;

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Caveat&lt;/strong&gt;: In $\mathbf{R}_{y}$, where we use right-hand rule $z \times x$ get $y$, so the $\alpha$ is opposite.&lt;/p&gt;

&lt;h3 id=&quot;euler-angles&quot;&gt;Euler angles&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;To represent any 3D rotation from $\mathbf{R}_{x}, \mathbf{R}_{y}, \mathbf{R}_{z}$,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\mathbf{R}_{x y z}(\alpha, \beta, \gamma)=\mathbf{R}_{x}(\alpha) \mathbf{R}_{y}(\beta) \mathbf{R}_{z}(\gamma)$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$(\alpha, \beta, \gamma)$ is &lt;strong&gt;Euler angles&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Often used in flight simulator:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rb2SjU.jpg&quot; alt=&quot;cg-3-4&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Eluer angles may cause &lt;a href=&quot;https://en.wikipedia.org/wiki/Gimbal_lock&quot;&gt;Gimbal lock&lt;/a&gt;: The loss of one degree of &lt;strong&gt;freedom&lt;/strong&gt;.
    &lt;ul&gt;
      &lt;li&gt;This suitation occurs when the axes of two of the three gimbals are driven into a parallel configuration as the below shows.&lt;/li&gt;
      &lt;li&gt;Use &lt;a href=&quot;https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation&quot;&gt;Unit quaternions&lt;/a&gt; to solve this problem&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rbh2WR.gif&quot; alt=&quot;cg-3-5&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;rodrigues-rotation-formula&quot;&gt;Rodrigues’ Rotation Formula&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Rotation by angle $\alpha$ around axis $n$ (axis $n$ goes through the origin)&lt;/li&gt;
&lt;/ul&gt;

\[\mathbf{R}(\mathbf{n}, \alpha)=\cos (\alpha) \mathbf{I}+(1-\cos (\alpha)) \mathbf{n} \mathbf{n}^{T}+\sin (\alpha) \underbrace{\left(\begin{array}{ccc}0 &amp;amp; -n_{z} &amp;amp; n_{y} \\ n_{z} &amp;amp; 0 &amp;amp; -n_{x} \\ -n_{y} &amp;amp; n_{x} &amp;amp; 0\end{array}\right)}_{\mathbf{N}}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Formula &lt;a href=&quot;https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula#Derivation&quot;&gt;derivation&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If the rotation axis doesn’t go through the origin, but at $p$&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Translate the axis to origin. $T(-p)$&lt;/li&gt;
      &lt;li&gt;Rotate. $R(n, \alpha)$&lt;/li&gt;
      &lt;li&gt;Translate the axis back: $T(p)$&lt;/li&gt;
      &lt;li&gt;Thus: $T(p)R(n, \alpha)T(-p)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;viewing-transformation&quot;&gt;Viewing transformation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;View / Camera Transformation&lt;/li&gt;
  &lt;li&gt;Projection transformation
    &lt;ul&gt;
      &lt;li&gt;Orthographics projection&lt;/li&gt;
      &lt;li&gt;Perspective projection&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;a-vivid-analogy&quot;&gt;A vivid analogy&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Analogous to taking a photo:
    &lt;ul&gt;
      &lt;li&gt;Find a good place and arrage people (&lt;strong&gt;model&lt;/strong&gt; transformation)&lt;/li&gt;
      &lt;li&gt;Find a good “angle” to put the camera (&lt;strong&gt;view&lt;/strong&gt; transformation)&lt;/li&gt;
      &lt;li&gt;Cheese! (&lt;strong&gt;projection&lt;/strong&gt; transformation)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;view--camera-transformation&quot;&gt;View / Camera Transformation&lt;/h3&gt;

&lt;h4 id=&quot;define-the-camera&quot;&gt;Define the camera&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Define the camera first (suppose every objects has been arranged properly)
    &lt;ul&gt;
      &lt;li&gt;Position $\vec{e}$&lt;/li&gt;
      &lt;li&gt;Look-at / gaze direction $\hat{g}$&lt;/li&gt;
      &lt;li&gt;up direction $\hat{t}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rbgzcT.jpg&quot; alt=&quot;cg-3-6&quot; width=&quot;380px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Key observation: If the camera and all objects move together, the photo will be the same. Thus we transform the camera to the fixed origin point.
    &lt;ul&gt;
      &lt;li&gt;Position: the origin&lt;/li&gt;
      &lt;li&gt;Look-at direction: -Z&lt;/li&gt;
      &lt;li&gt;up  direction: Y&lt;/li&gt;
      &lt;li&gt;Then transform the objects along with the fixed camera&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rbgx3V.jpg&quot; alt=&quot;cg-3-7&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;transform-the-camera&quot;&gt;Transform the camera&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Transform the camera by $M_{\text {view}}$
    &lt;ul&gt;
      &lt;li&gt;To locate it at the origin, up at $Y$, look at $Z$
        &lt;ul&gt;
          &lt;li&gt;Translates $e$ to origin&lt;/li&gt;
          &lt;li&gt;Rotates $t$ to $Y$&lt;/li&gt;
          &lt;li&gt;Rotates $g$ to $-Z$&lt;/li&gt;
          &lt;li&gt;If $t$ to $Y$ and $g$ to $-Z$, then $\hat{g} \times \hat{t}$ will be to $X$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rqnfI0.jpg&quot; alt=&quot;cg-3-8&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$M_{\text {view}}=R_{\text {view}}T_{\text {view}}$
    &lt;ul&gt;
      &lt;li&gt;Translate $e$ to origin&lt;br /&gt;
\(T_{v i e w}=\left[\begin{array}{cccc}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; -x_{e} \\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; -y_{e} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; -z_{e} \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right]\)&lt;/li&gt;
      &lt;li&gt;Difficult to directly get $R_{view}$, so consider its inverse rotation: &lt;br /&gt;
\(R_{v i e w}^{-1}=\left[\begin{array}{cccc}x_{\hat{g} \times \hat{t}} &amp;amp; x_{t} &amp;amp; x_{-g} &amp;amp; 0 \\ y_{\hat{g} \times \hat{t}} &amp;amp; y_{t} &amp;amp; y_{-g} &amp;amp; 0 \\ z_{\hat{g} \times \hat{t}} &amp;amp; z_{t} &amp;amp; z_{-g} &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right] \quad \Rightarrow  \quad R_{v i e w} = (R_{v i e w}^{-1})^{T} = \left[\begin{array}{cccc}x_{\hat{g} \times \hat{t}} &amp;amp; y_{\hat{g} \times \hat{t}} &amp;amp; z_{\hat{g} \times \hat{t}} &amp;amp; 0 \\ x_{t} &amp;amp; y_{t} &amp;amp; z_{t} &amp;amp; 0 \\ x_{-g} &amp;amp; y_{-g} &amp;amp; z_{-g} &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right]\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: We can validate the result of the multiplication of $R_{v i e w}^{-1}$ and the vector $\left(\begin{array}{llll}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\end{array}\right)$ which represents $X$ axis, the vector $\left(\begin{array}{llll}0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0\end{array}\right)$ which represents $Y$ axis, and the vector $\left(\begin{array}{llll}0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0\end{array}\right)$ which represents $Z$ axis. We could find $X$ axis rotates to $\hat{g} \times \hat{t}$, $Y$ rotates to $t$ and $Z$ rotates to $-g$.&lt;/p&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Each column of the $R_{view}$ except for the last column is the &lt;strong&gt;unit&lt;/strong&gt; vector describing the camera, so the transposed matrix of it is its inversed matrix itself.&lt;/p&gt;

&lt;h3 id=&quot;projection-transformation&quot;&gt;Projection transformation&lt;/h3&gt;

&lt;h4 id=&quot;projection-in-computer-graphics&quot;&gt;Projection in Computer Graphics&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;In orthogonal projection, the camera can be supposed to be placed infinite way from the viewing frustum (now the frustum becomes cuboid).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/31/rvExG6.jpg&quot; alt=&quot;cg-3-9&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;orthographic-projection&quot;&gt;Orthographic Projection&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Camera located at origin, looking at -Z, up at Y&lt;/li&gt;
  &lt;li&gt;Drop Z coordinate&lt;/li&gt;
  &lt;li&gt;Translate and scale the resulting rectangle to $\left[-1, 1\right]^2$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/31/rvEvPx.jpg&quot; alt=&quot;cg-3-10&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;More in general: map a cuboid $\left[l, r\right] \times \left[b, t\right] \times \left[f, n\right]$ to the canonical cube $\left[-1, 1\right]^3$. (left, right, bottom, top, far, near)
    &lt;ul&gt;
      &lt;li&gt;Translate the center to origin first, then scale each edge to 2.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[M_{\text {ortho}}=\left[\begin{array}{cccc}\frac{2}{r-l} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{2}{t-b} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{2}{n-f} &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right]\left[\begin{array}{cccc}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; -\frac{r+l}{2} \\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; -\frac{t+b}{2} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; -\frac{n+f}{2} \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right]\]

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Objects may be stretched out of the original scale, so the next &lt;a href=&quot;/2020/08/19/cg-4#canonical-cube-to-screen&quot;&gt;viewport transform&lt;/a&gt; will deal with this and draw it back to the original scale.&lt;/p&gt;

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Caveat&lt;/strong&gt;: Looking along $-Z$ makes &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f&lt;/code&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;near&lt;/code&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;far&lt;/code&gt;) and this is the reason why OpenGL uses left hand coords.&lt;/p&gt;

&lt;h4 id=&quot;perspective-projection&quot;&gt;Perspective Projection&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Most common in Computer Graphics, art, visual system&lt;/li&gt;
  &lt;li&gt;Further objects are smaller&lt;/li&gt;
  &lt;li&gt;Parallel lines not parallel, converge to single point&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: We only consider Euclidean Geometry (Not Riemannian Geometry)&lt;/p&gt;

&lt;p&gt;The step to do perspective projection&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;First squish the frustum into a cuboid $M_{\text {persp} \rightarrow \text {ortho}}$&lt;/li&gt;
  &lt;li&gt;Do orthographic projection $M_{ortho}$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/31/rvVBw9.jpg&quot; alt=&quot;cg-3-11&quot; width=&quot;640px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Denote vertical &lt;strong&gt;field-of-view (fovY)&lt;/strong&gt; and &lt;strong&gt;aspect&lt;/strong&gt; ratio (assume symmetry i.e. $l=-r\ b=-t$)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rvvjfJ.jpg&quot; alt=&quot;cg-3-13&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

\[Aspect\ Ratio=\frac{width}{height}\]

&lt;ul&gt;
  &lt;li&gt;Convert &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fovY&lt;/code&gt; and aspect to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l, r, b, t&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rvxiTO.jpg&quot; alt=&quot;cg-3-14&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

\[\begin{aligned} \tan \frac{f o v Y}{2} &amp;amp;=\frac{t}{|n|} \\ \text { aspect } &amp;amp;=\frac{r}{t} \end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;Find the relationship between transformed points $\left(x^{\prime}, y^{\prime}, z^{\prime}\right)$ and original points $\left(x, y, z)\right)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/31/rvVL6S.jpg&quot; alt=&quot;cg-3-12&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

\[y^{\prime}=\frac{n}{z} y\]

&lt;p&gt;Similar to $x$:&lt;/p&gt;

\[x^{\prime}=\frac{n}{z} x\]

&lt;ul&gt;
  &lt;li&gt;Use homogenous coordinates to represent this relationship:&lt;/li&gt;
&lt;/ul&gt;

\[\left(\begin{array}{l}x \\ y \\ z \\ 1\end{array}\right) \Rightarrow\left(\begin{array}{c}n x / z \\ n y / z \\ \text { unknown } \\ 1\end{array}\right) \begin{array}{l} == \end{array}\left(\begin{array}{c}n x \\ n y \\ \text { still unknown } \\ z\end{array}\right)\]

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: according to the points defined in homogenous coordinates. &lt;a href=&quot;#homogeneous-coordinate&quot;&gt;reference&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;So the operation squish should be the following form:&lt;/li&gt;
&lt;/ul&gt;

\[M_{\text {persp} \rightarrow \text {ortho}}^{(4 \times 4)}\left(\begin{array}{l}x \\ y \\ z \\ 1\end{array}\right)=\left(\begin{array}{c}n x \\ n y \\ \text { unknown } \\ z\end{array}\right)\]

&lt;ul&gt;
  &lt;li&gt;Three known parameters could get a good reference of three rows of $M_{\text {persp} \rightarrow \text {ortho}}$:&lt;/li&gt;
&lt;/ul&gt;

\[M_{\text {persp} \rightarrow \text {ortho}}=\left(\begin{array}{cccc}n &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; n &amp;amp; 0 &amp;amp; 0 \\ ? &amp;amp; ? &amp;amp; ? &amp;amp; ? \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0\end{array}\right)\]

&lt;ul&gt;
  &lt;li&gt;Two important observations, which is responsible for $z^{\prime}$:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1. Any point on the near plane will not change&lt;/p&gt;

\[M_{\text {persp} \rightarrow \text {ortho}}^{(4 \times 4)}\left(\begin{array}{l}x \\ y \\ z \\ 1\end{array}\right)=\left(\begin{array}{c}n x \\ n y \\ \text { unknown } \\ z\end{array}\right) \quad \begin{array}{l}\end{array}\]

&lt;p&gt;Replace $z$ with $n$:&lt;/p&gt;

\[\left(\begin{array}{l}x \\ y \\ n \\ 1\end{array}\right) \Rightarrow\left(\begin{array}{l}x \\ y \\ n \\ 1\end{array}\right)==\left(\begin{array}{c}n x \\ n y \\ n^{2} \\ n\end{array}\right)\]

&lt;p&gt;Thus, the third row must be of the form $(0\ 0\ A\ B)$:&lt;/p&gt;

\[\left(\begin{array}{llll}0 &amp;amp; 0 &amp;amp; A &amp;amp; B\end{array}\right)\left(\begin{array}{l}x \\ y \\ n \\ 1\end{array}\right)=n^{2}\]

\[A n+B=n^{2}\]

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: $n$ is only the known paramter, and has nothing to do with $z$, so $A$ and $B$ can not be determined yet.&lt;/p&gt;

&lt;p&gt;2. Any $z$ of points on the far plane will not change&lt;/p&gt;

\[\left(\begin{array}{l}0 \\ 0 \\ f \\ 1\end{array}\right) \Rightarrow\left(\begin{array}{l}0 \\ 0 \\ f \\ 1\end{array}\right)==\left(\begin{array}{l}0 \\ 0 \\ f^{2} \\ f\end{array}\right)\]

\[A f+B=f^{2}\]

&lt;ul&gt;
  &lt;li&gt;From the two above equations we get, we could solve $A$ and $B$:&lt;/li&gt;
&lt;/ul&gt;

\[\left\{\begin{array}{l}A n+B=n^{2} \\ A f+B=f^{2}\end{array}\right. \Rightarrow \left\{\begin{array}{l}A=n+f \\ B=-n f\end{array}\right.\]

&lt;ul&gt;
  &lt;li&gt;Now, every entry of $M_{\text {persp} \rightarrow \text {ortho}}$ is known:&lt;/li&gt;
&lt;/ul&gt;

\[M_{\text {persp} \rightarrow \text {ortho}}=\left(\begin{array}{cccc}n &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; n &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; n+f &amp;amp; -nf \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0\end{array}\right)\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Finally, do orthographic projection $M_{ortho}$ to finish&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In summary: $M_{\text {persp}}=M_{\text {ortho}} M_{\text {persp} \rightarrow \text {ortho}}$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/47736315&quot;&gt;如何通俗地解释欧拉角？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/AndrewFan/article/details/60981437#&quot;&gt;欧拉角与万向节死锁&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">2D/3D Transformation, Viewing Transformation</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅱ</title><link href="https://harrypotterrrr.github.io//2020/08/11/cg-2.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅱ" /><published>2020-08-11T00:00:00+08:00</published><updated>2020-08-11T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/08/11/cg-2</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/08/11/cg-2.html">&lt;p&gt;A swift and brutal review of Linear Algebra&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;computer-graphics-dependencies&quot;&gt;Computer Graphics’ Dependencies&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Basic mathematics
    &lt;ul&gt;
      &lt;li&gt;Linear algebra&lt;/li&gt;
      &lt;li&gt;Calculus&lt;/li&gt;
      &lt;li&gt;Statistics&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Basic physics
    &lt;ul&gt;
      &lt;li&gt;Optics (Advanced: if we could not suppose the light travels in straight lines but interacts with a surface material in a form of light wave?)&lt;/li&gt;
      &lt;li&gt;Mechanics&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Misc.
    &lt;ul&gt;
      &lt;li&gt;Signal processing (for anti-alias)&lt;/li&gt;
      &lt;li&gt;Numerical analysis (rendering is to find a solution of calculus defined by recursion, simulation is to solve FEA, Finite Element Analysis, or diffusion equation)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;A bit of aesthetics&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;vector&quot;&gt;Vector&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Direction and length&lt;/li&gt;
  &lt;li&gt;Usually written as $\vec{a}$ or using start and end point $\overrightarrow{AB}$&lt;/li&gt;
  &lt;li&gt;No absolute starting position&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vector-normalization&quot;&gt;Vector Normalization&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Magnitude (length) of a vector written as $|\vec{a}|$&lt;/li&gt;
  &lt;li&gt;Unit vector
    &lt;ul&gt;
      &lt;li&gt;A vector with length of 1&lt;/li&gt;
      &lt;li&gt;$\hat{a}=\vec{a} /|\vec{a}|$&lt;/li&gt;
      &lt;li&gt;represent directions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vector-addition&quot;&gt;Vector Addition&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Geometrically: Parallelogram law &amp;amp; Triangle law&lt;/li&gt;
  &lt;li&gt;Algebraically: Simply add coordinates&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dot-scalar-product&quot;&gt;Dot (scalar) Product&lt;/h3&gt;

&lt;p&gt;$\vec{a} \cdot \vec{b}=|\vec{a}||\vec{b}| \cos \theta$&lt;/p&gt;

&lt;p&gt;For unit vectors:&lt;/p&gt;

&lt;p&gt;$\cos \theta=\hat{a} \cdot \hat{b}$&lt;/p&gt;

&lt;p&gt;Some properties:&lt;/p&gt;

&lt;p&gt;$\vec{a} \cdot \vec{b}=\vec{b} \cdot \vec{a}$&lt;/p&gt;

&lt;p&gt;$\vec{a} \cdot(\vec{b}+\vec{c})=\vec{a} \cdot \vec{b}+\vec{a} \cdot \vec{c}$&lt;/p&gt;

&lt;p&gt;$(k \vec{a}) \cdot \vec{b}=\vec{a} \cdot(k \vec{b})=k(\vec{a} \cdot \vec{b})$&lt;/p&gt;

&lt;p&gt;For component-wise multiplication of vectors in Cartesian coordinates:&lt;/p&gt;

\[\vec{a} \cdot \vec{b}=\left(\begin{matrix}x_{a} \\ y_{a} \\ z_{a}\end{matrix}\right) \cdot\left(\begin{matrix}x_{b} \\ y_{b} \\ z_{b}\end{matrix}\right)=x_{a} x_{b}+y_{a} y_{b}+z_{a} z_{b}\]

&lt;p&gt;&lt;strong&gt;Four common usages of dot product&lt;/strong&gt;:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;To find angle between two vectors&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To find projection of one vector on another:&lt;/p&gt;

    &lt;p&gt;To Calculate $\vec{b}_{\perp}$: projection of $\vec{b}$ onto $\vec{a}$&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;$\vec{b}_{\perp}$ must be along $\vec{a}$, thus $\vec{b}_{\perp}=k \hat{a}$&lt;/li&gt;
      &lt;li&gt;The magnitude of $k$ is $\left|\vec{b}_{\perp}\right|=|\vec{b}| \cos \theta$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;To measure how close two directions are&lt;/li&gt;
  &lt;li&gt;To decompose a vector:  $\vec{b}$, $\vec{b}_{\perp}$, $\vec{b}-\vec{b}_{\perp}$&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;cross-product&quot;&gt;Cross Product&lt;/h3&gt;

&lt;p&gt;$|a \times b|=|a||b| \sin \phi$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cross product is orthogonal to two initial vectors&lt;/li&gt;
  &lt;li&gt;Direction determined by right-hand rule&lt;/li&gt;
  &lt;li&gt;To construct coordinate systems&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some properties:&lt;/p&gt;

&lt;p&gt;$\vec{a} \times \vec{b}=-\vec{b} \times \vec{a}$&lt;/p&gt;

&lt;p&gt;$\vec{a} \times \vec{a}=\overrightarrow{0}$&lt;/p&gt;

&lt;p&gt;$\vec{a} \times(\vec{b}+\vec{c})=\vec{a} \times \vec{b}+\vec{a} \times \vec{c}$&lt;/p&gt;

&lt;p&gt;$\vec{a} \times(k \vec{b})=k(\vec{a} \times \vec{b})$&lt;/p&gt;

&lt;p&gt;For cross product in Cartesian Formula:&lt;/p&gt;

\[\vec{a} \times \vec{b}=\left(\begin{array}{l}y_{a} z_{b}-y_{b} z_{a} \\ z_{a} x_{b}-x_{a} z_{b} \\ x_{a} y_{b}-y_{a} x_{b}\end{array}\right)\]

&lt;p&gt;Or using matrix form:&lt;/p&gt;

\[\vec{a} \times \vec{b}=A^{*} b=\left(\begin{array}{ccc}0 &amp;amp; -z_{a} &amp;amp; y_{a} \\ z_{a} &amp;amp; 0 &amp;amp; -x_{a} \\ -y_{a} &amp;amp; x_{a} &amp;amp; 0\end{array}\right)\left(\begin{array}{l}x_{b} \\ y_{b} \\ z_{b}\end{array}\right)\]

&lt;p&gt;&lt;strong&gt;Two common usages of cross product:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/r7oeXV.jpg&quot; alt=&quot;cg-2-1&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;To determine left/right: check if the cross product of two vectors points to the outside of the screen or out.&lt;/li&gt;
  &lt;li&gt;To determine inside/outside: check if the cross product of $\overrightarrow{AB} \times \overrightarrow{AP}$ and $\overrightarrow{BP} \times \overrightarrow{BP}$ and $\overrightarrow{CA} \times \overrightarrow{CP}$ all directed to the outside of the screen.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;orthonormal-coordinate&quot;&gt;Orthonormal Coordinate&lt;/h3&gt;

&lt;p&gt;We can decompose any vectors $\vec{p}$ by 3 unit vectors:&lt;/p&gt;

&lt;p&gt;$\vec{p}=(\vec{p} \cdot \vec{u}) \vec{u}+(\vec{p} \cdot \vec{v}) \vec{v}+(\vec{p} \cdot \vec{w}) \vec{w}$&lt;br /&gt;
, where&lt;br /&gt;
$|\vec{u}|=|\vec{v}|=|\vec{w}|=1$&lt;br /&gt;
$\vec{u} \cdot \vec{v}=\vec{v} \cdot \vec{w}=\vec{u} \cdot \vec{w}=0$&lt;br /&gt;
$\vec{w}=\vec{u} \times \vec{v} \quad$&lt;/p&gt;

&lt;h2 id=&quot;matrix&quot;&gt;Matrix&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;2D arrays that haunt in every CS course&lt;/li&gt;
  &lt;li&gt;In Graphics, pervasively used to represent &lt;strong&gt;transformations&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;matrix-matrix-multiplication&quot;&gt;Matrix-Matrix Multiplication&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;columns in A must = rows in B&lt;/li&gt;
  &lt;li&gt;Element (i, j) in the product is the dot product of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;row i from A&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;column j from B&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some properties:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Non-commutative: ($AB$ and $BA$ are different in general)&lt;/li&gt;
  &lt;li&gt;Associative and distributive:
    &lt;ul&gt;
      &lt;li&gt;$(AB)C = A(BC)$&lt;/li&gt;
      &lt;li&gt;$A(B+C) = AB + AC$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;matrix-vecotr-multiplication&quot;&gt;Matrix-Vecotr Multiplication&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Treat vector as a &lt;strong&gt;column matrix&lt;/strong&gt; (Mx1)&lt;/li&gt;
  &lt;li&gt;Treat vector as the right multiplier of the matrix (as a point)&lt;/li&gt;
  &lt;li&gt;Key for transforming points&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;transpose-of-a-matrix&quot;&gt;Transpose of a Matrix&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Switch rows and columns ($ij$ to $ji$)&lt;/li&gt;
  &lt;li&gt;$(A B)^{T}=B^{T} A^{T}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;identity-matrix-and-inverses&quot;&gt;Identity Matrix and Inverses&lt;/h3&gt;

\[I_{3 \times 3}=\left(\begin{array}{lll}1 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1\end{array}\right)\]

&lt;p&gt;$A A^{-1}=A^{-1} A=I$&lt;/p&gt;

&lt;p&gt;$(A B)^{-1}=B^{-1} A^{-1}$&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">A swift and brutal review of Linear Algebra</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅰ</title><link href="https://harrypotterrrr.github.io//2020/08/10/cg-1.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅰ" /><published>2020-08-10T00:00:00+08:00</published><updated>2020-08-10T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/08/10/cg-1</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/08/10/cg-1.html">&lt;p&gt;An Overview to Computer Graphics&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;computer-graphics&quot;&gt;Computer Graphics&lt;/h2&gt;

&lt;p&gt;To synthesis and manipulate visual information.&lt;/p&gt;

&lt;h3 id=&quot;application&quot;&gt;Application&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Video Games&lt;/strong&gt;: Technically, global illumination determines the quality of the game performance: the lighter the graphics shows, the better the game is.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Movies&lt;/strong&gt;: Special effects&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Animations&lt;/strong&gt;: Simulate particles in different scenes.&lt;/li&gt;
  &lt;li&gt;Design&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Visualization&lt;/strong&gt;: One of the way to manipulate visual information.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Virtual Reality &amp;amp; Augmented Reality&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Digital Illustration&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Simulation&lt;/strong&gt;: physical simulation, computation and implementation.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Graphical User Interface&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Topography&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;fundamental-challenge&quot;&gt;Fundamental Challenge&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Require understanding of all aspects of physical world&lt;/li&gt;
  &lt;li&gt;Create and interact with realistic virtual world&lt;/li&gt;
  &lt;li&gt;Computing methods, displays, technology.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;topics&quot;&gt;Topics&lt;/h2&gt;

&lt;h3 id=&quot;rasterization&quot;&gt;Rasterization&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Project &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;geometry primitives&lt;/code&gt; (3D triangles/polygons) on to the screen.&lt;/li&gt;
  &lt;li&gt;Break projected primitives into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fragments&lt;/code&gt; (pixels)&lt;/li&gt;
  &lt;li&gt;Gold standard in Video Games (Real-time Applications)&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Real-time/offline computer graphics&lt;/strong&gt;: more than 30 fps (frame per second)&lt;/p&gt;

&lt;h3 id=&quot;curves-and-meshes&quot;&gt;Curves and Meshes&lt;/h3&gt;

&lt;p&gt;How to represent geometry in Computer Graphics&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bezier Curve&lt;/li&gt;
  &lt;li&gt;Catmull-Clark subdivision&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ray-tracing&quot;&gt;Ray Tracing&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shoot rays from the camera through each pixel&lt;/li&gt;
  &lt;li&gt;Gold standard in Animations / Movies (Offline Application)\&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;animation--simulation&quot;&gt;Animation / Simulation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Key frame animation&lt;/li&gt;
  &lt;li&gt;Mass-spring System&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cg-vs-cv&quot;&gt;CG vs CV&lt;/h2&gt;

&lt;h3 id=&quot;difference&quot;&gt;Difference&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/r7onmT.jpg&quot; alt=&quot;cg-1-1&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Computer Vision is to understand, recognize and predict the content of images.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Computer Graphics is to model and simulate the geometry of visual information.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;geek--genius--freak&quot;&gt;Geek = Genius + Freak&lt;/h2&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">An Overview to Computer Graphics</summary></entry></feed>