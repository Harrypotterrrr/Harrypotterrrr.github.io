<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://harrypotterrrr.github.io//feed.xml" rel="self" type="application/atom+xml" /><link href="https://harrypotterrrr.github.io//" rel="alternate" type="text/html" /><updated>2021-01-08T23:29:48+08:00</updated><id>https://harrypotterrrr.github.io//feed.xml</id><title type="html">Haolin Jia’s Homepage</title><subtitle>Keep working hard!
</subtitle><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><entry><title type="html">The Notes of Computer Graphics Ⅵ</title><link href="https://harrypotterrrr.github.io//2020/09/07/cg-6.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅵ" /><published>2020-09-07T00:00:00+08:00</published><updated>2020-09-07T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/09/07/cg-6</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/09/07/cg-6.html">&lt;p&gt;Texture, Texture Mapping, Interpolation, Texture Filtering&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;texture-mapping&quot;&gt;Texture Mapping&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Texture mapping&lt;/strong&gt; is to apply different colors at different places&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Texture&lt;/strong&gt; defines property and color for each vertex&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;surface&quot;&gt;Surface&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Surfaces are 2D though lives in 3D world space&lt;/li&gt;
  &lt;li&gt;Every 3D surface point also has a place where it goes in the 2D image (&lt;strong&gt;texture&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;In other words, each vertex of primitives in 3D world corresponds to the vertex of the primitive in 2D texture.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVCEp4.jpg&quot; alt=&quot;cg-6-1&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;texture&quot;&gt;Texture&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Texture is applied to Surface&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;We didn’t care about how mapping relationship of triangles produces between model and texture. The mapping and definition of primitives (triangles) are known.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVCZc9.jpg&quot; alt=&quot;cg-6-2&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Generally, texture comes in two ways:
    &lt;ul&gt;
      &lt;li&gt;Art designer design and produce the texture&lt;/li&gt;
      &lt;li&gt;Parameterization of triangular meshes&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parameterization&lt;/strong&gt; is the process of finding parametric equations of a curve, a surface, a manifold or a variety, defined by an implicit equation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;texture-coordinates&quot;&gt;Texture Coordinates&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Each triangle vertex is assigned a texture coordinate $(u,v)$.&lt;/li&gt;
  &lt;li&gt;Define mapping between points on triangle’s surface (object coordinate space) to points in texture coordinate space.&lt;/li&gt;
  &lt;li&gt;Each vertex corresponds to one texture mapping. Again, this mapping is known and we don’t care how this mapping come from.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: No matter the texture is square or not, $u$ and $v$ are in range of $(0,1)$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVeE90.jpg&quot; alt=&quot;cg-6-3&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;texture-tile&quot;&gt;Texture Tile&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Textures can be applied multiple times&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVZlSf.jpg&quot; alt=&quot;cg-6-4&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Well-designed texture is tileable when multiple textures blend together profesionally and seamlessly together, borders of texture is not easily conspicuous.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVi2kV.png&quot; alt=&quot;cg-6-5&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;interpolation&quot;&gt;Interpolation&lt;/h2&gt;

&lt;h3 id=&quot;interpolation-across-triangles-barycentric-coordinates&quot;&gt;Interpolation Across Triangles: Barycentric Coordinates&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Why to interpolate
    &lt;ul&gt;
      &lt;li&gt;Specify values at vertices&lt;/li&gt;
      &lt;li&gt;Obtain smoothly varying values across triangles&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;What to interpolate
    &lt;ul&gt;
      &lt;li&gt;Texture coordinates, colors, normal vectors. etc.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;How to interpolate
    &lt;ul&gt;
      &lt;li&gt;Barycentric coordinate&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;barycentric-coordinate&quot;&gt;Barycentric Coordinate&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Any point $(x,y)$ in the plane can be represented as a linear combination of triangular vertices.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sZUVNq.jpg&quot; alt=&quot;cg-6-6&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A coordinate system for triangles $(\alpha, \beta, \gamma)$&lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned}(x, &amp;amp;y)= \alpha A+\beta B+\gamma C \\ &amp;amp; \alpha+\beta+\gamma=1 \end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Point $(x,y)$ is not in the plane of $ABC$ if $\alpha+\beta+\gamma \neq1$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Point $(x,y)$ is inside the triangle if and only if all three $(\alpha, \beta, \gamma)$ are non-negative.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;e.g. $A$ is when $(\alpha, \beta, \gamma) = (1, 0, 0)$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Geometric viewpoint: proportional areas
    &lt;ul&gt;
      &lt;li&gt;It is available to get $(\alpha, \beta, \gamma)$ by given a spcified point $(x,y)$.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned} \alpha &amp;amp;=\frac{A_{A}}{A_{A}+A_{B}+A_{C}} \\ \beta &amp;amp;=\frac{A_{B}}{A_{A}+A_{B}+A_{C}} \\ \gamma &amp;amp;=\frac{A_{C}}{A_{A}+A_{B}+A_{C}} \end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Barycentric coordinate&lt;/strong&gt; of centroid: $(\alpha, \beta, \gamma) = (\frac{1}{3}, \frac{1}{3}, \frac{1}{3})$, then $(x, y)=\frac{1}{3} A+\frac{1}{3} B+\frac{1}{3} C$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Linear interpolate values at vertices&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;$V_A, V_B, V_C$ can be positions, texture coordinates, color, normal, depth, material attributes…&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[V=\alpha V_{A}+\beta V_{B}+\gamma V_{C}\]

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: barycentric coordinates are not invariant under projection! Thus interpolate every time after projections.&lt;/p&gt;

&lt;h3 id=&quot;texture-applying&quot;&gt;Texture Applying&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Simple texture mapping: diffuse color&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rasterized&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;screen&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;           &lt;span class=&quot;c1&quot;&gt;// Usually a pixel's center&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;evaluate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texture&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coordinate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;at&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Using barycentric coordinates&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;texcolor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;// get texture (u,v)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;set&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;                 &lt;span class=&quot;c1&quot;&gt;// Usually the diffuse albedo Kd of Blinn-Phong reflectance model&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;texture-filtering&quot;&gt;Texture Filtering&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;To determine the texture color for a texture mapped pixel, using the colors near by &lt;strong&gt;texels&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Texel&lt;/strong&gt; (纹素): a pixel on a texture&lt;/li&gt;
  &lt;li&gt;Two main categories of texture filtering, depending on the situation texture filtering
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Magnification filtering&lt;/strong&gt;: a type of reconstruction filter where sparse data is interpolated to fill gaps&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Minification filtering&lt;/strong&gt;: a type of anti-aliasing (AA), where texture samples exist at a higher frequency than required for the sample frequency needed for texture fill&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;texture-magnification&quot;&gt;Texture Magnification&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Insufficient texture resolution: texture is too small comparing to the object, then the texture has to be enlarged than its actual resolution.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: For each point on the object or scene, mapping it to the corresponding point on the low resolution texture will get non-integer coordinates of texture. Rounding off is the common process to obtain non-floating coordinate texel. As a result, multiple pixels of the object or scene will corresponds to the same texel of the texture, which means the generated figure is obscure of low quality. Thus interpolation handle it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sZN7cD.jpg&quot; alt=&quot;cg-6-7&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;bilinear-interpolation&quot;&gt;Bilinear Interpolation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Linear interpolation (1D)&lt;/li&gt;
&lt;/ul&gt;

\[\operatorname{lerp}\left(x, v_{0}, v_{1}\right)=v_{0}+x\left(v_{1}-v_{0}\right)\]

&lt;ul&gt;
  &lt;li&gt;Two horizontal interpolations&lt;/li&gt;
&lt;/ul&gt;

\[u_{0}=\operatorname{lerp}\left(s, u_{00}, u_{10}\right) \\
u_{1}=\operatorname{lerp}\left(s, u_{01}, u_{11}\right)\]

&lt;ul&gt;
  &lt;li&gt;Final vertical interpolation&lt;/li&gt;
&lt;/ul&gt;

\[f(x, y)=\operatorname{lerp}\left(t, u_{0}, u_{1}\right)\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sZNOHA.jpg&quot; alt=&quot;cg-6-8&quot; width=&quot;350px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Red point: want to sample texture value $f(x,y)$&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Black points: indicate texture sample locations (the center of texel)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For the nearest method of texture applying, take the red point as an example, any mapping point in the square which the red point and $u_{11}$ locates at will take $u_{11}$ as a texel. When the object or scene is very large comparing to the texture, multiple pixels will map to the same texel as $u_{11}$. That is the reason why jaggies and artifacts are consipicuous in the above nearest figure.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;For the bilinear interpolation, it takes 4 nearest sample locations with textrue values as labeled, blending the property and information of 4 texels, so the result is more smooth and realistic.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Bilinear interpolation usually gives pretty good results at reasonable costs.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;bicubic-interpolation&quot;&gt;Bicubic Interpolation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Bicubic interpolation is to use 4 x 4 point to do interpolation, which has better performance but higher costs. (Look into the canthus of the above figure, bilinear create jaggies but bicubic is more realistic)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sZNjAI.png&quot; alt=&quot;cg-6-9&quot; width=&quot;650px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;texture-minification&quot;&gt;Texture Minification&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Superadundant texture resolution: Texture is too large comparing to the screen space required, so it has to be shrunken relative to its natural resolution.
    &lt;ul&gt;
      &lt;li&gt;Intuitively, when the texture is large, every information is available. But it is incorrect.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sehxtP.jpg&quot; alt=&quot;cg-6-10&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Screen Pixel’s “Footprint” in Texture
    &lt;ul&gt;
      &lt;li&gt;As the pixel in the screen space get growingly further, the number of corresponding texels in texture gets more and more.&lt;/li&gt;
      &lt;li&gt;Take the above image as an example, the pixels close to the horizon represent a large region of texture. The information lost happens when the square which the blue point is inside is selected as texel&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sehvkt.jpg&quot; alt=&quot;cg-6-11&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Supersampling to antialiasing: yes, high quality, but costly.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;The reason of aliasing when perform minification
    &lt;ul&gt;
      &lt;li&gt;When highly minified, many texels in pixel footprint&lt;/li&gt;
      &lt;li&gt;Signal frequency too large in a pixel&lt;/li&gt;
      &lt;li&gt;Need even higher sampling frequency&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Solution: Not do sampling but get the average value within a range, &lt;strong&gt;Range Query&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: Some data structure like K-d tree, segment tree, binary indexed tree etc. are good ways to solve range query problem.&lt;/p&gt;

&lt;h4 id=&quot;mipmap&quot;&gt;Mipmap&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Precompute and store the averages of the texture over various areas of different size and position.&lt;/li&gt;
  &lt;li&gt;Allowing &lt;strong&gt;fast&lt;/strong&gt;, &lt;strong&gt;approximate&lt;/strong&gt;, &lt;strong&gt;square&lt;/strong&gt; range queries.
    &lt;ul&gt;
      &lt;li&gt;“Mip” comes from the Latin, meaning a multitude in a small space.&lt;/li&gt;
      &lt;li&gt;A sequence of textures that contains the same image but at lower and lower resolution. 
 &lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sehXTI.jpg&quot; alt=&quot;cg-6-12&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;There are total of $log(n)$ images&lt;br /&gt;
 &lt;img src=&quot;https://s3.ax1x.com/2021/01/07/sehO0A.jpg&quot; alt=&quot;cg-6-13&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;The total storage overhead of a mipmap is the summation of series: $\frac{4}{3}$ to the original image.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: We call this kind of structure, with images that represent the same content at a series of lower and lower sampling rates, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;image pyramid&lt;/code&gt; in computer vision field.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Computing Mipmap at level $D$: estimate texture footprint using texture coordinates of &lt;strong&gt;neighboring&lt;/strong&gt; screen samples&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/su7yKx.jpg&quot; alt=&quot;cg-6-14&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The distance between the pixel and neighbouring in screen space is 1&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Denote the pixel $(x,y)$ in screen space and texel $(u,v)$ in texture space&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Denote transformation $\psi$ the mapping from image sapce to texture space as a linear mapping, the transformation equation, thus $u = \psi_{x}(x, y), v = \psi_{y}(x, y)$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/jacobian/v/the-jacobian-matrix&quot;&gt;&lt;em&gt;Jacobian matrix&lt;/em&gt;&lt;/a&gt; $J$ is the best linear approximation of $\psi$ in a neighbourhood of $(u,v)$ where $\psi$ is differentiable.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\lim_{\Delta p \to 0}\psi(\mathbf{p}+\Delta \mathbf{p})=\psi(\mathbf{p} )+ \mathbf{J}\Delta \mathbf{p}\]

\[\mathbf{J}=\frac{\partial (u, v)}{\partial (x, y)}=\left[\begin{array}{ll}\frac{\partial u}{\partial x} &amp;amp; \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} &amp;amp; \frac{\partial v}{\partial y}\end{array}\right]\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKmMo8.gif&quot; alt=&quot;cg-6-15&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Recall that in linear transformation \(\left[\begin{array}{ll}a_{x} &amp;amp; b_{x} \\ a_{y} &amp;amp; b_{y}\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]=\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right]\),\(\left[\begin{array}{ll}a_{x} &amp;amp; b_{x} \\ a_{y} &amp;amp; b_{y}\end{array}\right]\) is transformation matrix, the two columns of it \(\left[\begin{array}{l}a_{x} \\ a_{y}\end{array}\right]\) and \(\left[\begin{array}{l}a_{x} \\ a_{y}\end{array}\right]\) are two basis vector of the new space if the original basis is  \(\left[\begin{array}{l}1 \\ 0\end{array}\right]\) and \(\left[\begin{array}{l}0 \\ 1\end{array}\right]\). Thus, we could take Jacobian matrix as transformation matrix mapping the pixel $(x, y)$ in screen space to the texture space $(u, v)$.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In screen space, suppose $(u, v)_{10}$ and $(u, v)_{01}$ as $(1, 0)$ and $(0, 1)$ relatively, the corresponding texel coordinate is computed by multiplying the transformation Jacobian matrix $J$:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\left(\begin{array}{l}u^{\prime}_{10} \\ v^{\prime}_{10}\end{array}\right)=\left[\begin{array}{cc}\frac{\partial u}{\partial x} &amp;amp; \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} &amp;amp; \frac{\partial v}{\partial y}\end{array}\right]\left(\begin{array}{l}1 \\ 0\end{array}\right)=\left(\begin{array}{c}\frac{\partial u}{\partial x} \\ \frac{\partial v}{\partial x}\end{array}\right)\]

\[\left(\begin{array}{l}u^{\prime}_{01} \\ v^{\prime}_{01}\end{array}\right)=\left[\begin{array}{cc}\frac{\partial u}{\partial x} &amp;amp; \frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial x} &amp;amp; \frac{\partial v}{\partial y}\end{array}\right]\left(\begin{array}{l}0 \\ 1\end{array}\right)=\left(\begin{array}{c}\frac{\partial u}{\partial y} \\ \frac{\partial v}{\partial y}\end{array}\right)\]

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Each column of Jacobian matrix is the new basis vector of the transformed space. &lt;a href=&quot;https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/jacobian/v/jacobian-prerequisite-knowledge&quot;&gt;More details&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sK3AKg.jpg&quot; alt=&quot;cg-6-17&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Choose the level $D$ so that the size covered by the texels at that level is roughly the same as the overall size of the pixel footprint.&lt;/li&gt;
&lt;/ul&gt;

\[D=\log _{2} L\]

\[\quad L=\max \left(\sqrt{\left(\frac{d u}{d x}\right)^{2}+\left(\frac{d v}{d x}\right)^{2}}, \sqrt{\left(\frac{d u}{d y}\right)^{2}+\left(\frac{d v}{d y}\right)^{2}}\right)\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/su7UVU.jpg&quot; alt=&quot;cg-6-16&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$D$ rounded to nearest integer level
    &lt;ul&gt;
      &lt;li&gt;near (in red) corresponds to low level of texture&lt;/li&gt;
      &lt;li&gt;far (in blue) corresponds to high level of texture&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKJYZQ.jpg&quot; alt=&quot;cg-6-18&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;But Bilinear filtering only, where $D$ is clamped to nearest level, not support floating $D$ and the level $D$ is not continuous.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Trilinear Interpolation&lt;/strong&gt;: perform two Bilinear interpolation in neighbouring levels and interpolate the interpolated result again.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[u_{d}= BilinearInterpolate(p_{d})\\
u_{d+1}= BilinearInterpolate(p_{d+1})\\
f(x, y) = lerp(r, u_{d}, u_{d+1})\]

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKs5lQ.jpg&quot; alt=&quot;cg-6-19&quot; width=&quot;650px&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;isotrpic-limitation&quot;&gt;Isotrpic Limitation&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Mipmap limitation
    &lt;ul&gt;
      &lt;li&gt;the pixel footprint might be quite different in shape from the area represented by the texel, not always approximately square&lt;/li&gt;
      &lt;li&gt;Mipmap is unable to handle the pixel footprint with an elongated shape&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKs4Sg.jpg&quot; alt=&quot;cg-6-20&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tilinear (&lt;strong&gt;isotropic&lt;/strong&gt;) sampling will cause overblur problem most commonly when the points are on the floor that are far away viewed at very steep angles, which results in the pixel footprint covering much larger square areas.&lt;/li&gt;
  &lt;li&gt;As a result, most footprints far from the viewer are averaged over the large area of the texture, which causes &lt;strong&gt;overblur&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKsffS.jpg&quot; alt=&quot;cg-6-21&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;anisotropic-filtering&quot;&gt;Anisotropic filtering&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Anisotropic filtering&lt;/strong&gt;(Ripmap, or abbreviated &lt;strong&gt;AF&lt;/strong&gt;): use multiple lookups to approximate an elongated footprint better
    &lt;ul&gt;
      &lt;li&gt;select the mipmap level based on the shortest axis of the footprint rather than the largest&lt;/li&gt;
      &lt;li&gt;average together several lookups spaced along the long axis&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Look up axis-aligned rectangular zones and preserve detail at extreme viewing angles.&lt;/li&gt;
  &lt;li&gt;Comparing to isotropic filtering which consume on third of extra space, anisotropic filtering takes three times of extra space consumption.
    &lt;ul&gt;
      &lt;li&gt;Bilinear / trilinear filtering is insotropic and thus will overblur to avoid aliasing&lt;/li&gt;
      &lt;li&gt;Anisotropic texture filtering provides higher image quality at higher computation and memory bandwidth cost&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/08/sKsIyj.png&quot; alt=&quot;cg-6-22&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: N x Anisotropic filtering in video games means the original figure will be copied of reduced size up to N times along horizontal and vertial axis. No matter the N increases to 4x, 8x, 16x or more, the ceiling of the space consumption is 4 times of the original texture. Generally, as long as the graphics memory is enough, the larger anisotropy will has no influence on the computing performance.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Limitation so far: diagonal footprints still a problem&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;EWA filtering&lt;/strong&gt; (Elliptically Weighted Average Filtering) to enhance further
    &lt;ul&gt;
      &lt;li&gt;Use multiple lookups&lt;/li&gt;
      &lt;li&gt;Weighted average&lt;/li&gt;
      &lt;li&gt;Mipmap hierarchy still helps&lt;/li&gt;
      &lt;li&gt;Can handle irregular footprints&lt;/li&gt;
      &lt;li&gt;Trade time for better performance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;short-summary&quot;&gt;Short summary&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Texture mapping is a sampling operation and is prone to aliasing.&lt;/li&gt;
  &lt;li&gt;Solution: prefilter texture map to eliminate high frequencies in texture signal.&lt;/li&gt;
  &lt;li&gt;Mip-map: precompute and store multiple resampled versions of the texture image, each of which has different amounts of low-pass filtering.&lt;/li&gt;
  &lt;li&gt;During rendering: dynamically select how much low-pass filtering is required based on distance between nighbouring screen samples in texture space.
    &lt;ul&gt;
      &lt;li&gt;Goal is to retain as much high-frequency content (detail) in the texture as possible, while avoiding aliasing.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www3.cs.stonybrook.edu/~gu/lectures/2020/&quot;&gt;计算共形几何, 顾险峰，丘成桐&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Texture_filtering&quot;&gt;Texture filtering&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Jacobian_matrix_and_determinant&quot;&gt;Jacobian matrix and determinant&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/jacobian/v/the-jacobian-matrix&quot;&gt;Jacobian matrix, Khan Academy&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/bigmonkey/p/8665498.htm&quot;&gt;雅可比行列式&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/bigmonkey/p/8665498.html&quot;&gt;多变量微积分———变量替换&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://kaba.hilvi.org/homepage/cg/ewa/ewa.htm&quot;&gt;Enhanced EWA filtering&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">Texture, Texture Mapping, Interpolation, Texture Filtering</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅴ</title><link href="https://harrypotterrrr.github.io//2020/09/02/cg-5.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅴ" /><published>2020-09-02T00:00:00+08:00</published><updated>2020-09-02T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/09/02/cg-5</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/09/02/cg-5.html">&lt;p&gt;Shading, Blinn-Phong Shading Model, Shading Frequency, Graphics Pipeline&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;shading&quot;&gt;Shading&lt;/h2&gt;

&lt;h3 id=&quot;what-we-done-so-far&quot;&gt;What we done so far&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Model transformation&lt;/li&gt;
  &lt;li&gt;View transformation&lt;/li&gt;
  &lt;li&gt;Projection transformation&lt;/li&gt;
  &lt;li&gt;Viewport transformation&lt;/li&gt;
  &lt;li&gt;Rasterization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwP9U.jpg&quot; alt=&quot;cg-5-1&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The color applied to each pixel has not been determined yet.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;blinn-phong-reflectance-model&quot;&gt;Blinn-Phong Reflectance Model&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Shading&lt;/strong&gt;: The process of applying a material to an object.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Specular highlight&lt;/strong&gt;: the bright spot of light that apperas on shiny objects when illuminated. Direct light&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Diffuse lighting&lt;/strong&gt;: when a surface that faces an angle 90 degrees or less of the light, it will get a percentage of the light source. Direct light, but diverted from the light source&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ambient lighting&lt;/strong&gt;: light of the environment, most of which comes from reflected surfaces (by diffusion). Indirect light and not in the path of light source&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: We often assume ambient lighting is a constant.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skw9hT.jpg&quot; alt=&quot;cg-5-2&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;shading-point&quot;&gt;Shading point&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Compute light reflected toward camera at a specific &lt;strong&gt;shading point&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Inputs:
    &lt;ul&gt;
      &lt;li&gt;Viewer direction $v$&lt;/li&gt;
      &lt;li&gt;Surface normal $n$&lt;/li&gt;
      &lt;li&gt;Light direction $l$&lt;/li&gt;
      &lt;li&gt;Surface parameters, properties (color, shininess, etc.)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Caveat&lt;/strong&gt;: Above are all &lt;strong&gt;unit&lt;/strong&gt; vectors.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwFc4.jpg&quot; alt=&quot;cg-5-3&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Shading is local, so &lt;strong&gt;No Shadows&lt;/strong&gt; will be generated! (&lt;strong&gt;shading ≠ shadow&lt;/strong&gt;)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The below region in red rectangular is blocked by the object from the light source, but we still shade color to it since &lt;strong&gt;shading is local&lt;/strong&gt;. The shadow of this area will be discussed &lt;a href=&quot;&quot;&gt;later&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwi3F.jpg&quot; alt=&quot;cg-5-4&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;blinn-phong-model&quot;&gt;Blinn-Phong Model&lt;/h2&gt;

&lt;h3 id=&quot;diffuse-reflection&quot;&gt;Diffuse reflection&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Light is scattered uniformly in all directions&lt;/li&gt;
  &lt;li&gt;Surface color is the same for all viewing directions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwkjJ.jpg&quot; alt=&quot;cg-5-5&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lambert’s cosine law: determine how much light is received&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwZH1.jpg&quot; alt=&quot;cg-5-6&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;light-falloff&quot;&gt;Light Falloff&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Assume that ideally there is no loss of energy, for each moment of energy transmission, each spherical shell carries the same amount of luminous energy. For each unit space $dS$ on the spherical shell, we assume the energy is the same, so the for each spherical shell, the total amount of energy is $\oint IdS = 4\pi r^2 I$. Thus $I$ is inversely proportional to the square of the distance $r$.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwEu9.jpg&quot; alt=&quot;cg-5-7&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Above proof is not strict, but intuitive. More strict prove is as follows:
We assume there is no energy loss, so the luminous energy $Q$ from the light source per unit time is the same. According to $\Phi = dQ / dt$, we can get the luminous flux $\Phi$ per time unit is the same. From the definition of luminance: $L_{v} = d^2\Phi / d\Omega dA cos\theta$, the total of luminance $4\pi r^2 L_{v} = d\Phi / d\Omega cos\theta$ should be the same. Thus luminance $L_{v}$ is inversely proportional to the square of  the distance $r$.&lt;/p&gt;

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Caveat&lt;/strong&gt;: The relationship between Luminous intensity $l_{v}$ and Luminance $L_{v}$ is not clear in CG.&lt;/p&gt;

&lt;h3 id=&quot;diffuse-term&quot;&gt;Diffuse Term&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Lambertian Shading (Diffuse shading)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Shading &lt;strong&gt;independent&lt;/strong&gt; of view direction $v$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skwVBR.jpg&quot; alt=&quot;cg-5-8&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$\max (0, \mathbf{n} \cdot \mathbf{l})$ is to ensure the shading value is always positive even if the light comes from the back of the object&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;info&lt;/strong&gt;: The energy received is relative to the angle between normal $n$ and light $l$. This is also the reason why we feel cold in winter and hot in summer.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Diffuse coefficient&lt;/strong&gt;: often defined as 3 or 4 dimensional vector to store the percentage of energy the shading point reflects (not absorb in). Indirectly contain the material information of the object.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/skDi38.jpg&quot; alt=&quot;cg-5-9&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;specular-term&quot;&gt;Specular Term&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Intensity &lt;strong&gt;depends&lt;/strong&gt; on view direction
    &lt;ul&gt;
      &lt;li&gt;Specular highlight close to mirror reflection direction&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAURfS.jpg&quot; alt=&quot;cg-5-10&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$v$ close to mirror direction $\Leftrightarrow$ half vector close to normal&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUhlQ.jpg&quot; alt=&quot;cg-5-11&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Specular coefficient&lt;/strong&gt;: similar to &lt;strong&gt;diffuse coefficient&lt;/strong&gt;, to describe the property and material of the object, but specular coefficient always set to 1, which means the shading point emmits white color when the specular reflection happens.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;phong exponent&lt;/strong&gt;: increasing phong exponent $p$ will narrow the reflection lobe and accelerate the decay rate of the specular reflection effect as the angle increased.&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;When the angle between the reflected light and view direction more than 3~5 degree, we suppose specular reflection disappears.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUfSg.jpg&quot; alt=&quot;cg-5-12&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAU2Y8.jpg&quot; alt=&quot;cg-5-13&quot; width=&quot;780px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Compared to diffuse reflection, we ignore the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;energy received term&lt;/code&gt; for simplicity. Note that Blinn-Phong model is just an empirical model.&lt;/p&gt;

&lt;h3 id=&quot;ambient-term&quot;&gt;Ambient Term&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shading that does not depend on anything
    &lt;ul&gt;
      &lt;li&gt;Independent of light $l$ and view direction $v$&lt;/li&gt;
      &lt;li&gt;Add constant color to account for disregarded illumination and fill in black shadows&lt;/li&gt;
      &lt;li&gt;This is approximate / fake!&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ambient coefficient&lt;/strong&gt;: similar to &lt;strong&gt;specular coefficient&lt;/strong&gt; and &lt;strong&gt;diffuse coefficient&lt;/strong&gt;, but this is always a constant.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUgFf.jpg&quot; alt=&quot;cg-5-14&quot; width=&quot;750px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;blinn-phong-model-1&quot;&gt;Blinn-Phong Model&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAU5Os.jpg&quot; alt=&quot;cg-5-15&quot; /&gt;&lt;/p&gt;

\[\begin{aligned} L &amp;amp;=L_{a}+L_{d}+L_{s} \\ &amp;amp;=k_{a} I_{a}+k_{d}\left(I / r^{2}\right) \max (0, \mathbf{n} \cdot \mathbf{l})+k_{s}\left(I / r^{2}\right) \max (0, \mathbf{n} \cdot \mathbf{h})^{p} \end{aligned}\]

&lt;h2 id=&quot;shading-frequencies&quot;&gt;Shading Frequencies&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Flat (Face) shading (逐片元)&lt;/li&gt;
  &lt;li&gt;Gouraud (Vertex) shading (逐顶点)&lt;/li&gt;
  &lt;li&gt;Phong (Pixel) shading (逐像素)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;flat-shading&quot;&gt;Flat shading&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shading for each triangle&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;normal vector&lt;/code&gt; of each face is caluculated by cross product of triangle’s two edges&lt;/li&gt;
  &lt;li&gt;Not good for smooth surfaces&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUomn.jpg&quot; alt=&quot;cg-5-16&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;gouraud-shading&quot;&gt;Gouraud shading&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shading for each vertices and &lt;strong&gt;interpolate&lt;/strong&gt; triangle from vertices&lt;/li&gt;
  &lt;li&gt;Each vertex has a normal vector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAU7T0.jpg&quot; alt=&quot;cg-5-17&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It is easy to obtain vertex normal from the underlying known geometry. e.g. sphere&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAaOEt.jpg&quot; alt=&quot;cg-5-20&quot; width=&quot;700px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Otherwise vertex normal can be inferred from surrounding triangle:
    &lt;ul&gt;
      &lt;li&gt;average surrounding face normals&lt;/li&gt;
      &lt;li&gt;weighted average surrounding face normals according to the area of each triangle&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[N_{v}=\frac{\sum_{i} N_{i}}{\left\|\sum_{i} N_{i}\right\|}\]

&lt;h3 id=&quot;phong-shading&quot;&gt;Phong shading&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shading for each pixels across triangle&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;normal vector&lt;/code&gt; of each pixels is interpolated by vertex vector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUTwq.jpg&quot; alt=&quot;cg-5-18&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Phong shading&lt;/code&gt; is distinct from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Blinn-Phong reflectance model&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;pixel vector is computed by Barycentric interpolation of vertex normal&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUXpF.jpg&quot; alt=&quot;cg-5-22&quot; width=&quot;650px&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Caveat&lt;/strong&gt;: remember to normalize each normal vector after each step of interpolation.&lt;/p&gt;

&lt;h3 id=&quot;shading-difference&quot;&gt;Shading difference&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;As the model becomes more complex and has more vertices, the difference between three shading models become smaller&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/05/sAUqYT.jpg&quot; alt=&quot;cg-5-19&quot; width=&quot;750px&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;graphics-pipeline&quot;&gt;Graphics Pipeline&lt;/h2&gt;

&lt;h3 id=&quot;real-time-rendering-pipeline&quot;&gt;Real-time Rendering pipeline&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sEh9XR.jpg&quot; alt=&quot;cg-5-22&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;According to different shading frequency (face, vertex, pixel), Shading happens in Vertex Processing or Fragment Processing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Texture mapping also happens in Vertex Processing and Fragment Processing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Texture mapping is to assign vertices with different colors (properties, materials). This is the reason why objects look different in color and material after rendering. Detail in &lt;a href=&quot;/2020/09/07/cg-6&quot;&gt;Texture&lt;/a&gt; later.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sEhPn1.png&quot; alt=&quot;cg-5-23&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Fragment (片元) is widely used in OpenGL and other modern API, which commonly means Pixel. Fragment shading (processing) = Pixel shading (processing).&lt;/p&gt;

&lt;h3 id=&quot;shader-programs&quot;&gt;Shader Programs&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Modern GPU allows to custom various shader by writing &lt;strong&gt;shader program&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Program vertex and fragment processing stages&lt;/li&gt;
      &lt;li&gt;Describe operation on a single vertex or fragment. Shader function executes once per fragment, thus there is no need to loop or traverse each vertex or fragment&lt;/li&gt;
      &lt;li&gt;Outputs color of surface at the current fragment’s screen sample position&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Example GLSL fragment shader program&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sampler2D&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;myTexture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;// texture property&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lightDir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;              &lt;span class=&quot;c1&quot;&gt;// inversed light direction vector&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;varying&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec2&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;                    &lt;span class=&quot;c1&quot;&gt;// perfragment value (interp. by rasterizer)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;varying&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;                  &lt;span class=&quot;c1&quot;&gt;// norm vector, perfragment value (interp. by rasterizer)&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;diffuseShader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vec3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;                        &lt;span class=&quot;c1&quot;&gt;// vector3d to store color value&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;kd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;texture2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;myTexture&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// material color and property from texture&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;kd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;–&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lightDir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// diffuse shading&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;gl_FragColor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;// assign fragment color value to gl_FragColor&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;This shader performs a texture lookup to obtain the surface’s material color at this point&lt;/li&gt;
  &lt;li&gt;Then performs a diffuse lighting calculation&lt;/li&gt;
  &lt;li&gt;Vertex shader (顶点着色器) programs to each vertex, fragment shader （片元/像素着色器) programs to each pixel&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Info&lt;/strong&gt;: Incredible shader program and website: shadertoy.com&lt;/p&gt;

&lt;h3 id=&quot;highly-complex-3d-scenes-in-realtime&quot;&gt;Highly Complex 3D Scenes in Realtime&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Modern GPU could handle much complex 3D scenes in realtime by deploying great amount of computation in parallel.
    &lt;ul&gt;
      &lt;li&gt;thousands to millions of triangles in a scene&lt;/li&gt;
      &lt;li&gt;Complex vertex and fragment shader computations&lt;/li&gt;
      &lt;li&gt;High resolution (2-4 megapixel and supersampling)&lt;/li&gt;
      &lt;li&gt;30-60 fps (frames per second) and even higher for VR&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Game engine&lt;/strong&gt; (architecture) is designed for developers to focus more on constructing games instead of techniques of graphics or rendering. The core functionality typically by a game engine includes a rendering engine (renderer) for 2D or 3D graphics (including shadows, global illumination etc.), a physics engine including collision detection and response, animation, artifical intelligence, sounding, memory management, threading, precomputation etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gpu-graphics-pipeline-implementation&quot;&gt;GPU: Graphics Pipeline Implementation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Specialized processors for executing graphics pipeline computations&lt;/li&gt;
  &lt;li&gt;Heterogeneous, Multi-core Processor&lt;/li&gt;
  &lt;li&gt;Emerge different new shaders:
    &lt;ul&gt;
      &lt;li&gt;Geometry shader: govern the processing of primitives and produce more triangles&lt;/li&gt;
      &lt;li&gt;Compute shader: more general purpose for different computing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/06/sVF90I.jpg&quot; alt=&quot;cg-5-24&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;FLOPS (floating point operatins per second): measure of computer performance:&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Prefix&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Abbreviation&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Order of magnitude&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Computer performance&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Storage capacity&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;mega-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;M&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^6$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;megaFLOPS (MFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;megabyte (MB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;giga-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;G&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^9$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;gigaFLOPS (GFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;gigabyte (GB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;tera-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;T&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^{12}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;teraFLOPS (TFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;terabyte (TB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;peta-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;P&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^{15}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;petaFLOPS (PFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;petabyte (PB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;exa-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;E&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^{18}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;exaFLOPS (EFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;exabyte (EB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;zetta-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Z&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^{21}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;zettaFLOPS (ZFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;zettabyte (ZB)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yotta-&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Y&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$10^{24}$&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yottaFLOPS (YFLOPS)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yottabyte (YB)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/53080536/answer/133398317&quot;&gt;光能、光通量、光强、亮度&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">Shading, Blinn-Phong Shading Model, Shading Frequency, Graphics Pipeline</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅳ</title><link href="https://harrypotterrrr.github.io//2020/08/19/cg-4.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅳ" /><published>2020-08-19T00:00:00+08:00</published><updated>2020-08-19T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/08/19/cg-4</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/08/19/cg-4.html">&lt;p&gt;Rasterization, Sampling, Frequency and Filtering, Antialiasing, Z-buffer&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;after-viewing-transformation&quot;&gt;After Viewing transformation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Viewport transformation&lt;/strong&gt;: project the canonical cube $\left[-1, 1\right]^3$, we get from viewing transformation, to the screen.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;screen&quot;&gt;Screen&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;An array of pixels&lt;/li&gt;
  &lt;li&gt;Size of the array: resolution (i.e. 1920 x 1080)&lt;/li&gt;
  &lt;li&gt;A typical kind of raster display&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;raster&quot;&gt;Raster&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Raster&lt;/strong&gt; == screen in German&lt;/li&gt;
  &lt;li&gt;Rasterize – drawing onto the screen&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pixel&quot;&gt;Pixel&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;short for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;picture element&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;For now: A pixel is a little square with uniform color. [Not strictly]&lt;/li&gt;
  &lt;li&gt;Color is a mixture of (red, green, blue)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the real displays of LCD screen. Each pixel is not uniform color, but R,G,B pixel geometry. Even so, now we assume a colored square full-color pixel.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rx0xXT.jpg&quot; alt=&quot;cg-4-7&quot; width=&quot;600px&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: Bayer Pattern(Filter) is shown on the right, where green elements are twice as many as  red or blue to mimic the physiology of the human eye which is more sensitive to green light.&lt;/p&gt;

&lt;h3 id=&quot;screen-space&quot;&gt;Screen space&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxwcR0.jpg&quot; alt=&quot;cg-4-1&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Following definition is slightly different from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tiger book&lt;/code&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;Pixels indices are in the form of $(x,y)$, where both $x$ and $y$ are integers&lt;/li&gt;
      &lt;li&gt;Pixels indices are from $(0,0)$ to $(width-1, height-1)$&lt;/li&gt;
      &lt;li&gt;Pixel $(x,y)$ is centered at $(x+0.5, y+0.5)$&lt;/li&gt;
      &lt;li&gt;The screen covers range $(0,0)$ to $(width, height)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;canonical-cube-to-screen&quot;&gt;Canonical Cube to Screen&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxw6Gq.jpg&quot; alt=&quot;cg-4-2&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;irrelevant to $z$&lt;/li&gt;
  &lt;li&gt;Transform in $xy$ plane: $\left[-1, 1\right]^2$ to $\left[0, width\right]^2 \times \left[0, height\right]^2$&lt;/li&gt;
  &lt;li&gt;Viewport transform matrix&lt;/li&gt;
&lt;/ul&gt;

\[M_{\text {viewport}}=\left(\begin{array}{cccc}\frac{\text {width}}{2} &amp;amp; 0 &amp;amp; 0 &amp;amp; \frac{\text {width}}{2} \\ 0 &amp;amp; \frac{\text {height}}{2} &amp;amp; 0 &amp;amp; \frac{\text {height}}{2} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right)\]

&lt;h3 id=&quot;raster-displays&quot;&gt;Raster Displays&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;CRT (Cathode Ray Tube)&lt;/li&gt;
  &lt;li&gt;Television: Raster Display CRT&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: On the memory of PC or Graphic Processing Unit (GPU), &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Frame Buffer&lt;/code&gt; is the memory for a raster display.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;LCD (Liquid Crystal Display)
    &lt;ul&gt;
      &lt;li&gt;Principle: block or transmit light by twisting polarization(极化, 偏振方向)&lt;/li&gt;
      &lt;li&gt;Base on the wave property of light&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Electrophoretic&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rasterization&quot;&gt;Rasterization&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Rasterization&lt;/strong&gt;: Drawing to Raster Display&lt;/p&gt;

&lt;h3 id=&quot;triangles--fundamental-shape&quot;&gt;Triangles = Fundamental Shape&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Most basic polygon
    &lt;ul&gt;
      &lt;li&gt;break up other polygons&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Unique properties
    &lt;ul&gt;
      &lt;li&gt;Guaranteed to be planar&lt;/li&gt;
      &lt;li&gt;Well-defined interior (How about the polygon which has holes in it, and how about concave polygons?)&lt;/li&gt;
      &lt;li&gt;Well-defined method for interpolating values at vertices over triangle (barycentric interpolation)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;from-triangle-to-pixels&quot;&gt;From Triangle to pixels&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Input: position of traingle vertices projected on screen&lt;/li&gt;
  &lt;li&gt;Output: set of pixel values approximating triangle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxUIII.jpg&quot; alt=&quot;cg-4-3&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;sampling-a-function&quot;&gt;Sampling a Function&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Evaluating a function at a point is sampling, we can &lt;strong&gt;discretize&lt;/strong&gt; a function by sampling&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxbGnO.jpg&quot; alt=&quot;cg-4-8&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: Sampling is a core idea in graphics. i.e. We sample time(1D), area (2D), direction (2D), volumn (3D). Here, &lt;strong&gt;the centers&lt;/strong&gt; of pixels are used to sample &lt;strong&gt;screen space&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;rasterization-as-2d-sampling&quot;&gt;Rasterization as 2D Sampling&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Sample if each pixel center is inside triangle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxU5dA.jpg&quot; alt=&quot;cg-4-4&quot; width=&quot;430px&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-c++ highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;inside&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// x, y: not necessarily integers&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Point&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;triangle&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ymax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inside&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tri&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Use three &lt;a href=&quot;2020-08-11-cg-2.md#cross-product&quot;&gt;cross product&lt;/a&gt; to check if the Point is inside the triangle or not.&lt;/li&gt;
  &lt;li&gt;Disregard edge cases when the sample point is exactly on the edge of the triangle.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: Pixel values are integers so the center should be additional 0.5 amount.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Use Bounding Box (axis aligned) to avoid checking all pixels on the screen and reduce great time consumption.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxUfqH.jpg&quot; alt=&quot;cg-4-5&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Incremental triangle traversal: traverse from the beginning of the left side of the triangle to the right.
    &lt;ul&gt;
      &lt;li&gt;Suitable for thin and rotated triangles, especially for those which has small area but consume the large proportion of bounding box&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxUTit.jpg&quot; alt=&quot;cg-4-6&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;sampling&quot;&gt;Sampling&lt;/h2&gt;

&lt;h3 id=&quot;ubiquitous-sampling&quot;&gt;Ubiquitous Sampling&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Rasterization = Sample 2D Positions&lt;/li&gt;
  &lt;li&gt;Photograph = Sample Image Sensor Plane&lt;/li&gt;
  &lt;li&gt;Video =  Sample Time&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;artifacts&quot;&gt;Artifacts&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Artifacts&lt;/strong&gt;: Errors, Mistakes, Inaccuracies&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Aliasing Artifacts due to sampling&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Jaggies: sampling in space
&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxbJBD.jpg&quot; alt=&quot;cg-4-9&quot; width=&quot;600px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Moire pattern: undersampling (skip odd rows and columns) images
&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxbh3q.jpg&quot; alt=&quot;cg-4-10&quot; width=&quot;600px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Wagon wheel effect: sampling in time of our eyes
&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rxbgEQ.gif&quot; alt=&quot;cg-4-11&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-reason-behind-the-aliasing-artifact&quot;&gt;The reason behind the Aliasing Artifact&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Signals are changing too &lt;strong&gt;fast&lt;/strong&gt; (high frequency) but sampled too &lt;strong&gt;slowly&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;frequency-and-filtering&quot;&gt;Frequency and Filtering&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Central Idea: Blurring (pre-filtering) before sampling&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Directly sample: pixel values of jaggies in rasterized triangle are pure red or white&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/rzHG59.jpg&quot; alt=&quot;cg-4-12&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Pre-filter before sample: pixel values of antialiased edges have intermediate values&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/rzH8UJ.jpg&quot; alt=&quot;cg-4-13&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: remove frequencies above &lt;a href=&quot;#nyquist-theory&quot;&gt;Nyquist&lt;/a&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The order of blurring and sampling matters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/rzH3E4.jpg&quot; alt=&quot;cg-4-14&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The above figures are sampling, antialiasing (filter then sample), blurred alisaing (sample then filter)&lt;/p&gt;

&lt;p&gt;The reason why undersampling introduces aliasing, and prefiltering then sampling can do antialiasing instead of the inversed operation will be explained at &lt;a href=&quot;#antialiasing&quot;&gt;Antialiasing&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;fourier-transform&quot;&gt;Fourier Transform&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Frequency&lt;/strong&gt;: $f$ in $sin(2\pi fx)$, where $f = \frac{1}{T}$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Represent a function as a weighted sum of sines and cosines.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/sS9m8O.jpg&quot; alt=&quot;cg-4-15&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fourier transform decomposes a signal into frequencies, from spatial domain to frequency domain&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPyISO.png&quot; alt=&quot;cg-4-27&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;nyquist-theory&quot;&gt;Nyquist Theory&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Low frequency signal: sampled adequately for reasonable reconstruction&lt;/li&gt;
  &lt;li&gt;High frequency signal: insufficiently sampled and reconstruction is correct&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/sSiDZd.jpg&quot; alt=&quot;cg-4-16&quot; width=&quot;650px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Thus, higher frequencies need faster sampling&lt;/li&gt;
  &lt;li&gt;Strictly, the sampling frequency should at least be &lt;strong&gt;twice&lt;/strong&gt; the signal bandwidth. This frequency is called &lt;strong&gt;Nyquist rate&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/sSi0qH.jpg&quot; alt=&quot;cg-4-17&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Two frequencies (above blue and black) that are indistinguishable at a given sampling rate called &lt;strong&gt;aliases&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;filtering&quot;&gt;Filtering&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Filtering&lt;/strong&gt;: Getting rid of certain frequency contents&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/02/sSTicV.jpg&quot; alt=&quot;cg-4-18&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The right image shows the value of frequency domain which is transformed by Fourier Transform from the left image, spatial domain.&lt;/li&gt;
&lt;/ul&gt;

\[F(u, v)=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty} f(x, y) e^{-j 2 \pi(u x+v y)} d x d y\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Above two-dimensional transform formula shows that the original image $f(x,y)$ is transformed into $F(u,v)$&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In the right figure, the center represents $u =0,v=0$, that is $F(0,0)$. This means the center of the image is the low frequency region, otherwise high frequency region.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;High-pass filter will get rid of all low frequency and keep edges of the image.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/03/spKY6A.jpg&quot; alt=&quot;cg-4-19&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Low-pass filter will filter the high frequency and retain the smooth part of the image.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/03/spKJld.jpg&quot; alt=&quot;cg-4-20&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: For the two-dimensional Fourier Transform, the image can be thought of as being tiled (stacked vertically and horizontally) infinitely. Thus two highlight strips in a cross shape at the center of the image is caused by the drastic change of the edges of the left figures.&lt;/p&gt;

&lt;h3 id=&quot;convolution&quot;&gt;Convolution&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Convolution in spatial domain is equivalent to multiplication in frequency domain, and vice versa&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;An intuitive proof&lt;/strong&gt;: The spatial domain signal can be decomposed into a series of sinusoidal signals with different frequencies. According to the distributive property of convolution operation, the convolution of two spatial signals can be regarded as the sum of the convolutions of pairwise sinusoidal signals. Since the result of the convolution of sinusodial signals with different frequencies is zero, only the convolution of sinusoidal signals with the same frequency is left. As a result, the output of convolution is that the frequency remains unchanged and the amplitude is to be multiplied. For frequency domain, it appears as direct multiplication.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Option 1:
    &lt;ul&gt;
      &lt;li&gt;Filter by convolution in the spatial domain&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Option 2:
    &lt;ul&gt;
      &lt;li&gt;Transform to frequency domain (Fourier transform)&lt;/li&gt;
      &lt;li&gt;Multiply by Fourier transform of convolution kernel&lt;/li&gt;
      &lt;li&gt;Transform back to spatial domain (inverse Fourier)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sCjpr9.jpg&quot; alt=&quot;cg-4-21&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Regularization term (i.e. $\frac{1}{9}$ in the above image) is to ensure the brightness of theimage does not change after transformation.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Wider Filter Kernel = Lower Frequency&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPyhY6.jpg&quot; alt=&quot;cg-4-22&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sampling = Repeating Frequency Contents&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPy4fK.jpg&quot; alt=&quot;cg-4-23&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;(a) band-unlimited signal&lt;/li&gt;
  &lt;li&gt;(b) frequency spectrum of (a)&lt;/li&gt;
  &lt;li&gt;(c) unit-impulse function, which is used to simulate sampling&lt;/li&gt;
  &lt;li&gt;(d) frequency spectrum of (b)&lt;/li&gt;
  &lt;li&gt;(e) result of convolution of (a) and (c)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;(f) result of multiplication of (d) and (f). More intuitive, (f) is copied for many times along the frequency axis.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Aliasing = Mixed Frequency Contents&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPygm9.jpg&quot; alt=&quot;cg-4-24&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;When the sampling interval becomes small, the corresponding sampling frequency will become relatively large, which will lead to the overlapping phenomenon in final frequency spectrum. Thus, aliasing is caused by information lost.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;antialiasing&quot;&gt;Antialiasing&lt;/h2&gt;

&lt;h3 id=&quot;basic-theory&quot;&gt;Basic theory&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Option 1: Increase sampling rate
    &lt;ul&gt;
      &lt;li&gt;Eseentially increasing the distance between replicas in the Fourier domain&lt;/li&gt;
      &lt;li&gt;Higher resolution displays, sensors, framebuffers..&lt;/li&gt;
      &lt;li&gt;Disadvantage: costly &amp;amp; may need very high resolution&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Option 2: Antialiasing
    &lt;ul&gt;
      &lt;li&gt;Making Fourier contents “narrower” before repeating&lt;/li&gt;
      &lt;li&gt;i.e. Filtering out high frequencies before sampling&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPy2wR.jpg&quot; alt=&quot;cg-4-25&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Perform filtering before the sampling will discard the high frequency and reduce the overlapping phenomenon, consequently reduce the loss of information and aliasing.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Antialiasing by averaging values in pixel area
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Convolve&lt;/strong&gt; by a 1-pixel box-blur (convolving = filtering = averaing)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Sample&lt;/strong&gt; at every pixel’s center&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;In rasterizing one triangle, the average value inside a pixel area is equal to the area of the pixel covered by the triangle&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sPyRT1.jpg&quot; alt=&quot;cg-4-26&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Sampling is an irreversable mapping, so the combination of convolution mapping and sampling is not commutative.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Generally, antialiasing is to filter the high frequency signal so that the sampling frequency could catch up with the signal frequency.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;msaa&quot;&gt;MSAA&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;MSAA (multi-sample antialiasing) is to antialias by supersampling: Approximate the effect of the 1-pixel box filter by sampling multiple locations within a pixel and averagin their values.
    &lt;ul&gt;
      &lt;li&gt;One sample per pixel
&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sP2Ghq.jpg&quot; alt=&quot;cg-4-28&quot; width=&quot;650px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Take N x N samples in each pixel
&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sP2t3V.jpg&quot; alt=&quot;cg-4-29&quot; width=&quot;650px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Average the N x N samples inside each pixel
&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sP2Y90.jpg&quot; alt=&quot;cg-4-30&quot; width=&quot;650px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Until all pixel are averaged
&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sP28Nn.jpg&quot; alt=&quot;cg-4-31&quot; width=&quot;650px&quot; /&gt;&lt;/li&gt;
      &lt;li&gt;Corresponding signal emitted by the display
&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/sP23As.jpg&quot; alt=&quot;cg-4-32&quot; width=&quot;650px&quot; /&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Take 4 x MSAA as an example, given a screen with a resolution of 800 x 600, MSAA firstly render the image to the buffer of 1600 x 1200, and downsample it back to the original 800 x 600.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;The cost of MSAA is time consuming, the size of render target increases to the MSAA multiple times.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The more multiplier of MSAA, the better performace of antialiasing, the more cost of time.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;milestones-of-antialiasing&quot;&gt;Milestones of Antialiasing&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;FXAA (Fast Approximate AA): screen-space anti-aliasing algorithm. Different with MSAA which process the image before the sampling, FXAA postprocess the image after sampled and rasterized. FXAA contrast pixels to heuristically find edges and optimize jaggies in different directions. Very fast!&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;TAA (Temporal AA) : reuse the previous frame and accordingly reduce the effects of temporal aliasing caused by the sampling rate of a scene being too low compared to the transformation speed of objects inside of the scene.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: We often pronounce &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[temˈporəl]&lt;/code&gt; in industry to distinguish with ‘temporary’ meaning.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Super resolution / super sampling
    &lt;ul&gt;
      &lt;li&gt;low resolution to high resolution&lt;/li&gt;
      &lt;li&gt;DLSS (Deep Learning Super Sampling): to understand and predict the missing information&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;visibility-and-occlusion&quot;&gt;Visibility and Occlusion&lt;/h2&gt;

&lt;h3 id=&quot;painters-algorithm&quot;&gt;Painter’s Algorithm&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Solve the problem of triangles rendering order&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Inspired by how painters paint: Paint from back to front, &lt;strong&gt;overwrite&lt;/strong&gt; in the framebuffer.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Require sorting in depth $Olog(n)$ for n triangles&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;unresolvable depth order exist:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/si29sS.png&quot; alt=&quot;cg-4-33&quot; width=&quot;250px&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;z-buffer&quot;&gt;Z-Buffer&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;store current minimum of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;z-value&lt;/code&gt; for each pixel&lt;/li&gt;
  &lt;li&gt;need an additional buffer for depth values
    &lt;ul&gt;
      &lt;li&gt;frame buffer stores color values&lt;/li&gt;
      &lt;li&gt;depth buffer (z-buffer) stores depth&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: For simplicity we suppose &lt;em&gt;z is always positive&lt;/em&gt; (smaller z is closer, larger z is further)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/04/si2pM8.jpg&quot; alt=&quot;cg-4-34&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Initialize&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;depth&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;buffer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inf&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// During rasterization&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;triangle&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;each&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// closest sample so far&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;frame_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rgb&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// update color&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;z_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;// update depth&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pass&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// do nothing, this sample is occluded&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Complexity: $O(n)$ for traversing $n$ triangles&lt;/li&gt;
  &lt;li&gt;Different order of drawing triangles has nothing to do with the result&lt;/li&gt;
  &lt;li&gt;Most important visibility algorithm implemented in hardware for all GPUs&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: z-buffer can not deal with transparent objects.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/29246532&quot;&gt;图像傅里叶变换的频率&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/22611929&quot;&gt;二维傅里叶变换&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/20236638&quot;&gt;FXAA、MSAA区别&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">Rasterization, Sampling, Frequency and Filtering, Antialiasing, Z-buffer</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅲ</title><link href="https://harrypotterrrr.github.io//2020/08/15/cg-3.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅲ" /><published>2020-08-15T00:00:00+08:00</published><updated>2020-08-15T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/08/15/cg-3</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/08/15/cg-3.html">&lt;p&gt;2D/3D Transformation, Viewing Transformation&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;linear-transformations&quot;&gt;Linear Transformations&lt;/h2&gt;

&lt;h3 id=&quot;scale&quot;&gt;Scale&lt;/h3&gt;

\[\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right]=\left[\begin{array}{ll}s_{x} &amp;amp; 0 \\ 0 &amp;amp; s_{y}\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]\]

&lt;h3 id=&quot;reflection&quot;&gt;Reflection&lt;/h3&gt;

\[\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right]=\left[\begin{array}{cc}-1 &amp;amp; 0 \\ 0 &amp;amp; 1\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]\]

&lt;h3 id=&quot;shear&quot;&gt;Shear&lt;/h3&gt;

\[\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right]=\left[\begin{array}{ll}1 &amp;amp; a \\ 0 &amp;amp; 1\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]\]

&lt;h3 id=&quot;rotation&quot;&gt;Rotation&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rHDd58.jpg&quot; alt=&quot;cg-3-1&quot; /&gt;&lt;/p&gt;

\[\mathbf{R}_{\theta}=\left[\begin{array}{cc}\cos \theta &amp;amp; -\sin \theta \\ \sin \theta &amp;amp; \cos \hat{\theta}\end{array}\right]\]

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: For the rotation matrix $M$, which is always normalized in orthogonal form. Thus the transposed matrix $M^{T}$ is exactly inversed matrix $M^{-1}$, that is:
$M^{T}=M^{-1}$, where $M$ is orthogonal matrix&lt;/p&gt;

&lt;h3 id=&quot;linear-transformations-1&quot;&gt;Linear Transformations&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Use the same dimension matrix&lt;/li&gt;
&lt;/ul&gt;

\[\begin{aligned}\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right] &amp;amp;=\left[\begin{array}{ll}a &amp;amp; b \\ c &amp;amp; d\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right] \\ \mathbf{x}^{\prime} &amp;amp;=\mathbf{M} \mathbf{x} \end{aligned}\]

&lt;h2 id=&quot;affine-transformations&quot;&gt;Affine Transformations&lt;/h2&gt;

&lt;h3 id=&quot;homogeneous-coordinate&quot;&gt;Homogeneous Coordinate&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Translation cannot be represented in matrix form&lt;/li&gt;
&lt;/ul&gt;

\[\left[\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right]=\left[\begin{array}{ll}a &amp;amp; b \\ c &amp;amp; d\end{array}\right]\left[\begin{array}{l}x \\ y\end{array}\right]+\left[\begin{array}{l}t_{x} \\ t_{y}\end{array}\right]\]

&lt;p&gt;Hence, translation is &lt;strong&gt;Not&lt;/strong&gt; linear transform&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;But we don’t want translation to be a special case, so is there a unified way to represent all transformations?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Add a third coordinate, and use 3D matrix to represent translations:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;2D point $=(x, y, 1)^{\top}$&lt;/li&gt;
      &lt;li&gt;2D vector $=(x, y, 0)^{\top}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[\left(\begin{array}{c}x^{\prime} \\ y^{\prime} \\ w^{\prime}\end{array}\right)=\left(\begin{array}{ccc}1 &amp;amp; 0 &amp;amp; t_{x} \\ 0 &amp;amp; 1 &amp;amp; t_{y} \\ 0 &amp;amp; 0 &amp;amp; 1\end{array}\right) \cdot\left(\begin{array}{l}x \\ y \\ 1\end{array}\right)=\left(\begin{array}{c}x+t_{x} \\ y+t_{y} \\ 1\end{array}\right)\]

&lt;ul&gt;
  &lt;li&gt;Valid operation if w-coordinate of result is 1 or 0
    &lt;ul&gt;
      &lt;li&gt;vector + vector = vector&lt;/li&gt;
      &lt;li&gt;point - point = vector&lt;/li&gt;
      &lt;li&gt;point + vector = point&lt;/li&gt;
      &lt;li&gt;point + point = ?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: In homogenous coordinates,&lt;br /&gt;
\(\left(\begin{array}{l}x \\ y \\ w\end{array}\right)\) is the 2D point \(\left(\begin{array}{c}x / w \\ y / w \\ 1\end{array}\right), w \neq 0\)&lt;br /&gt;
Thus, &lt;strong&gt;point + point = midpoint of two points&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;affine-transformations-1&quot;&gt;Affine Transformations&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Affine map = linear map + translation&lt;/li&gt;
&lt;/ul&gt;

\[\left(\begin{array}{l}x^{\prime} \\ y^{\prime}\end{array}\right)=\left(\begin{array}{ll}a &amp;amp; b \\ c &amp;amp; d\end{array}\right) \cdot\left(\begin{array}{l}x \\ y\end{array}\right)+\left(\begin{array}{l}t_{x} \\ t_{y}\end{array}\right)\]

&lt;ul&gt;
  &lt;li&gt;Using homogenous coordinates:&lt;/li&gt;
&lt;/ul&gt;

\[\left(\begin{array}{l}x^{\prime} \\ y^{\prime} \\ 1\end{array}\right)=\left(\begin{array}{lll}a &amp;amp; b &amp;amp; t_{x} \\ c &amp;amp; d &amp;amp; t_{y} \\ 0 &amp;amp; 0 &amp;amp; 1\end{array}\right) \cdot\left(\begin{array}{l}x \\ y \\ 1\end{array}\right)\]

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: This means linear transform first, and then translation.&lt;/p&gt;

&lt;h3 id=&quot;inverse-transform&quot;&gt;Inverse Transform&lt;/h3&gt;

&lt;p&gt;$\mathbf{M}^{-1}$ is the inverse of transform $\mathbf{M}$ in both a matrix and geometric sense.&lt;/p&gt;

&lt;h2 id=&quot;composite-transform&quot;&gt;Composite transform&lt;/h2&gt;

&lt;h3 id=&quot;composing-transforms&quot;&gt;Composing Transforms&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Matrix multiplication is not &lt;strong&gt;commutative&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;For a sequence of affine transforms $A_{1}, A_{2}, A_{3}, \ldots$
    &lt;ul&gt;
      &lt;li&gt;Compose by matrix multiplication to speed up:
  \(A_{n}\left(\ldots A_{2}\left(A_{1}(\mathbf{x})\right)\right)=\mathbf{A}_{n} \cdots \mathbf{A}_{2} \cdot \mathbf{A}_{1} \cdot\left(\begin{array}{l}x \\ y \\ 1\end{array}\right)\)&lt;/li&gt;
      &lt;li&gt;Pre-multiply n matrices to obtain a single matrix $\mathbf{A}_{n} \cdots \mathbf{A}_{2} \cdot \mathbf{A}_{1}$ representing combined transform&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;decomposing-complex-transforms&quot;&gt;Decomposing Complex Transforms&lt;/h3&gt;

&lt;p&gt;How to rotate around a given point c?&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Translate center to origin&lt;/li&gt;
  &lt;li&gt;Rotate&lt;/li&gt;
  &lt;li&gt;Translate Back&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rH7d3j.jpg&quot; alt=&quot;cg-3-2&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3d-transformations&quot;&gt;3D transformations&lt;/h2&gt;

&lt;h3 id=&quot;rotation-around-x-y-z-axis&quot;&gt;Rotation around x, y, z-axis&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rHLZMd.jpg&quot; alt=&quot;cg-3-3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;\(\mathbf{R}_{x}(\alpha)=\left(\begin{array}{cccc}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \cos \alpha &amp;amp; -\sin \alpha &amp;amp; 0 \\ 0 &amp;amp; \sin \alpha &amp;amp; \cos \alpha &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right)\)&lt;br /&gt;
\(\mathbf{R}_{y}(\alpha)=\left(\begin{array}{cccc}\cos \alpha &amp;amp; 0 &amp;amp; \sin \alpha &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\ -\sin \alpha &amp;amp; 0 &amp;amp; \cos \alpha &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right)\)&lt;br /&gt;
\(\mathbf{R}_{z}(\alpha)=\left(\begin{array}{cccc}\cos \alpha &amp;amp; -\sin \alpha &amp;amp; 0 &amp;amp; 0 \\ \sin \alpha &amp;amp; \cos \alpha &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right)\)&lt;/p&gt;

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Caveat&lt;/strong&gt;: In $\mathbf{R}_{y}$, where we use right-hand rule $z \times x$ get $y$, so the $\alpha$ is opposite.&lt;/p&gt;

&lt;h3 id=&quot;euler-angles&quot;&gt;Euler angles&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;To represent any 3D rotation from $\mathbf{R}_{x}, \mathbf{R}_{y}, \mathbf{R}_{z}$,&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$\mathbf{R}_{x y z}(\alpha, \beta, \gamma)=\mathbf{R}_{x}(\alpha) \mathbf{R}_{y}(\beta) \mathbf{R}_{z}(\gamma)$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;$(\alpha, \beta, \gamma)$ is &lt;strong&gt;Euler angles&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Often used in flight simulator:&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rb2SjU.jpg&quot; alt=&quot;cg-3-4&quot; width=&quot;450px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Eluer angles may cause &lt;a href=&quot;https://en.wikipedia.org/wiki/Gimbal_lock&quot;&gt;Gimbal lock&lt;/a&gt;: The loss of one degree of &lt;strong&gt;freedom&lt;/strong&gt;.
    &lt;ul&gt;
      &lt;li&gt;This suitation occurs when the axes of two of the three gimbals are driven into a parallel configuration as the below shows.&lt;/li&gt;
      &lt;li&gt;Use &lt;a href=&quot;https://en.wikipedia.org/wiki/Quaternions_and_spatial_rotation&quot;&gt;Unit quaternions&lt;/a&gt; to solve this problem&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rbh2WR.gif&quot; alt=&quot;cg-3-5&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;rodrigues-rotation-formula&quot;&gt;Rodrigues’ Rotation Formula&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Rotation by angle $\alpha$ around axis $n$ (axis $n$ goes through the origin)&lt;/li&gt;
&lt;/ul&gt;

\[\mathbf{R}(\mathbf{n}, \alpha)=\cos (\alpha) \mathbf{I}+(1-\cos (\alpha)) \mathbf{n} \mathbf{n}^{T}+\sin (\alpha) \underbrace{\left(\begin{array}{ccc}0 &amp;amp; -n_{z} &amp;amp; n_{y} \\ n_{z} &amp;amp; 0 &amp;amp; -n_{x} \\ -n_{y} &amp;amp; n_{x} &amp;amp; 0\end{array}\right)}_{\mathbf{N}}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Formula &lt;a href=&quot;https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula#Derivation&quot;&gt;derivation&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;If the rotation axis doesn’t go through the origin, but at $p$&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Translate the axis to origin. $T(-p)$&lt;/li&gt;
      &lt;li&gt;Rotate. $R(n, \alpha)$&lt;/li&gt;
      &lt;li&gt;Translate the axis back: $T(p)$&lt;/li&gt;
      &lt;li&gt;Thus: $T(p)R(n, \alpha)T(-p)$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;viewing-transformation&quot;&gt;Viewing transformation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;View / Camera Transformation&lt;/li&gt;
  &lt;li&gt;Projection transformation
    &lt;ul&gt;
      &lt;li&gt;Orthographics projection&lt;/li&gt;
      &lt;li&gt;Perspective projection&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;a-vivid-analogy&quot;&gt;A vivid analogy&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Analogous to taking a photo:
    &lt;ul&gt;
      &lt;li&gt;Find a good place and arrage people (&lt;strong&gt;model&lt;/strong&gt; transformation)&lt;/li&gt;
      &lt;li&gt;Find a good “angle” to put the camera (&lt;strong&gt;view&lt;/strong&gt; transformation)&lt;/li&gt;
      &lt;li&gt;Cheese! (&lt;strong&gt;projection&lt;/strong&gt; transformation)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;view--camera-transformation&quot;&gt;View / Camera Transformation&lt;/h3&gt;

&lt;h4 id=&quot;define-the-camera&quot;&gt;Define the camera&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Define the camera first (suppose every objects has been arranged properly)
    &lt;ul&gt;
      &lt;li&gt;Position $\vec{e}$&lt;/li&gt;
      &lt;li&gt;Look-at / gaze direction $\hat{g}$&lt;/li&gt;
      &lt;li&gt;up direction $\hat{t}$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rbgzcT.jpg&quot; alt=&quot;cg-3-6&quot; width=&quot;380px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Key observation: If the camera and all objects move together, the photo will be the same. Thus we transform the camera to the fixed origin point.
    &lt;ul&gt;
      &lt;li&gt;Position: the origin&lt;/li&gt;
      &lt;li&gt;Look-at direction: -Z&lt;/li&gt;
      &lt;li&gt;up  direction: Y&lt;/li&gt;
      &lt;li&gt;Then transform the objects along with the fixed camera&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rbgx3V.jpg&quot; alt=&quot;cg-3-7&quot; width=&quot;400px&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;transform-the-camera&quot;&gt;Transform the camera&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Transform the camera by $M_{\text {view}}$
    &lt;ul&gt;
      &lt;li&gt;To locate it at the origin, up at $Y$, look at $Z$
        &lt;ul&gt;
          &lt;li&gt;Translates $e$ to origin&lt;/li&gt;
          &lt;li&gt;Rotates $t$ to $Y$&lt;/li&gt;
          &lt;li&gt;Rotates $g$ to $-Z$&lt;/li&gt;
          &lt;li&gt;If $t$ to $Y$ and $g$ to $-Z$, then $\hat{g} \times \hat{t}$ will be to $X$&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/rqnfI0.jpg&quot; alt=&quot;cg-3-8&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$M_{\text {view}}=R_{\text {view}}T_{\text {view}}$
    &lt;ul&gt;
      &lt;li&gt;Translate $e$ to origin&lt;br /&gt;
\(T_{v i e w}=\left[\begin{array}{cccc}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; -x_{e} \\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; -y_{e} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; -z_{e} \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right]\)&lt;/li&gt;
      &lt;li&gt;Difficult to directly get $R_{view}$, so consider its inverse rotation: &lt;br /&gt;
\(R_{v i e w}^{-1}=\left[\begin{array}{cccc}x_{\hat{g} \times \hat{t}} &amp;amp; x_{t} &amp;amp; x_{-g} &amp;amp; 0 \\ y_{\hat{g} \times \hat{t}} &amp;amp; y_{t} &amp;amp; y_{-g} &amp;amp; 0 \\ z_{\hat{g} \times \hat{t}} &amp;amp; z_{t} &amp;amp; z_{-g} &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right] \quad \Rightarrow  \quad R_{v i e w} = (R_{v i e w}^{-1})^{T} = \left[\begin{array}{cccc}x_{\hat{g} \times \hat{t}} &amp;amp; y_{\hat{g} \times \hat{t}} &amp;amp; z_{\hat{g} \times \hat{t}} &amp;amp; 0 \\ x_{t} &amp;amp; y_{t} &amp;amp; z_{t} &amp;amp; 0 \\ x_{-g} &amp;amp; y_{-g} &amp;amp; z_{-g} &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right]\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: We can validate the result of the multiplication of $R_{v i e w}^{-1}$ and the vector $\left(\begin{array}{llll}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\end{array}\right)$ which represents $X$ axis, the vector $\left(\begin{array}{llll}0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0\end{array}\right)$ which represents $Y$ axis, and the vector $\left(\begin{array}{llll}0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0\end{array}\right)$ which represents $Z$ axis. We could find $X$ axis rotates to $\hat{g} \times \hat{t}$, $Y$ rotates to $t$ and $Z$ rotates to $-g$.&lt;/p&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Each column of the $R_{view}$ except for the last column is the &lt;strong&gt;unit&lt;/strong&gt; vector describing the camera, so the transposed matrix of it is its inversed matrix itself.&lt;/p&gt;

&lt;h3 id=&quot;projection-transformation&quot;&gt;Projection transformation&lt;/h3&gt;

&lt;h4 id=&quot;projection-in-computer-graphics&quot;&gt;Projection in Computer Graphics&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;In orthogonal projection, the camera can be supposed to be placed infinite way from the viewing frustum (now the frustum becomes cuboid).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/31/rvExG6.jpg&quot; alt=&quot;cg-3-9&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;orthographic-projection&quot;&gt;Orthographic Projection&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Camera located at origin, looking at -Z, up at Y&lt;/li&gt;
  &lt;li&gt;Drop Z coordinate&lt;/li&gt;
  &lt;li&gt;Translate and scale the resulting rectangle to $\left[-1, 1\right]^2$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/31/rvEvPx.jpg&quot; alt=&quot;cg-3-10&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;More in general: map a cuboid $\left[l, r\right] \times \left[b, t\right] \times \left[f, n\right]$ to the canonical cube $\left[-1, 1\right]^3$. (left, right, bottom, top, far, near)
    &lt;ul&gt;
      &lt;li&gt;Translate the center to origin first, then scale each edge to 2.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

\[M_{\text {ortho}}=\left[\begin{array}{cccc}\frac{2}{r-l} &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; \frac{2}{t-b} &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; \frac{2}{n-f} &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right]\left[\begin{array}{cccc}1 &amp;amp; 0 &amp;amp; 0 &amp;amp; -\frac{r+l}{2} \\ 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; -\frac{t+b}{2} \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; -\frac{n+f}{2} \\ 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1\end{array}\right]\]

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: Objects may be stretched out of the original scale, so the next &lt;a href=&quot;2020-08-19-cg-4.md#canonical-cube-to-screen&quot;&gt;viewport transform&lt;/a&gt; will deal with this and draw it back to the original scale.&lt;/p&gt;

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Caveat&lt;/strong&gt;: Looking along $-Z$ makes &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f&lt;/code&gt; (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;near&lt;/code&gt; &amp;gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;far&lt;/code&gt;) and this is the reason why OpenGL uses left hand coords.&lt;/p&gt;

&lt;h4 id=&quot;perspective-projection&quot;&gt;Perspective Projection&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;Most common in Computer Graphics, art, visual system&lt;/li&gt;
  &lt;li&gt;Further objects are smaller&lt;/li&gt;
  &lt;li&gt;Parallel lines not parallel, converge to single point&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: We only consider Euclidean Geometry (Not Riemannian Geometry)&lt;/p&gt;

&lt;p&gt;The step to do perspective projection&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;First squish the frustum into a cuboid $M_{\text {persp} \rightarrow \text {ortho}}$&lt;/li&gt;
  &lt;li&gt;Do orthographic projection $M_{ortho}$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/31/rvVBw9.jpg&quot; alt=&quot;cg-3-11&quot; width=&quot;640px&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Denote vertical &lt;strong&gt;field-of-view (fovY)&lt;/strong&gt; and &lt;strong&gt;aspect&lt;/strong&gt; ratio (assume symmetry i.e. $l=-r\ b=-t$)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rvvjfJ.jpg&quot; alt=&quot;cg-3-13&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

\[Aspect\ Ratio=\frac{width}{height}\]

&lt;ul&gt;
  &lt;li&gt;Convert &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fovY&lt;/code&gt; and aspect to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l, r, b, t&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2021/01/01/rvxiTO.jpg&quot; alt=&quot;cg-3-14&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

\[\begin{aligned} \tan \frac{f o v Y}{2} &amp;amp;=\frac{t}{|n|} \\ \text { aspect } &amp;amp;=\frac{r}{t} \end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;Find the relationship between transformed points $\left(x^{\prime}, y^{\prime}, z^{\prime}\right)$ and original points $\left(x, y, z)\right)$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/31/rvVL6S.jpg&quot; alt=&quot;cg-3-12&quot; width=&quot;500px&quot; /&gt;&lt;/p&gt;

\[y^{\prime}=\frac{n}{z} y\]

&lt;p&gt;Similar to $x$:&lt;/p&gt;

\[x^{\prime}=\frac{n}{z} x\]

&lt;ul&gt;
  &lt;li&gt;Use homogenous coordinates to represent this relationship:&lt;/li&gt;
&lt;/ul&gt;

\[\left(\begin{array}{l}x \\ y \\ z \\ 1\end{array}\right) \Rightarrow\left(\begin{array}{c}n x / z \\ n y / z \\ \text { unknown } \\ 1\end{array}\right) \begin{array}{l} == \end{array}\left(\begin{array}{c}n x \\ n y \\ \text { still unknown } \\ z\end{array}\right)\]

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: according to the points defined in homogenous coordinates. &lt;a href=&quot;#homogeneous-coordinate&quot;&gt;reference&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;So the operation squish should be the following form:&lt;/li&gt;
&lt;/ul&gt;

\[M_{\text {persp} \rightarrow \text {ortho}}^{(4 \times 4)}\left(\begin{array}{l}x \\ y \\ z \\ 1\end{array}\right)=\left(\begin{array}{c}n x \\ n y \\ \text { unknown } \\ z\end{array}\right)\]

&lt;ul&gt;
  &lt;li&gt;Three known parameters could get a good reference of three rows of $M_{\text {persp} \rightarrow \text {ortho}}$:&lt;/li&gt;
&lt;/ul&gt;

\[M_{\text {persp} \rightarrow \text {ortho}}=\left(\begin{array}{cccc}n &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; n &amp;amp; 0 &amp;amp; 0 \\ ? &amp;amp; ? &amp;amp; ? &amp;amp; ? \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0\end{array}\right)\]

&lt;ul&gt;
  &lt;li&gt;Two important observations, which is responsible for $z^{\prime}$:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;1. Any point on the near plane will not change&lt;/p&gt;

\[M_{\text {persp} \rightarrow \text {ortho}}^{(4 \times 4)}\left(\begin{array}{l}x \\ y \\ z \\ 1\end{array}\right)=\left(\begin{array}{c}n x \\ n y \\ \text { unknown } \\ z\end{array}\right) \quad \begin{array}{l}\end{array}\]

&lt;p&gt;Replace $z$ with $n$:&lt;/p&gt;

\[\left(\begin{array}{l}x \\ y \\ n \\ 1\end{array}\right) \Rightarrow\left(\begin{array}{l}x \\ y \\ n \\ 1\end{array}\right)==\left(\begin{array}{c}n x \\ n y \\ n^{2} \\ n\end{array}\right)\]

&lt;p&gt;Thus, the third row must be of the form $(0\ 0\ A\ B)$:&lt;/p&gt;

\[\left(\begin{array}{llll}0 &amp;amp; 0 &amp;amp; A &amp;amp; B\end{array}\right)\left(\begin{array}{l}x \\ y \\ n \\ 1\end{array}\right)=n^{2}\]

\[A n+B=n^{2}\]

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Tip&lt;/strong&gt;: $n$ is only the known paramter, and has nothing to do with $z$, so $A$ and $B$ can not be determined yet.&lt;/p&gt;

&lt;p&gt;2. Any $z$ of points on the far plane will not change&lt;/p&gt;

\[\left(\begin{array}{l}0 \\ 0 \\ f \\ 1\end{array}\right) \Rightarrow\left(\begin{array}{l}0 \\ 0 \\ f \\ 1\end{array}\right)==\left(\begin{array}{l}0 \\ 0 \\ f^{2} \\ f\end{array}\right)\]

\[A f+B=f^{2}\]

&lt;ul&gt;
  &lt;li&gt;From the two above equations we get, we could solve $A$ and $B$:&lt;/li&gt;
&lt;/ul&gt;

\[\left\{\begin{array}{l}A n+B=n^{2} \\ A f+B=f^{2}\end{array}\right. \Rightarrow \left\{\begin{array}{l}A=n+f \\ B=-n f\end{array}\right.\]

&lt;ul&gt;
  &lt;li&gt;Now, every entry of $M_{\text {persp} \rightarrow \text {ortho}}$ is known:&lt;/li&gt;
&lt;/ul&gt;

\[M_{\text {persp} \rightarrow \text {ortho}}=\left(\begin{array}{cccc}n &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; n &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; n+f &amp;amp; -nf \\ 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0\end{array}\right)\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Finally, do orthographic projection $M_{ortho}$ to finish&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;In summary: $M_{\text {persp}}=M_{\text {ortho}} M_{\text {persp} \rightarrow \text {ortho}}$&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.zhihu.com/question/47736315&quot;&gt;如何通俗地解释欧拉角？&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/AndrewFan/article/details/60981437#&quot;&gt;欧拉角与万向节死锁&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">2D/3D Transformation, Viewing Transformation</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅱ</title><link href="https://harrypotterrrr.github.io//2020/08/11/cg-2.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅱ" /><published>2020-08-11T00:00:00+08:00</published><updated>2020-08-11T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/08/11/cg-2</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/08/11/cg-2.html">&lt;p&gt;A swift and brutal review of Linear Algebra&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;computer-graphics-dependencies&quot;&gt;Computer Graphics’ Dependencies&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Basic mathematics
    &lt;ul&gt;
      &lt;li&gt;Linear algebra&lt;/li&gt;
      &lt;li&gt;Calculus&lt;/li&gt;
      &lt;li&gt;Statistics&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Basic physics
    &lt;ul&gt;
      &lt;li&gt;Optics (Advanced: if we could not suppose the light travels in straight lines but interacts with a surface material in a form of light wave?)&lt;/li&gt;
      &lt;li&gt;Mechanics&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Misc.
    &lt;ul&gt;
      &lt;li&gt;Signal processing (for anti-alias)&lt;/li&gt;
      &lt;li&gt;Numerical analysis (rendering is to find a solution of calculus defined by recursion, simulation is to solve FEA, Finite Element Analysis, or diffusion equation)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;A bit of aesthetics&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;vector&quot;&gt;Vector&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Direction and length&lt;/li&gt;
  &lt;li&gt;Usually written as $\vec{a}$ or using start and end point $\overrightarrow{AB}$&lt;/li&gt;
  &lt;li&gt;No absolute starting position&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vector-normalization&quot;&gt;Vector Normalization&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Magnitude (length) of a vector written as $|\vec{a}|$&lt;/li&gt;
  &lt;li&gt;Unit vector
    &lt;ul&gt;
      &lt;li&gt;A vector with length of 1&lt;/li&gt;
      &lt;li&gt;$\hat{a}=\vec{a} /|\vec{a}|$&lt;/li&gt;
      &lt;li&gt;represent directions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vector-addition&quot;&gt;Vector Addition&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Geometrically: Parallelogram law &amp;amp; Triangle law&lt;/li&gt;
  &lt;li&gt;Algebraically: Simply add coordinates&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dot-scalar-product&quot;&gt;Dot (scalar) Product&lt;/h3&gt;

&lt;p&gt;$\vec{a} \cdot \vec{b}=|\vec{a}||\vec{b}| \cos \theta$&lt;/p&gt;

&lt;p&gt;For unit vectors:&lt;/p&gt;

\[\cos \theta=\hat{a} \cdot \hat{b}\]

&lt;p&gt;For component-wise multiplication of vectors in Cartesian coordinates:&lt;/p&gt;

\[\vec{a} \cdot \vec{b}=\left(\begin{matrix}x_{a} \\ y_{a} \\ z_{a}\end{matrix}\right) \cdot\left(\begin{matrix}x_{b} \\ y_{b} \\ z_{b}\end{matrix}\right)=x_{a} x_{b}+y_{a} y_{b}+z_{a} z_{b}\]

&lt;p&gt;&lt;strong&gt;Four common usages of dot product&lt;/strong&gt;:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;To find angle between two vectors&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To find projection of one vector on another:&lt;/p&gt;

    &lt;p&gt;To Calculate $\vec{b}_{\perp}$: projection of $\vec{b}$ onto $\vec{a}$&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;$\vec{b}_{\perp}$ must be along $\vec{a}$, thus $\vec{b}_{\perp}=k \hat{a}$&lt;/li&gt;
      &lt;li&gt;The magnitude of $k$ is $\left|\vec{b}_{\perp}\right|=|\vec{b}| \cos \theta$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;To measure how close two directions are&lt;/li&gt;
  &lt;li&gt;To decompose a vector:  $\vec{b}$, $\vec{b}_{\perp}$, $\vec{b}-\vec{b}_{\perp}$&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;cross-product&quot;&gt;Cross Product&lt;/h3&gt;

&lt;p&gt;$|a \times b|=|a||b| \sin \phi$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Cross product is orthogonal to two initial vectors&lt;/li&gt;
  &lt;li&gt;Direction determined by right-hand rule&lt;/li&gt;
  &lt;li&gt;To construct coordinate systems&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some properties:&lt;/p&gt;

&lt;p&gt;$\vec{a} \times \vec{b}=-\vec{b} \times \vec{a}$&lt;/p&gt;

&lt;p&gt;$\vec{a} \times \vec{a}=\overrightarrow{0}$&lt;/p&gt;

&lt;p&gt;$\vec{a} \times(\vec{b}+\vec{c})=\vec{a} \times \vec{b}+\vec{a} \times \vec{c}$&lt;/p&gt;

&lt;p&gt;$\vec{a} \times(k \vec{b})=k(\vec{a} \times \vec{b})$&lt;/p&gt;

&lt;p&gt;For cross product in Cartesian Formula:&lt;/p&gt;

\[\vec{a} \times \vec{b}=\left(\begin{array}{l}y_{a} z_{b}-y_{b} z_{a} \\ z_{a} x_{b}-x_{a} z_{b} \\ x_{a} y_{b}-y_{a} x_{b}\end{array}\right)\]

&lt;p&gt;Or using matrix form:&lt;/p&gt;

\[\vec{a} \times \vec{b}=A^{*} b=\left(\begin{array}{ccc}0 &amp;amp; -z_{a} &amp;amp; y_{a} \\ z_{a} &amp;amp; 0 &amp;amp; -x_{a} \\ -y_{a} &amp;amp; x_{a} &amp;amp; 0\end{array}\right)\left(\begin{array}{l}x_{b} \\ y_{b} \\ z_{b}\end{array}\right)\]

&lt;p&gt;&lt;strong&gt;Two common usages of cross product:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/r7oeXV.jpg&quot; alt=&quot;cg-2-1&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;To determine left/right: check if the cross product of two vectors points to the outside of the screen or out.&lt;/li&gt;
  &lt;li&gt;To determine inside/outside: check if the cross product of $\overrightarrow{AB} \times \overrightarrow{AP}$ and $\overrightarrow{BP} \times \overrightarrow{BP}$ and $\overrightarrow{CA} \times \overrightarrow{CP}$ all directed to the outside of the screen.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;orthonormal-coordinate&quot;&gt;Orthonormal Coordinate&lt;/h3&gt;

&lt;p&gt;We can decompose any vectors $\vec{p}$ by 3 unit vectors:&lt;/p&gt;

&lt;p&gt;$\vec{p}=(\vec{p} \cdot \vec{u}) \vec{u}+(\vec{p} \cdot \vec{v}) \vec{v}+(\vec{p} \cdot \vec{w}) \vec{w}$&lt;br /&gt;
, where&lt;br /&gt;
$|\vec{u}|=|\vec{v}|=|\vec{w}|=1$&lt;br /&gt;
$\vec{u} \cdot \vec{v}=\vec{v} \cdot \vec{w}=\vec{u} \cdot \vec{w}=0$&lt;br /&gt;
$\vec{w}=\vec{u} \times \vec{v} \quad$&lt;/p&gt;

&lt;h2 id=&quot;matrix&quot;&gt;Matrix&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;2D arrays that haunt in every CS course&lt;/li&gt;
  &lt;li&gt;In Graphics, pervasively used to represent &lt;strong&gt;transformations&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;matrix-matrix-multiplication&quot;&gt;Matrix-Matrix Multiplication&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;columns in A must = rows in B&lt;/li&gt;
  &lt;li&gt;Element (i, j) in the product is the dot product of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;row i from A&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;column j from B&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some properties:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Non-commutative: ($AB$ and $BA$ are different in general)&lt;/li&gt;
  &lt;li&gt;Associative and distributive:
    &lt;ul&gt;
      &lt;li&gt;$(AB)C = A(BC)$&lt;/li&gt;
      &lt;li&gt;$A(B+C) = AB + AC$&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;matrix-vecotr-multiplication&quot;&gt;Matrix-Vecotr Multiplication&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Treat vector as a &lt;strong&gt;column matrix&lt;/strong&gt; (Mx1)&lt;/li&gt;
  &lt;li&gt;Treat vector as the right multiplier of the matrix (as a point)&lt;/li&gt;
  &lt;li&gt;Key for transforming points&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;transpose-of-a-matrix&quot;&gt;Transpose of a Matrix&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Switch rows and columns ($ij$ to $ji$)&lt;/li&gt;
  &lt;li&gt;$(A B)^{T}=B^{T} A^{T}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;identity-matrix-and-inverses&quot;&gt;Identity Matrix and Inverses&lt;/h3&gt;

\[I_{3 \times 3}=\left(\begin{array}{lll}1 &amp;amp; 0 &amp;amp; 0 \\ 0 &amp;amp; 1 &amp;amp; 0 \\ 0 &amp;amp; 0 &amp;amp; 1\end{array}\right)\]

&lt;p&gt;$A A^{-1}=A^{-1} A=I$&lt;/p&gt;

&lt;p&gt;$(A B)^{-1}=B^{-1} A^{-1}$&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">A swift and brutal review of Linear Algebra</summary></entry><entry><title type="html">The Notes of Computer Graphics Ⅰ</title><link href="https://harrypotterrrr.github.io//2020/08/10/cg-1.html" rel="alternate" type="text/html" title="The Notes of Computer Graphics Ⅰ" /><published>2020-08-10T00:00:00+08:00</published><updated>2020-08-10T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/08/10/cg-1</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/08/10/cg-1.html">&lt;p&gt;An Overview to Computer Graphics&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;computer-graphics&quot;&gt;Computer Graphics&lt;/h2&gt;

&lt;p&gt;To synthesis and manipulate visual information.&lt;/p&gt;

&lt;h3 id=&quot;application&quot;&gt;Application&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Video Games&lt;/strong&gt;: Technically, global illumination determines the quality of the game performance: the lighter the graphics shows, the better the game is.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Movies&lt;/strong&gt;: Special effects&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Animations&lt;/strong&gt;: Simulate particles in different scenes.&lt;/li&gt;
  &lt;li&gt;Design&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Visualization&lt;/strong&gt;: One of the way to manipulate visual information.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Virtual Reality &amp;amp; Augmented Reality&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Digital Illustration&lt;/strong&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Simulation&lt;/strong&gt;: physical simulation, computation and implementation.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Graphical User Interface&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Topography&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;fundamental-challenge&quot;&gt;Fundamental Challenge&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Require understanding of all aspects of physical world&lt;/li&gt;
  &lt;li&gt;Create and interact with realistic virtual world&lt;/li&gt;
  &lt;li&gt;Computing methods, displays, technology.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;topics&quot;&gt;Topics&lt;/h2&gt;

&lt;h3 id=&quot;rasterization&quot;&gt;Rasterization&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Project &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;geometry primitives&lt;/code&gt; (3D triangles/polygons) on to the screen.&lt;/li&gt;
  &lt;li&gt;Break projected primitives into &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;fragments&lt;/code&gt; (pixels)&lt;/li&gt;
  &lt;li&gt;Gold standard in Video Games (Real-time Applications)&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Real-time/offline computer graphics&lt;/strong&gt;: more than 30 fps (frame per second)&lt;/p&gt;

&lt;h3 id=&quot;curves-and-meshes&quot;&gt;Curves and Meshes&lt;/h3&gt;

&lt;p&gt;How to represent geometry in Computer Graphics&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Bezier Curve&lt;/li&gt;
  &lt;li&gt;Catmull-Clark subdivision&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ray-tracing&quot;&gt;Ray Tracing&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Shoot rays from the camera through each pixel&lt;/li&gt;
  &lt;li&gt;Gold standard in Animations / Movies (Offline Application)\&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;animation--simulation&quot;&gt;Animation / Simulation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Key frame animation&lt;/li&gt;
  &lt;li&gt;Mass-spring System&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;cg-vs-cv&quot;&gt;CG vs CV&lt;/h2&gt;

&lt;h3 id=&quot;difference&quot;&gt;Difference&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.ax1x.com/2020/12/29/r7onmT.jpg&quot; alt=&quot;cg-1-1&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Computer Vision is to understand, recognize and predict the content of images.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Computer Graphics is to model and simulate the geometry of visual information.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;geek--genius--freak&quot;&gt;Geek = Genius + Freak&lt;/h2&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.cs.ucsb.edu/~lingqi/teaching/games101.html&quot;&gt;GAMES101, Lingqi Yan&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="computer graphics" /><category term="notes" /><summary type="html">An Overview to Computer Graphics</summary></entry><entry><title type="html">The Notes of Phil Gordon’s Little Green Book Ⅱ</title><link href="https://harrypotterrrr.github.io//2020/07/29/green-book-2.html" rel="alternate" type="text/html" title="The Notes of Phil Gordon’s Little Green Book Ⅱ" /><published>2020-07-29T00:00:00+08:00</published><updated>2020-07-29T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/07/29/green-book-2</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/07/29/green-book-2.html">&lt;p&gt;Chapter 2: Before the Flop&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;before-the-flop&quot;&gt;Before the Flop&lt;/h2&gt;

&lt;p&gt;Use the starting hand tables under the following specific circumstances:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The first person to voluntarily put money into the pot and to come in for a raise for about three times the big blind.&lt;/li&gt;
  &lt;li&gt;Don’t know much about opponents.&lt;/li&gt;
  &lt;li&gt;All players at the table have an average-size stack&lt;/li&gt;
  &lt;li&gt;The blinds are relatively small in realtion to the size of the stacks.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;study-then-look&quot;&gt;Study, then look&lt;/h3&gt;

&lt;p&gt;Never look at cards before it is your turn, because your judgement will be influenced by the hands.&lt;/p&gt;

&lt;h3 id=&quot;when-first-in-the-pot-raise&quot;&gt;When first in the pot, raise&lt;/h3&gt;

&lt;p&gt;I rarely limp (just call the big blind) when I am the first player to voluntarily put chips into the pot before flop. Almost &lt;strong&gt;always raise&lt;/strong&gt; if you decide to play your hands as the first person in. Here are five reasons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;To limit the competition: A raise will result in fewer player seeing the flop. The fewer player in, the easier to analyze player’s hands and thus the better chance of winning with hands.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: Pocket aces against a random hand wins 85.5% of the time, while wins 55.8% of the time against four hands.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;To take control of the betting: I am informing the other players that I have a high expectation of winning the pot by raising before the flop. Any postflop bets will &lt;strong&gt;back up&lt;/strong&gt; my initial portrayal of strength and become the table captain for this hand.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To better define my opponenets’ hands: Let’s say if I limp in before the flop, then the players behind me and the big blind just checks, they could literally have any two cards:&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;Check with a strong hand like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;K-Q&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;small hand like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;7-2&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;pocket pairs&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;  But if I raise before flop and get others called, we can at least, with some confidence, eliminate the worst third or half of opponenets’ potential hands.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;To make it more difficult for my opponents to determine the strength of my hand: If I raise with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;6-5&lt;/code&gt; suited and with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A-A&lt;/code&gt;, it will effectively conceal the strength of my hand.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;To win the blinds: Opening raise will give a chance to win or steal the blinds without having to see the flop.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Attention&lt;/strong&gt;: Stealing the blinds is critical to the success in poker.&lt;/p&gt;

&lt;h3 id=&quot;limping&quot;&gt;Limping&lt;/h3&gt;

&lt;p&gt;Though always limping is not a good habit, you should keep changing your gear playing cards. There are several situations where limping &lt;em&gt;might&lt;/em&gt; be preferable to raising beffore the flop:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Have a very strong hand and suspect the player behind you may raise if you limp:
    &lt;ul&gt;
      &lt;li&gt;Opponents with short stacks looking for a chance to all in.&lt;/li&gt;
      &lt;li&gt;Maniacs who are raising every time.&lt;/li&gt;
      &lt;li&gt;The players in the blinds are weak after the flop&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: Limp in from middle or late position against a player in the blind who consistently overbets the pot after the flop. Give up a small amount of preflop expectation for some excellent implied odds after the flop.(!!!Pot Odds and Implied Odds)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Limping will help to deceive opponents: By occasionally limping in with a good hand, you may be able to train opponents to allow you to limp in with marginal hands. The player burned by this strategy will be less likely to re-raise the next time you limp in.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;raise-the-right-amount&quot;&gt;Raise the right amount&lt;/h3&gt;

&lt;p&gt;The table of the raise amount regarding the position and the reasons:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Position&lt;/th&gt;
      &lt;th&gt;Raise Amount&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Early&lt;/td&gt;
      &lt;td&gt;2.5x-3.0x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Middle&lt;/td&gt;
      &lt;td&gt;3.0x-3.5x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Late&lt;/td&gt;
      &lt;td&gt;3.5x-4.0x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Small blind&lt;/td&gt;
      &lt;td&gt;3.0x&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;Commit fewer chips when out of the position.&lt;/li&gt;
  &lt;li&gt;Smaller raise with a powerhouse hand from early position encourages opponents to play against you.&lt;/li&gt;
  &lt;li&gt;Bigger raises from late position put pressure on the remaining players to fold and make it harder for the blinds to re-raise.&lt;/li&gt;
  &lt;li&gt;When playing in position, there is always more money in the pot.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Attention&lt;/strong&gt;: Dont vary the size of raise amount with the strength of your hand, because opponents could define your hand by the size of your bet from different multipliers of the raise.&lt;/p&gt;

&lt;p class=&quot;error&quot;&gt;&lt;strong&gt;Important&lt;/strong&gt;: Raising before the flop is to &lt;strong&gt;limit the opponents limping in the pot&lt;/strong&gt;. If you find a raise of three times the big blind is ineffective and opponents are still calling your preflop raise, you could &lt;strong&gt;tighten up the starting hand&lt;/strong&gt; requirements and &lt;strong&gt;raise&lt;/strong&gt; the multiplier.&lt;/p&gt;

&lt;h3 id=&quot;calling-limpers&quot;&gt;Calling limpers&lt;/h3&gt;

&lt;p&gt;While it is not a good habit to limp into a pot as the first player, it is common to call limpers in position.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;A player limps in from middle or late position rarely have a premium cards, so suited connectors(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;8-7&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;7-6&lt;/code&gt;, etc.) and suited gappers(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;8-6&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;7-5&lt;/code&gt;, etc.) will be not dominated. Besides, the strength of opponents’ hands is not strong enough to turn into the big pot, we will benefit more from a small hand. (!!! Big Hand Big Pot, Small Hand Small Pot)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;It is more wasy to get value from exploiting the superior position. You can stands up against three or four opponents with suited aces, suited connectors, or small/medium pocket pairs.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;in-position-smooth-call-a-raiser&quot;&gt;In position, smooth-call a raiser&lt;/h3&gt;

&lt;p&gt;When a component raises and everyone folds to me in late position, it is profitable to call with a wide range of hands. This strategy is especially effective to the opponents who  misses the flop and check to you, or bet when they hit the pot. If they are more likely to miss the flop, you could make a bet and take the pot.&lt;/p&gt;

&lt;h3 id=&quot;playing-from-the-small-blind&quot;&gt;Playing from the small blind&lt;/h3&gt;

&lt;p&gt;If there are no antes in play and the only money in the pot is the small blind and the big blind, I useually stick to a &lt;strong&gt;conservative&lt;/strong&gt; plan: 60~65% of the hands:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Any ace&lt;/li&gt;
  &lt;li&gt;Any pocket pair&lt;/li&gt;
  &lt;li&gt;All suited kings, most unsuited kings&lt;/li&gt;
  &lt;li&gt;Queens down to about &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Q-6&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Jacks down to about &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;J-5&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Most low suited connectors&lt;/li&gt;
  &lt;li&gt;Most low suited one-gap connectors(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;6-4&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;7-5&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;Some trashier hands&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Info&lt;/strong&gt;: With &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;J-5&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Q-6&lt;/code&gt;, the five card gap is the largest gap that allows a two-way straight draw: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;J-5&lt;/code&gt; meets the flop  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;9-8-7&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Q-6&lt;/code&gt; meets the flop &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T-9-8&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;raising-from-the-big-blind&quot;&gt;Raising from the big blind&lt;/h3&gt;

&lt;p&gt;On the rare occasions when everyone folds to the small blind who just completes the bet, you should consider raising with any two cards.&lt;/p&gt;

&lt;h3 id=&quot;raise-the-limpers&quot;&gt;Raise the limpers&lt;/h3&gt;

&lt;p&gt;When an early position player limps in, the next player calls, then it is time to summon up the courage to raise and punish the players with weak hands. It doesn’t take a good hand to win the pot, but situational awareness, tight image and the courage to fire the bullet.&lt;/p&gt;

&lt;p&gt;It is a good idea to raise the size of the pot. If someone happens to call the raise, then you will have a good idea what kind of hand they are on.&lt;/p&gt;

&lt;h3 id=&quot;the-chip-sandwich-play&quot;&gt;The chip-sandwich play&lt;/h3&gt;

&lt;p&gt;Chip-sandwich play: When an early-position opponent, preferably a loose opponent, raises and gets called by one or more players, you could raise when you are &lt;strong&gt;in the blind position&lt;/strong&gt; with a big hand, because:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The pot is large now.&lt;/li&gt;
  &lt;li&gt;Callers have a little chance of having a hand that merit a call or a big re-raise (beacause if they did, they would have raised)&lt;/li&gt;
  &lt;li&gt;If the raise get the initial raiser to fold, the &lt;em&gt;sandwiched&lt;/em&gt; callers would be likely to fold as well.&lt;/li&gt;
  &lt;li&gt;If you make this play from the button and one of the blinds happens to wake up with a great hand, you will get re-raised and lose a lot of money.&lt;/li&gt;
  &lt;li&gt;While if you are in the blinds, especially when you are down to about fifteen big blinds, raising all-in will &lt;strong&gt;negate all positional disadvantage&lt;/strong&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;steal-from-the-cutoff&quot;&gt;Steal from the cutoff&lt;/h3&gt;

&lt;h2 id=&quot;others&quot;&gt;Others&lt;/h2&gt;

&lt;p&gt;筹码较深的时候，中小对子的价值会上升，因为构成暗三比较隐蔽，我们说隐含赔率比较好
筹码越深，位置作用越大
建议浅筹码量入池&lt;/p&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="poker" /><category term="notes" /><summary type="html">Chapter 2: Before the Flop</summary></entry><entry><title type="html">The Notes of Phil Gordon’s Little Green Book Ⅰ</title><link href="https://harrypotterrrr.github.io//2020/07/28/green-book-1.html" rel="alternate" type="text/html" title="The Notes of Phil Gordon’s Little Green Book Ⅰ" /><published>2020-07-28T00:00:00+08:00</published><updated>2020-07-28T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/07/28/green-book-1</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/07/28/green-book-1.html">&lt;p&gt;Chapter 1: The Truth of the Poker Hold’em&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;the-truth-of-the-poker-holdem&quot;&gt;The Truth of the Poker Hold’em&lt;/h2&gt;

&lt;h3 id=&quot;the-fundamental-theorem&quot;&gt;The fundamental theorem&lt;/h3&gt;

&lt;p&gt;Groundbreaking book, The Theory of Poker writes: Every time you play a hand differently from the way you would have played it if you could see all your opponenets’ cards, they gain.
It would be always a right decision to bet or raise when you have the best hand, check and fold when you have the worst hand, and call when you have the right pot odds or implied odds to see another card.&lt;/p&gt;

&lt;h3 id=&quot;common-mistakes&quot;&gt;Common Mistakes&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;A player overvalues top pair: The average winning hand in Hold’em is two pair. If others take tremendous risks with top pair, you will overbet the pot to put them in a dilemma, or go out of my way to play small pocket pairs against them since I am likely to get paid off in a huge way if you flop a set. !!!(Implied odds)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;value-of-aggression&quot;&gt;Value of aggression&lt;/h3&gt;

&lt;p&gt;The player I fear most at the table are the players who consistently bet and raise. Checkers and callers are usually not threats.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Check or call will win only if the best hand is acquired at the showdown.&lt;/li&gt;
  &lt;li&gt;Bet or raise will win either opponents may fold or the best is acquired at the showdown.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;position&quot;&gt;Position&lt;/h3&gt;

&lt;p&gt;If you are in position, you can take advantage of the difficulty of flopping a good hand. Unpaired hole cards (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A-K&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;K-Q&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;6-4&lt;/code&gt;, etc.) will only flop a pair or better about 35% of the time.&lt;/p&gt;

&lt;h3 id=&quot;blinds-have-a-negative-expectation&quot;&gt;Blinds have a negative expectation&lt;/h3&gt;

&lt;p&gt;The blinds have a negative expectation primarily because they are the first to act on every round of betting after the flop. The hands the most success playing from out of position are small and medium pocket pairs. Flopping a set is a great way to win a big pot &lt;strong&gt;from any position&lt;/strong&gt;. !!!(Implied odds)&lt;/p&gt;

&lt;h3 id=&quot;have-a-reason-to-bet&quot;&gt;Have a reason to bet&lt;/h3&gt;

&lt;p&gt;The reason commiting chips into the pot before the flop:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;To steal the blinds. !!!(steal teh blind)&lt;/li&gt;
  &lt;li&gt;To set up a delayed steal, call from position and after my opponent misses the flop, then intend to take the pot.&lt;/li&gt;
  &lt;li&gt;To isolate a player. !!!(re-raise to Isolate)&lt;/li&gt;
  &lt;li&gt;You think you have the best hand.&lt;/li&gt;
  &lt;li&gt;If you make a hand, opponents will pay you off in a big way. !!!(Pot odds and Implied Odds)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The reason to bet after the flop:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;There is a reasonable chance opponents will fold.&lt;/li&gt;
  &lt;li&gt;You think opponents have a draw, and you want to either make them pay for the privilege of drawing or make them fold a hand that can catch up.&lt;/li&gt;
  &lt;li&gt;You think you have the best hand.&lt;/li&gt;
  &lt;li&gt;Betting is the only chance to win the pot.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;changing-gears&quot;&gt;Changing gears&lt;/h3&gt;

&lt;p&gt;It is always right to keep opponenets guessing as to what mode you are in by changing from one gear to the next.&lt;/p&gt;

&lt;h3 id=&quot;big-hand-big-pot-small-hand-small-pot&quot;&gt;Big hand big pot, small hand small pot&lt;/h3&gt;

&lt;p&gt;When an opponent is looing to build a big pot by making a large raise, it is more sensible to throw away most of smaller hands so that you have a better chance of sticking around long enough to get into a big pot with a big hand.&lt;/p&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="poker" /><category term="notes" /><summary type="html">Chapter 1: The Truth of the Poker Hold’em</summary></entry><entry><title type="html">Port forward</title><link href="https://harrypotterrrr.github.io//2020/04/01/Port-forward.html" rel="alternate" type="text/html" title="Port forward" /><published>2020-04-01T00:00:00+08:00</published><updated>2020-04-01T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2020/04/01/Port-forward</id><content type="html" xml:base="https://harrypotterrrr.github.io//2020/04/01/Port-forward.html">&lt;p&gt;Given a internal server without public IP, this cookbook aims to instruct how to use port forward techniques to access resources of it with the help of the outside server with public IP.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h2 id=&quot;preparation&quot;&gt;Preparation&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;One internal server without public IP, has an account named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;innerServer&lt;/code&gt;. This server has resources you want to access remotely.&lt;/li&gt;
  &lt;li&gt;One global server with public IP &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;xx.xx.xx.xx&lt;/code&gt;, has an account named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;publicServer&lt;/code&gt;. This server is used to forward ports.&lt;/li&gt;
  &lt;li&gt;Personal PC, named &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;personalPC&lt;/code&gt;. This one is the only PC around you, enabling you to fetch data from remote nodes.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;target&quot;&gt;Target&lt;/h2&gt;

&lt;p&gt;Manipulate &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;personalPC&lt;/code&gt; to access remote resources from &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;innerServer&lt;/code&gt; through &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;publicServer&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;procedure&quot;&gt;Procedure&lt;/h2&gt;

&lt;h3 id=&quot;forward-the-app-port-to-the-public-server&quot;&gt;Forward the app port to the public server&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; Remote port forwarding to enable &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;publicServer&lt;/code&gt; to listen applications residing in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;innerServer&lt;/code&gt;. Run the command on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;innerServer&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh &lt;span class=&quot;nt&quot;&gt;-NfR&lt;/span&gt; &amp;lt;remote_port&amp;gt;:localhost:&amp;lt;inner_port&amp;gt; publicServer@xx.xx.xx.xx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;remote_port&amp;gt;&lt;/code&gt; is the port specified as the listening port on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;publicServer&lt;/code&gt;, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;inner_port&lt;/code&gt; is the port of the running application on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;innerServer&lt;/code&gt;, e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;inner_port&lt;/code&gt; sets to 22 as ssh service is to be forwarded.&lt;/p&gt;

&lt;p&gt;If the error &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssh : Permission denied (publickey,gssapi-with-mic)&lt;/code&gt; appears, please check &lt;a href=&quot;#faq&quot;&gt;FAQ&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It is also helpful to check whether the ports are being listened at backend both on two server:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;netstat &lt;span class=&quot;nt&quot;&gt;-nultp&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &amp;lt;port&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; Test on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;publicServer&lt;/code&gt; to check if port forwarding works. Run command on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;publicServer&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &amp;lt;remote_port&amp;gt; innerServer@localhost
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Note that the innerServer is the account name of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;innerServer&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Then there are &lt;strong&gt;two ways&lt;/strong&gt; to fetch data to your local PC.&lt;/p&gt;

&lt;h3 id=&quot;forward-the-listening-port-to-the-local-server&quot;&gt;Forward the listening port to the local server&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;3.&lt;/strong&gt; Local port forwarding let a connection from a local computer to another server. Run the command on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;personalPC&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh &lt;span class=&quot;nt&quot;&gt;-NfL&lt;/span&gt; &amp;lt;local_port&amp;gt;:localhost:&amp;lt;remote_port&amp;gt; publicServer@xx.xx.xx.xx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;where &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;remote_port&lt;/code&gt; is the same to the previous setting in remote forwarding step, and the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;local_port&lt;/code&gt; is an available port on your personal PC.&lt;/p&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Info:&lt;/strong&gt; If the SSH connection and the port forwarding both go in the same direction, then it is said to be a local forwarding, otherwise remote forwarding.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4.&lt;/strong&gt; Test connection on your personal PC. Execute the command following or use the third-party app like MobaXTerm to log in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;innerServer&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &amp;lt;local_port&amp;gt; innerServer@xx.xx.xx.xx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;While it would be convenient to fetch remotely in this way, every time local forwarding the port from the local PC to the public server is not handy. Then comes another way.&lt;/p&gt;

&lt;h3 id=&quot;access-resources-directly-through-visiting-the-remote-server&quot;&gt;Access resources directly through visiting the remote server&lt;/h3&gt;

&lt;p&gt;Without step 3 and 4, you directly access the listening port of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;publicServer&lt;/code&gt;. Try the following command on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;personalPC&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &amp;lt;remote_port&amp;gt; innerServer@xx.xx.xx.xx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If time out comes out or the connection failed, it is time to check the firewall checking of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;publicServer&lt;/code&gt;. The following steps are helpful to the public server deployed on google cloud.&lt;/p&gt;

&lt;h2 id=&quot;firewall-setting&quot;&gt;Firewall setting&lt;/h2&gt;

&lt;p&gt;Google cloud has a series of extremely strict regulations and mechanism to prevent from DDOS and other sorts of malevolent attacks. Thus the available port on the google engine is limited and have to be appended whenever it needed. Google issues a useful firewall documentation to manage ports. Check this &lt;a href=&quot;https://cloud.google.com/sdk/gcloud/reference/compute/firewall-rules/create&quot;&gt;link&lt;/a&gt; for more info.&lt;/p&gt;

&lt;p&gt;Shortly, you could firstly try to find out where Firewall Rules option is available by going to look at &lt;strong&gt;VPC Networking&lt;/strong&gt; title of the google cloud console. Then in the &lt;strong&gt;firewall&lt;/strong&gt; tab, all port rules are listed.&lt;/p&gt;

&lt;p&gt;It is a good way to append personal rules by click &lt;strong&gt;CREATE FIREWALL RULE&lt;/strong&gt;, but it is more recommended to use commands on Google Engine:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; First authorize gcloud to access the Cloud Platform with personal credentials:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gcloud auth login
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;filling in the verification code through the link command line provides.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; Append the port through the following command:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gcloud compute firewall-rules create &amp;lt;rule_name&amp;gt; &lt;span class=&quot;nt&quot;&gt;--allow&lt;/span&gt; tcp:&amp;lt;remote_port&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;where the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;rule_name&lt;/code&gt; should satisfy the naming rule, and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;remote_port&lt;/code&gt; is the same to the above specified remote port.&lt;/p&gt;

&lt;p&gt;Then you could return to the &lt;strong&gt;VPC Networking&lt;/strong&gt; website to check if the rule is appended. Now it is time to test if you could access the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;innerServer&lt;/code&gt; directly from you &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;personalPC&lt;/code&gt; through this &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;remote_port&lt;/code&gt; on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;publicServer&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;advanced&quot;&gt;Advanced&lt;/h2&gt;

&lt;p&gt;The connection frequently invalid and too tricky to deal with the disconnection?
Here is a more convenient way to automatically check the tunnel you built between two server.&lt;/p&gt;

&lt;h3 id=&quot;waive-password-to-log-in&quot;&gt;Waive password to log in&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1.&lt;/strong&gt; Build public&amp;amp;private ssh key on &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;innerServer&lt;/code&gt;, execute:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh-keygen
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;then &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id_rsa&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id_rsa.pub&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;known_hosts&lt;/code&gt; three files are generated in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.ssh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2.&lt;/strong&gt; Add ssh key to the public server to authorize identity, then no more password needed next time when log in. Here are two ways to reach this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;copy the content of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id_rsa.pub&lt;/code&gt; of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;innerServer&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.ssh/authorized_keys&lt;/code&gt; of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;publicServer&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;resort to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssh-copy-id&lt;/code&gt; command: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssh-copy-id &amp;lt;publicServer&amp;gt;@xx.xx.xx.xx&lt;/code&gt;, which will automatically copy the public key to the authorized list.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;auto-reconnect-the-broken-ssh&quot;&gt;Auto reconnect the broken ssh&lt;/h3&gt;

&lt;p&gt;Specify a new port &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;listen_port&amp;gt;&lt;/code&gt; to listen the state of the ssh connection and replace &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssh&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;autossh&lt;/code&gt; instructions:&lt;/p&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;autossh &lt;span class=&quot;nt&quot;&gt;-M&lt;/span&gt; &amp;lt;listen_port&amp;gt; &lt;span class=&quot;nt&quot;&gt;-NfR&lt;/span&gt; &amp;lt;remote_port&amp;gt;:localhost:&amp;lt;inner_port&amp;gt; publicServer@xx.xx.xx.xx
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;warning:&lt;/strong&gt; The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-f&lt;/code&gt; flag of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;autossh&lt;/code&gt; is different with the one in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ssh&lt;/code&gt;, which means &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;autossh&lt;/code&gt; will run in the background without a chance to input password. Thus, it is preferable to append &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id_rsa.pub&lt;/code&gt; of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;InnerServer&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;authorized_keys&lt;/code&gt; of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;publicServer&lt;/code&gt; before using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;autossh -f&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;more-extention&quot;&gt;More extention&lt;/h3&gt;

&lt;p&gt;Fill the above instructions in the startup setting in terms of the system version so as to launch the autossh service whenever the system starts up:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;SysV：/etc/inid.d/autossh
Upstart: /etc/init/autossh.conf
systemd: /usr/lib/systemd/system/autossh.service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;startup-script-example&quot;&gt;Startup script example&lt;/h3&gt;

&lt;p&gt;Here is an example of a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;xxx.service&lt;/code&gt; file as Ubuntu startup script under &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/systemd/systme/&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
Description=Port forward
After=network.target syslog.target
Wants=network.target default.target

[Service]
Type=forking
User=lz
Group=lz
ExecStart=/bin/bash /home/lz/potter/scripts/portf.sh
ExecReload=/bin/pkill autossh &amp;amp;&amp;amp; /home/lz/potter/scripts/portf.sh
ExecStop=/bin/pkill autossh

[Install]
WantedBy=default.target
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;portf.sh&lt;/code&gt; script is to describe which port to forward under specified path:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;autossh -M 9230 -NfR 9220:localhost:22 root@106.13.58.57
autossh -M 8895 -NfR 8894:localhost:8894 root@106.13.58.57
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;then refresh the system daemon and start your service:&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl daemon-reload
systemctl start xxx.service
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;faq&quot;&gt;FAQ&lt;/h2&gt;

&lt;h3 id=&quot;ssh-permission-denied&quot;&gt;SSH Permission Denied&lt;/h3&gt;

&lt;p&gt;It is common problem happens on the newly deployed server.
Solved it by amending in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/etc/ssh/sshd_config&lt;/code&gt;:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PasswordAuthentication yes&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GatewayPorts yes&lt;/code&gt; and also &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PermitRootLogin yes&lt;/code&gt; if you use root identity to log in, then re-started the service using &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;service sshd restart&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;reference&quot;&gt;Reference&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/irockcode/p/6629526.html&quot;&gt;SSH反向连接及Autossh&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.csdn.net/bgao86/article/details/80233913&quot;&gt;使用 ssh 端口转发实现登陆内网主机&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://unix.stackexchange.com/questions/115897/whats-ssh-port-forwarding-and-whats-the-difference-between-ssh-local-and-remot&quot;&gt;port forward sketches&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cnblogs.com/keerya/p/7612715.html&quot;&gt;端口转发详解及实例&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="cookbook" /><summary type="html">Given a internal server without public IP, this cookbook aims to instruct how to use port forward techniques to access resources of it with the help of the outside server with public IP.</summary></entry><entry><title type="html">Vim cookbook</title><link href="https://harrypotterrrr.github.io//2019/08/03/Vim-cookbook.html" rel="alternate" type="text/html" title="Vim cookbook" /><published>2019-08-03T00:00:00+08:00</published><updated>2019-08-03T00:00:00+08:00</updated><id>https://harrypotterrrr.github.io//2019/08/03/Vim-cookbook</id><content type="html" xml:base="https://harrypotterrrr.github.io//2019/08/03/Vim-cookbook.html">&lt;p&gt;This is a cheatsheet for vim commands and operations.
&lt;!--more--&gt;&lt;/p&gt;

&lt;h2 id=&quot;configuration&quot;&gt;Configuration&lt;/h2&gt;

&lt;h3 id=&quot;display-line-numbers&quot;&gt;Display line numbers&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;in the current file&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;:set number &lt;span class=&quot;c&quot;&gt;# to enable line numbers&lt;/span&gt;
:set nonumber &lt;span class=&quot;c&quot;&gt;# to disable line numbers&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;to change config&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set number&lt;/code&gt; in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.vimrc&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;set-mouse-mode-on&quot;&gt;set mouse mode on&lt;/h3&gt;

&lt;p&gt;add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set mouse=a&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;~/.vimrc&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;set-tab-size&quot;&gt;set tab size&lt;/h3&gt;

&lt;p&gt;add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;set tabstop=4&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&quot;navigating&quot;&gt;Navigating&lt;/h2&gt;

&lt;h3 id=&quot;basic-movement&quot;&gt;Basic movement&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;h&lt;/code&gt; move to the left by one position&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;l&lt;/code&gt; move to the right by one position&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;j&lt;/code&gt; move to the downward direction by one line&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt; move to the upward direction by one line&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;inline-movement&quot;&gt;Inline movement&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;b&lt;/code&gt; move to the start of the current word&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;e&lt;/code&gt; move to the end of the current word&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;w&lt;/code&gt; move to the start of the next word&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Info:&lt;/strong&gt; combine movement with a number, e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3w&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;9k&lt;/code&gt; is the same as pressing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;w&lt;/code&gt; three times, pressing &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k&lt;/code&gt; nine times, respectively.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;^&lt;/code&gt; move to the first non-blank character&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;g_&lt;/code&gt; move to the last non-blank character&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n + Space&lt;/code&gt; move to the nth character of the current line&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt; move to the &lt;strong&gt;start column&lt;/strong&gt; of the current line&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$&lt;/code&gt; move to the &lt;strong&gt;end column&lt;/strong&gt; of the current line&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;text-movement&quot;&gt;Text movement&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;+&lt;/code&gt; move to the first non-blank character of the next line&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-&lt;/code&gt; move to the first non-blank character of the previous line&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:n&lt;/code&gt; jump to the nth line&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:+n&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n + Enter&lt;/code&gt; jump down n lines&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:-n&lt;/code&gt; jump up n lines&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gg&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:0&lt;/code&gt; move to the &lt;strong&gt;first line&lt;/strong&gt; of the file&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;G&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:$&lt;/code&gt; move to the &lt;strong&gt;end line&lt;/strong&gt; of the file&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Info:&lt;/strong&gt; combine movement with a number, e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3G&lt;/code&gt; move to the third line of the file&lt;/p&gt;

&lt;h3 id=&quot;screen-movement&quot;&gt;screen movement&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl + e&lt;/code&gt; scroll down a line&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl + y&lt;/code&gt; scroll up a line&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl + d&lt;/code&gt; scroll down the half of page&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl + u&lt;/code&gt; scroll up the half page&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl + f&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Page down&lt;/code&gt; scroll down the entire page&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl + b&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Page up&lt;/code&gt; scroll up the entire page&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl + o&lt;/code&gt; jump to the previous position&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl + i&lt;/code&gt; jump to the next position&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;editing&quot;&gt;Editing&lt;/h2&gt;

&lt;h3 id=&quot;insert&quot;&gt;Insert&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;i&lt;/code&gt; insert the text before the cursor&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;I&lt;/code&gt; insert the text at the beginning of the line&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;open-a-new-line&quot;&gt;Open a new line&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;o&lt;/code&gt; open new line below the cursor&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;O&lt;/code&gt; open new line above the cursor&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;append&quot;&gt;Append&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;a&lt;/code&gt; append the text after the cursor&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;A&lt;/code&gt; append the text at the end of line&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;delete&quot;&gt;Delete&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;x&lt;/code&gt; delete the character on the cursor&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X&lt;/code&gt; delete the character before the cursor&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dw&lt;/code&gt; delete a word beginning at the cursor&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;d0&lt;/code&gt; delete from the beginning of current line to the cursor position (including current character)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;d$&lt;/code&gt; delete from current position to the end of the line (including current character)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;D&lt;/code&gt; delete entire line beginning at the cursor&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dd&lt;/code&gt; delete entire line，&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;d1G&lt;/code&gt; delete from the first line to the current line (including current line)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dG&lt;/code&gt; delete from the current line to the end (including current line)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Info:&lt;/strong&gt; combine movement with a number, e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3dw&lt;/code&gt; delete 3 words at a time, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4D&lt;/code&gt; delete 4 lines at a time&lt;/p&gt;

&lt;p class=&quot;warning&quot;&gt;&lt;strong&gt;Mention:&lt;/strong&gt; all of these commands is will ‘cut’ the text to the clipboard, so the following &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p&lt;/code&gt; will works!&lt;/p&gt;

&lt;h3 id=&quot;delete-and-insert&quot;&gt;Delete and insert&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;s&lt;/code&gt; delete the character under the cursor and switch to insert mode&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;S&lt;/code&gt; delete the whole line and switch to insert mode&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;C&lt;/code&gt; delete the following text after the cursor and switch to insert mode&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;replace&quot;&gt;Replace&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;r&lt;/code&gt; replace the character on the cursor but not switch to insert mode&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;R&lt;/code&gt; replace the following text&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;copy--paste&quot;&gt;Copy &amp;amp; Paste&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y&lt;/code&gt; copy a single character on the cursor&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yy&lt;/code&gt; copy entire line&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p&lt;/code&gt; paste text after the cursor&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;P&lt;/code&gt; paste text before the cursor&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Info:&lt;/strong&gt; combine movement with a number, e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3yy&lt;/code&gt; copy the following three lines including the current line&lt;/p&gt;

&lt;h3 id=&quot;join-lines&quot;&gt;Join lines&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;J&lt;/code&gt; remove the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;line breaks&lt;/code&gt; to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;whitespace&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Info:&lt;/strong&gt; combine inserting with a number, e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;5igo&lt;/code&gt; + &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Esc&lt;/code&gt; wil insert ‘go’ five times&lt;/p&gt;

&lt;h3 id=&quot;undo--redo&quot;&gt;Undo &amp;amp; Redo&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;u&lt;/code&gt; undo single action&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;info&quot;&gt;&lt;strong&gt;Info:&lt;/strong&gt; combine inserting with a number, e.g. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3u&lt;/code&gt; will undo action five times&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl + r&lt;/code&gt; redo single action&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;searching&quot;&gt;Searching&lt;/h2&gt;

&lt;h3 id=&quot;inline-searching&quot;&gt;Inline searching&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;f&amp;lt;char&amp;gt;&lt;/code&gt; jump to the next occurrence of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;char&amp;gt;&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;t&amp;lt;char&amp;gt;&lt;/code&gt; jump before the next occurrence of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;char&amp;gt;&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;e.g.&lt;/strong&gt; delete until specified char: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dt&quot;&lt;/code&gt; delete text until &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&quot;&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;global-searching&quot;&gt;Global searching&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;*&lt;/code&gt; search the next occurrence of the word cursor on&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#&lt;/code&gt; search the previous occurrence of the word cursor on&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/&amp;lt;expression&amp;gt;&lt;/code&gt; search the expression in forward direction&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;?&amp;lt;expression&amp;gt;&lt;/code&gt; search the expression in backward direction&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;n&lt;/code&gt; find the next/previous occurence in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/&amp;lt;expression&amp;gt;&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;?&amp;lt;expression&amp;gt;&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;N&lt;/code&gt; find the previous/next occurence in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/&amp;lt;expression&amp;gt;&lt;/code&gt;/&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;?&amp;lt;expression&amp;gt;&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;//&lt;/code&gt; repeat the previous searching&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;advance&quot;&gt;Advance&lt;/h2&gt;

&lt;h3 id=&quot;replace-1&quot;&gt;Replace&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:&amp;lt;line1&amp;gt;,&amp;lt;line2&amp;gt;s/&amp;lt;word1&amp;gt;/&amp;lt;word2&amp;gt;/g&lt;/code&gt; replace &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;word1&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;word2&lt;/code&gt; between &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;line1&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;line2&lt;/code&gt;, flag &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;g&lt;/code&gt; refers to global&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:%s/&amp;lt;word1&amp;gt;/&amp;lt;word2&amp;gt;/gc&lt;/code&gt; replace &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;word1&lt;/code&gt; with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;word2&lt;/code&gt; to the whole text, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;%&lt;/code&gt; means for every line, flag &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;gc&lt;/code&gt; refers to global and need confirmation&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ddp&lt;/code&gt; swap the current line to the next one&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;visual-mode&quot;&gt;Visual mode&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;v&lt;/code&gt; switch to visual mode&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;delete the whole word:&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;v&lt;/code&gt; for visual mode, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;e&lt;/code&gt; jump to the end of the current word, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;d&lt;/code&gt; to delete&lt;/p&gt;

&lt;h3 id=&quot;visual-block-mode&quot;&gt;Visual block mode&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl + v&lt;/code&gt; switch to visual block mode&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;success&quot;&gt;&lt;strong&gt;Comment quickly:&lt;/strong&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ctrl + v&lt;/code&gt; for block mode, select some lines, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;I&lt;/code&gt; to insect at the beginning of each line, input the annotation symbol, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Esc&lt;/code&gt; twice finally comment several lines quickly&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:10,20s#^#//#g&lt;/code&gt; comment &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;//&lt;/code&gt; from line 10 to line 20&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:10,20s#^//##g&lt;/code&gt; uncomment &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;//&lt;/code&gt; from line 10 to line 20&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:10,20s/^/#/g&lt;/code&gt; comment &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#&lt;/code&gt; from line 10 to line 20&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:10,20s/^#//g&lt;/code&gt; uncomment &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;#&lt;/code&gt; from line 10 to line 20&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:%s/$/\r/g&lt;/code&gt; add a newline to each line&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;others&quot;&gt;Others&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;:! &amp;lt;command&amp;gt;&lt;/code&gt; run the command and show the output outside of vim environment&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Haolin Jia</name><email>jiahaolin19971119@gmail.com</email></author><category term="cookbook" /><summary type="html">This is a cheatsheet for vim commands and operations.</summary></entry></feed>